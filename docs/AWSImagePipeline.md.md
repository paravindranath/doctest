[]{#1 .anchor}

AWS Pipeline

AWS Pipeline

Exported on Apr 11, 2019 5:03 PM

Recently Updated
================

-   ![\_scroll\_external/other/61561096f0786d2271838563d1301046-731be5b06b7ec3012033a1384ace652aa20b3c704a6d126b55fb16bef2f4df51](media/image1.png){width="0.5in"
    height="0.5in"}
    (https://atrihub.atlassian.net/wiki/display/\~paravindranath)

    [Pradeep
    Ravindranath](https://atrihub.atlassian.net/wiki/display/~paravindranath)
    (https://atrihub.atlassian.net/wiki/display/\~paravindranath)

-   [Pipeline Dictionary](#pipeline-dictionary)updated yesterday at 3:13
    PM[view
    change](https://atrihub.atlassian.net/wiki/pages/diffpagesbyversion.action?pageId=927367226&selectedPageVersions=27&selectedPageVersions=28)
    (https://atrihub.atlassian.net/wiki/pages/diffpagesbyversion.action?pageId=927367226&selectedPageVersions=27&selectedPageVersions=28)

<!-- -->

-   ![\_scroll\_external/other/f3c4d0a354f4494d0f0d983c01dc7a97-1e61ddbc78a5e70a976bd122c2dadcd8028b10ee948c7ec170eb5ea0e2f70816](media/image2.png){width="0.5in"
    height="0.5in"}
    (https://atrihub.atlassian.net/wiki/display/\~hongmeiq)

    [Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq)
    (https://atrihub.atlassian.net/wiki/display/\~hongmeiq)

-   [EDC Image Pipeline Plugin -
    API](#edc-image-pipeline-plugin---api)updated Apr 09, 2019[view
    change](https://atrihub.atlassian.net/wiki/pages/diffpagesbyversion.action?pageId=965541910&selectedPageVersions=2&selectedPageVersions=3)
    (https://atrihub.atlassian.net/wiki/pages/diffpagesbyversion.action?pageId=965541910&selectedPageVersions=2&selectedPageVersions=3)

-   [Image Pipeline - Parking Lot](#image-pipeline---parking-lot)updated
    Apr 08, 2019[view
    change](https://atrihub.atlassian.net/wiki/pages/diffpagesbyversion.action?pageId=967344202&selectedPageVersions=22&selectedPageVersions=23)
    (https://atrihub.atlassian.net/wiki/pages/diffpagesbyversion.action?pageId=967344202&selectedPageVersions=22&selectedPageVersions=23)

<!-- -->

-   ![\_scroll\_external/other/9ac034177948210d7799e0c32d50265c-a038d8b47e2d6d08c4cde75a21827b6a1aecdfa5ff0dcf3dc120ce570044fb5c](media/image3.png){width="0.5in"
    height="0.5in"}
    (https://atrihub.atlassian.net/wiki/display/\~rkhemka)

    [Rajat Khemka](https://atrihub.atlassian.net/wiki/display/~rkhemka)
    (https://atrihub.atlassian.net/wiki/display/\~rkhemka)

-   [Image Pipeline -
    ProcessDCM.py](#image-pipeline---processdcm.py)updated Apr 04,
    2019[view
    change](https://atrihub.atlassian.net/wiki/pages/diffpagesbyversion.action?pageId=965967879&selectedPageVersions=22&selectedPageVersions=23)
    (https://atrihub.atlassian.net/wiki/pages/diffpagesbyversion.action?pageId=965967879&selectedPageVersions=22&selectedPageVersions=23)

<!-- -->

-   ![\_scroll\_external/other/f3c4d0a354f4494d0f0d983c01dc7a97-1e61ddbc78a5e70a976bd122c2dadcd8028b10ee948c7ec170eb5ea0e2f70816](media/image2.png){width="0.5in"
    height="0.5in"}
    (https://atrihub.atlassian.net/wiki/display/\~hongmeiq)

    [Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq)
    (https://atrihub.atlassian.net/wiki/display/\~hongmeiq)

-   [Image Pipeline Components and
    Resources](#image-pipeline-components-and-resources)updated Apr 03,
    2019[view
    change](https://atrihub.atlassian.net/wiki/pages/diffpagesbyversion.action?pageId=959873105&selectedPageVersions=4&selectedPageVersions=5)
    (https://atrihub.atlassian.net/wiki/pages/diffpagesbyversion.action?pageId=959873105&selectedPageVersions=4&selectedPageVersions=5)

How-to Articles
===============

-   Page:[Setup A new Image Pipeline](#setup-a-new-image-pipeline)(AWS
    Pipeline)

    -   [kb-how-to-article](https://atrihub.atlassian.net/wiki/label/AWSPIPE/kb-how-to-article)
        (https://atrihub.atlassian.net/wiki/label/AWSPIPE/kb-how-to-article)

    -   [runbook](https://atrihub.atlassian.net/wiki/label/AWSPIPE/runbook)
        (https://atrihub.atlassian.net/wiki/label/AWSPIPE/runbook)

-   Page:[How to manually trigger image pipeline in step
    function](#how-to-manually-trigger-image-pipeline-in-step-function)(AWS
    Pipeline)

    -   [kb-how-to-article](https://atrihub.atlassian.net/wiki/label/AWSPIPE/kb-how-to-article)
        (https://atrihub.atlassian.net/wiki/label/AWSPIPE/kb-how-to-article)

Open issues in JIRA
===================

  Key                                                                                                                                  T                                                                                                                                                                                                                                                       Created              Updated              Due   Assignee       Status                                                            Resolution
  ------------------------------------------------------------------------------------------------------------------------------------ ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- -------------------- -------------------- ----- -------------- ----------------------------------------------------------------- ------------
  [PIPE-58](https://atrihub.atlassian.net/browse/PIPE-58?src=confmacro) (https://atrihub.atlassian.net/browse/PIPE-58?src=confmacro)   ![\_scroll\_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](media/image4.png){width="0.16666666666666666in" height="0.16666666666666666in"} (https://atrihub.atlassian.net/browse/PIPE-58?src=confmacro)   Apr 08, 2019 16:51   Apr 08, 2019 16:51         Hongmei Qiu    **<span style="font-variant:small-caps;"> to do </span>**         Unresolved
  [PIPE-57](https://atrihub.atlassian.net/browse/PIPE-57?src=confmacro) (https://atrihub.atlassian.net/browse/PIPE-57?src=confmacro)   ![\_scroll\_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](media/image4.png){width="0.16666666666666666in" height="0.16666666666666666in"} (https://atrihub.atlassian.net/browse/PIPE-57?src=confmacro)   Apr 05, 2019 01:32   Apr 05, 2019 01:32         Hongmei Qiu    **<span style="font-variant:small-caps;"> to do </span>**         Unresolved
  [PIPE-56](https://atrihub.atlassian.net/browse/PIPE-56?src=confmacro) (https://atrihub.atlassian.net/browse/PIPE-56?src=confmacro)   ![\_scroll\_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](media/image4.png){width="0.16666666666666666in" height="0.16666666666666666in"} (https://atrihub.atlassian.net/browse/PIPE-56?src=confmacro)   Apr 04, 2019 23:52   Apr 04, 2019 23:52         Hongmei Qiu    **<span style="font-variant:small-caps;"> to do </span>**         Unresolved
  [PIPE-55](https://atrihub.atlassian.net/browse/PIPE-55?src=confmacro) (https://atrihub.atlassian.net/browse/PIPE-55?src=confmacro)   ![\_scroll\_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](media/image4.png){width="0.16666666666666666in" height="0.16666666666666666in"} (https://atrihub.atlassian.net/browse/PIPE-55?src=confmacro)   Apr 04, 2019 16:47   Apr 08, 2019 14:11         Unassigned     **<span style="font-variant:small-caps;"> in progress </span>**   Unresolved
  [PIPE-54](https://atrihub.atlassian.net/browse/PIPE-54?src=confmacro) (https://atrihub.atlassian.net/browse/PIPE-54?src=confmacro)   ![\_scroll\_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](media/image4.png){width="0.16666666666666666in" height="0.16666666666666666in"} (https://atrihub.atlassian.net/browse/PIPE-54?src=confmacro)   Apr 04, 2019 12:47   Apr 04, 2019 12:47         Hongmei Qiu    **<span style="font-variant:small-caps;"> to do </span>**         Unresolved
  [PIPE-53](https://atrihub.atlassian.net/browse/PIPE-53?src=confmacro) (https://atrihub.atlassian.net/browse/PIPE-53?src=confmacro)   ![\_scroll\_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](media/image4.png){width="0.16666666666666666in" height="0.16666666666666666in"} (https://atrihub.atlassian.net/browse/PIPE-53?src=confmacro)   Apr 03, 2019 00:45   Apr 03, 2019 00:47         Hongmei Qiu    **<span style="font-variant:small-caps;"> in progress </span>**   Unresolved
  [PIPE-52](https://atrihub.atlassian.net/browse/PIPE-52?src=confmacro) (https://atrihub.atlassian.net/browse/PIPE-52?src=confmacro)   ![\_scroll\_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](media/image4.png){width="0.16666666666666666in" height="0.16666666666666666in"} (https://atrihub.atlassian.net/browse/PIPE-52?src=confmacro)   Apr 03, 2019 00:45   Apr 03, 2019 00:47         Hongmei Qiu    **<span style="font-variant:small-caps;"> in progress </span>**   Unresolved
  [PIPE-51](https://atrihub.atlassian.net/browse/PIPE-51?src=confmacro) (https://atrihub.atlassian.net/browse/PIPE-51?src=confmacro)   ![\_scroll\_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](media/image4.png){width="0.16666666666666666in" height="0.16666666666666666in"} (https://atrihub.atlassian.net/browse/PIPE-51?src=confmacro)   Apr 02, 2019 16:28   Apr 04, 2019 16:50         Unassigned     **<span style="font-variant:small-caps;"> in review </span>**     Unresolved
  [PIPE-50](https://atrihub.atlassian.net/browse/PIPE-50?src=confmacro) (https://atrihub.atlassian.net/browse/PIPE-50?src=confmacro)   ![\_scroll\_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](media/image4.png){width="0.16666666666666666in" height="0.16666666666666666in"} (https://atrihub.atlassian.net/browse/PIPE-50?src=confmacro)   Apr 02, 2019 16:17   Apr 04, 2019 16:50         Unassigned     **<span style="font-variant:small-caps;"> in review </span>**     Unresolved
  [PIPE-49](https://atrihub.atlassian.net/browse/PIPE-49?src=confmacro) (https://atrihub.atlassian.net/browse/PIPE-49?src=confmacro)   ![\_scroll\_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](media/image4.png){width="0.16666666666666666in" height="0.16666666666666666in"} (https://atrihub.atlassian.net/browse/PIPE-49?src=confmacro)   Apr 02, 2019 16:17   Apr 04, 2019 16:50         Unassigned     **<span style="font-variant:small-caps;"> in review </span>**     Unresolved
  [PIPE-48](https://atrihub.atlassian.net/browse/PIPE-48?src=confmacro) (https://atrihub.atlassian.net/browse/PIPE-48?src=confmacro)   ![\_scroll\_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](media/image4.png){width="0.16666666666666666in" height="0.16666666666666666in"} (https://atrihub.atlassian.net/browse/PIPE-48?src=confmacro)   Apr 02, 2019 16:17   Apr 04, 2019 16:50         Unassigned     **<span style="font-variant:small-caps;"> in review </span>**     Unresolved
  [PIPE-47](https://atrihub.atlassian.net/browse/PIPE-47?src=confmacro) (https://atrihub.atlassian.net/browse/PIPE-47?src=confmacro)   ![\_scroll\_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](media/image4.png){width="0.16666666666666666in" height="0.16666666666666666in"} (https://atrihub.atlassian.net/browse/PIPE-47?src=confmacro)   Apr 02, 2019 16:17   Apr 04, 2019 16:50         Unassigned     **<span style="font-variant:small-caps;"> in review </span>**     Unresolved
  [PIPE-46](https://atrihub.atlassian.net/browse/PIPE-46?src=confmacro) (https://atrihub.atlassian.net/browse/PIPE-46?src=confmacro)   ![\_scroll\_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](media/image4.png){width="0.16666666666666666in" height="0.16666666666666666in"} (https://atrihub.atlassian.net/browse/PIPE-46?src=confmacro)   Apr 02, 2019 16:12   Apr 04, 2019 16:50         Unassigned     **<span style="font-variant:small-caps;"> in review </span>**     Unresolved
  [PIPE-45](https://atrihub.atlassian.net/browse/PIPE-45?src=confmacro) (https://atrihub.atlassian.net/browse/PIPE-45?src=confmacro)   ![\_scroll\_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](media/image4.png){width="0.16666666666666666in" height="0.16666666666666666in"} (https://atrihub.atlassian.net/browse/PIPE-45?src=confmacro)   Apr 02, 2019 16:07   Apr 04, 2019 16:50         Unassigned     **<span style="font-variant:small-caps;"> in review </span>**     Unresolved
  [PIPE-44](https://atrihub.atlassian.net/browse/PIPE-44?src=confmacro) (https://atrihub.atlassian.net/browse/PIPE-44?src=confmacro)   ![\_scroll\_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](media/image4.png){width="0.16666666666666666in" height="0.16666666666666666in"} (https://atrihub.atlassian.net/browse/PIPE-44?src=confmacro)   Apr 01, 2019 15:44   Apr 03, 2019 00:44         Hongmei Qiu    **<span style="font-variant:small-caps;"> in progress </span>**   Unresolved
  [PIPE-43](https://atrihub.atlassian.net/browse/PIPE-43?src=confmacro) (https://atrihub.atlassian.net/browse/PIPE-43?src=confmacro)   ![\_scroll\_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](media/image4.png){width="0.16666666666666666in" height="0.16666666666666666in"} (https://atrihub.atlassian.net/browse/PIPE-43?src=confmacro)   Apr 01, 2019 15:44   Apr 03, 2019 00:44         Hongmei Qiu    **<span style="font-variant:small-caps;"> in progress </span>**   Unresolved
  [PIPE-42](https://atrihub.atlassian.net/browse/PIPE-42?src=confmacro) (https://atrihub.atlassian.net/browse/PIPE-42?src=confmacro)   ![\_scroll\_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](media/image4.png){width="0.16666666666666666in" height="0.16666666666666666in"} (https://atrihub.atlassian.net/browse/PIPE-42?src=confmacro)   Apr 01, 2019 09:15   Apr 01, 2019 09:16         Hongmei Qiu    **<span style="font-variant:small-caps;"> in progress </span>**   Unresolved
  [PIPE-41](https://atrihub.atlassian.net/browse/PIPE-41?src=confmacro) (https://atrihub.atlassian.net/browse/PIPE-41?src=confmacro)   ![\_scroll\_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](media/image4.png){width="0.16666666666666666in" height="0.16666666666666666in"} (https://atrihub.atlassian.net/browse/PIPE-41?src=confmacro)   Apr 01, 2019 09:14   Apr 01, 2019 09:16         Hongmei Qiu    **<span style="font-variant:small-caps;"> in progress </span>**   Unresolved
  [PIPE-40](https://atrihub.atlassian.net/browse/PIPE-40?src=confmacro) (https://atrihub.atlassian.net/browse/PIPE-40?src=confmacro)   ![\_scroll\_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](media/image4.png){width="0.16666666666666666in" height="0.16666666666666666in"} (https://atrihub.atlassian.net/browse/PIPE-40?src=confmacro)   Apr 01, 2019 08:29   Apr 04, 2019 16:50         Unassigned     **<span style="font-variant:small-caps;"> in review </span>**     Unresolved
  [PIPE-39](https://atrihub.atlassian.net/browse/PIPE-39?src=confmacro) (https://atrihub.atlassian.net/browse/PIPE-39?src=confmacro)   ![\_scroll\_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](media/image4.png){width="0.16666666666666666in" height="0.16666666666666666in"} (https://atrihub.atlassian.net/browse/PIPE-39?src=confmacro)   Mar 29, 2019 16:01   Apr 04, 2019 16:50         Rajat Khemka   **<span style="font-variant:small-caps;"> in review </span>**     Unresolved

Showing 20 out of [57
issues](https://atrihub.atlassian.net/secure/IssueNavigator.jspa?reset=true&jqlQuery=project%3DPIPE+AND+status+not+in+%28DONE%2C+RESOLVED%2C+CLOSED%29+&src=confmacro)
(https://atrihub.atlassian.net/secure/IssueNavigator.jspa?reset=true&jqlQuery=project%3DPIPE+AND+status+not+in+%28DONE%2C+RESOLVED%2C+CLOSED%29+&src=confmacro)

Meeting notes
=============

Create meeting note

Incomplete tasks from meetings
------------------------------

Task report
-----------

Looking good, no incomplete tasks.

All meeting notes
-----------------

  Title                                                                                                          Creator                                                                                                                                                                                                            Modified
  -------------------------------------------------------------------------------------------------------------- ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ --------------
  [2019-04-03 - meeting notes - internal meetup on processDCM](#meeting-notes---internal-meetup-on-processdcm)   [Hongmei Qiu](https://atrihub.atlassian.net/people/557058:0e04da62-9320-49f9-8df3-3a744f02137a?ref=confluence) (https://atrihub.atlassian.net/people/557058:0e04da62-9320-49f9-8df3-3a744f02137a?ref=confluence)   Apr 02, 2019
  [2019-02-27 meeting notes - TRC Image Pipeline](#meeting-notes---trc-image-pipeline-7)                         [Hongmei Qiu](https://atrihub.atlassian.net/people/557058:0e04da62-9320-49f9-8df3-3a744f02137a?ref=confluence) (https://atrihub.atlassian.net/people/557058:0e04da62-9320-49f9-8df3-3a744f02137a?ref=confluence)   Feb 27, 2019
  [2019-02-25 Meeting notes - TRC Image Pipeline](#meeting-notes---trc-image-pipeline-6)                         [Hongmei Qiu](https://atrihub.atlassian.net/people/557058:0e04da62-9320-49f9-8df3-3a744f02137a?ref=confluence) (https://atrihub.atlassian.net/people/557058:0e04da62-9320-49f9-8df3-3a744f02137a?ref=confluence)   Feb 25, 2019
  [2019-02-20 Meeting notes - TRC Image Pipeline](#meeting-notes---trc-image-pipeline-5)                         [Hongmei Qiu](https://atrihub.atlassian.net/people/557058:0e04da62-9320-49f9-8df3-3a744f02137a?ref=confluence) (https://atrihub.atlassian.net/people/557058:0e04da62-9320-49f9-8df3-3a744f02137a?ref=confluence)   Feb 20, 2019
  [2019-02-13 Meeting notes - TRC Image Pipeline](#meeting-notes---trc-image-pipeline-4)                         [Hongmei Qiu](https://atrihub.atlassian.net/people/557058:0e04da62-9320-49f9-8df3-3a744f02137a?ref=confluence) (https://atrihub.atlassian.net/people/557058:0e04da62-9320-49f9-8df3-3a744f02137a?ref=confluence)   Feb 13, 2019
  [2019-02-11 Meeting notes - TRC Image Pipeline](#meeting-notes---trc-image-pipeline-3)                         [Hongmei Qiu](https://atrihub.atlassian.net/people/557058:0e04da62-9320-49f9-8df3-3a744f02137a?ref=confluence) (https://atrihub.atlassian.net/people/557058:0e04da62-9320-49f9-8df3-3a744f02137a?ref=confluence)   Feb 11, 2019
  [2019-02-07 Meeting notes - TRC image pipeline](#meeting-notes---trc-image-pipeline-2)                         [Hongmei Qiu](https://atrihub.atlassian.net/people/557058:0e04da62-9320-49f9-8df3-3a744f02137a?ref=confluence) (https://atrihub.atlassian.net/people/557058:0e04da62-9320-49f9-8df3-3a744f02137a?ref=confluence)   Feb 07, 2019
  [2019-01-30 Meeting notes - TRC Image Pipeline](#meeting-notes---trc-image-pipeline-1)                         [Hongmei Qiu](https://atrihub.atlassian.net/people/557058:0e04da62-9320-49f9-8df3-3a744f02137a?ref=confluence) (https://atrihub.atlassian.net/people/557058:0e04da62-9320-49f9-8df3-3a744f02137a?ref=confluence)   Feb 05, 2019
  [2019-01-28 Meeting notes - TRC image pipeline](#meeting-notes---trc-image-pipeline)                           [Hongmei Qiu](https://atrihub.atlassian.net/people/557058:0e04da62-9320-49f9-8df3-3a744f02137a?ref=confluence) (https://atrihub.atlassian.net/people/557058:0e04da62-9320-49f9-8df3-3a744f02137a?ref=confluence)   Jan 30, 2019
  [2019-01-25 Meeting notes - Pipelines](#meeting-notes---pipelines)                                             [Hongmei Qiu](https://atrihub.atlassian.net/people/557058:0e04da62-9320-49f9-8df3-3a744f02137a?ref=confluence) (https://atrihub.atlassian.net/people/557058:0e04da62-9320-49f9-8df3-3a744f02137a?ref=confluence)   Jan 28, 2019

2019-01-25 Meeting notes - Pipelines
------------------------------------

### Date

25 Jan 2019

### Participants

-   [Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq)
    (https://atrihub.atlassian.net/wiki/display/\~hongmeiq)

-   [Pradeep
    Ravindranath](https://atrihub.atlassian.net/wiki/display/~paravindranath)
    (https://atrihub.atlassian.net/wiki/display/\~paravindranath)

-   [Stefania
    Bruschi](https://atrihub.atlassian.net/wiki/display/~bruschi)
    (https://atrihub.atlassian.net/wiki/display/\~bruschi)

-   [Gustavo
    Jimenez-Maggiora](https://atrihub.atlassian.net/wiki/display/~gustavoj)
    (https://atrihub.atlassian.net/wiki/display/\~gustavoj)

-   [Emil Lerch](https://atrihub.atlassian.net/wiki/display/~emilerch)
    (https://atrihub.atlassian.net/wiki/display/\~emilerch)

-   Heather Stratton

-   [Adam Hunter](https://atrihub.atlassian.net/wiki/display/~adamhunt)
    (https://atrihub.atlassian.net/wiki/display/\~adamhunt)

### Goals

-   Project Overview​

-   Timeline​

-   Architecture Overview ​

-   Challenges​

-   Deliverables ​

-   Collaboration – discussion​

-   Next Step – discussion​

-   ​

-   -   Slides: <https://atrihub.app.box.com/file/389348050296>
    (https://atrihub.app.box.com/file/389348050296)

### Discussion topics

  Time   Item                                                              Presenter   Notes
  ------ ----------------------------------------------------------------- ----------- ---------------------------------------------------------------
         Emil suggested use Glue to retrieve and process files in chunks               note for developers: look into this approach in phase 2
         Emil suggested SFTP                                                           <https://aws.amazon.com/sftp/> (https://aws.amazon.com/sftp/)
         vzip/ Snappy                                                                  
         Large file upload GUI                                                         JS components, multi-part upload

### Action items

-   [Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq)
    > (https://atrihub.atlassian.net/wiki/display/\~hongmeiq) create IAM
    > readonly account for Emil on sandbox

-   [Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq)
    > (https://atrihub.atlassian.net/wiki/display/\~hongmeiq) share
    > sample phantom files with Emil

-   [Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq)
    > (https://atrihub.atlassian.net/wiki/display/\~hongmeiq) send out
    > doodle poll for weekly touch base meetings

-   [Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq)
    > (https://atrihub.atlassian.net/wiki/display/\~hongmeiq) create
    > slack space and invite Emil to it

-   [Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq)
    > (https://atrihub.atlassian.net/wiki/display/\~hongmeiq) share Emil
    > Github repo with lambda code

### Decisions

2019-01-28 Meeting notes - TRC image pipeline
---------------------------------------------

### Date

28 Jan 2019

### Participants

-   [Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq)
    (https://atrihub.atlassian.net/wiki/display/\~hongmeiq)

-   [Emil Lerch](https://atrihub.atlassian.net/wiki/display/~emilerch)
    (https://atrihub.atlassian.net/wiki/display/\~emilerch)

-   [Pradeep
    Ravindranath](https://atrihub.atlassian.net/wiki/display/~paravindranath)
    (https://atrihub.atlassian.net/wiki/display/\~paravindranath)

-   Tom Christensen

### Goals

-   Meeting recording: <https://atrihub.app.box.com/folder/65237095772>
    (https://atrihub.app.box.com/folder/65237095772)

### Discussion topics

  --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  Time   Item                                                                                                          Presenter   Notes
  ------ ------------------------------------------------------------------------------------------------------------- ----------- -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
                                                                                                                                   -   

         AWS Batch: Job Role IAM for S3 access                                                                                     solved: create a role with s3 access policy → ecstatics → Tasks (<https://aws.amazon.com/blogs/compute/creating-a-simple-fetch-and-run-aws-batch-job/> (https://aws.amazon.com/blogs/compute/creating-a-simple-fetch-and-run-aws-batch-job/))

         AWS Batch: environment, queue, definition - should we create them through lambda or feed them as parameters               (Emil) feed them. Do not create them in lambda - no benefit, longer

         What does multi-node configuration do                                                                                     for array jobs. For jobs that requires to run parallel execution.

         What are node properties? Can we use it to by pass docker container for execution                                         node ami is just to run ecstatics and docker container. Docker container can be used to work with node ami only at kernel level.
                                                                                                                                   
                                                                                                                                   Cannot bypass container. for running and scaling only with AMIs use SQS → scale ec2. This is required when more control is required.

         Debug RUNNABLE state is batch.                                                                                            Can be done ssh’ing into a single node running job instance, and checking the ecstatics agent.
                                                                                                                                   
                                                                                                                                   ECS agent can be customized to write docker logs. Have to create our own log driver

         What happens when we kill the ecs spun instance                                                                           Exact relation not known. waits and runs the available/next available tasks.

         VPC and subnets.                                                                                                          Public VPC and public subnets in private VPC works.
                                                                                                                                   
                                                                                                                                   private subnets keep the jobs in runnable state.
                                                                                                                                   
                                                                                                                                   (emil) create an endpoint letting ec2 access to ecs - not working (have to check again recreating the ecs cluster - probably it had old configurations)

         custom AMI                                                                                                                have to include ecstatics agent.
  --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

### Action items

-    

### Decisions

2019-01-30 Meeting notes - TRC Image Pipeline
---------------------------------------------

### Date

30 Jan 2019

### Participants

-   [Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq)
    (https://atrihub.atlassian.net/wiki/display/\~hongmeiq)

-   [Pradeep
    Ravindranath](https://atrihub.atlassian.net/wiki/display/~paravindranath)
    (https://atrihub.atlassian.net/wiki/display/\~paravindranath)

-   [Emil Lerch](https://atrihub.atlassian.net/wiki/display/~emilerch)
    (https://atrihub.atlassian.net/wiki/display/\~emilerch)

-   Tom Christensen

### Goals

-   Meeting recording:
    <https://atrihub.box.com/s/efczd3bqe0n49osxochwfwzc3aivp4s0>
    (https://atrihub.box.com/s/efczd3bqe0n49osxochwfwzc3aivp4s0)

### Discussion topics - next meeting

-   Show status - demo

    -   Best practice: where to store batch configuration variables
        (e.g. computing environment job queue and job definition)

        -   **Emil suggestion:**

            -   token: parameter store

            -   db password: secret manager

            -   for variables pass to next lambda function, e.g.
                computing environment, just definite those variables in
                each lambda function (so those info won’t be go through
                function call via network)

    -   1 study portal per step function + 1st lambda function

    -   store configurations in 1st lambda function

    -   Any concerns on: passing API token through lambda to batch job
        as an update to job definition?

-   batch

    -   passing parameters to batch

        -   override job definition is ok for same type of pipeline

    -   best practice to update batch job submission

        -   e.g. file path, file name different for each s3 object that
            triggers the job run

    -   batch error output to step function

        -   cloudwatch logs, error text (grabs from log stream)

            -   what goes into cloudwatch logs? stdout and stderr …

        -   aws batch return code makes its way back to step functionalt

        -   alternatives: s3 log, cloudwatch insights (still needs to
            split stdout and stderr)

        -   Emil recommended:~~mime approach, modify ecs agent to write
            to separate logs (won’t work for our case)~~

            -   ecs environment variable: which log streams

            -   error → s3 → cloudwatch log streams

            -   **todo: Emil share your example code with us**

    -   How to raise errors to next step function from batch (repeated
        from last question)

        -   best practice - combine step 2 (process image) and step 3
            (write metadata)? other options

            -   modify ECS agent

-   Templates/scripts: log the cost and duration matrix (Emil)

    -   **TBD**

-   Lambda CI/CD (serverless repository)

    -   Emil look into seamless flow:

        -   **TODO: share link jetbridge (through slack)**

    -   restrictions:

        -   total amount of code (layer will count toward it)

        -   space (/tmp, /opt)

-   Bastion Host: [Setup Bastion Host to SSH into EC2
    instances](https://atrihub.atlassian.net/wiki/spaces/APST2/pages/722272320/Setup+Bastion+Host+to+SSH+into+EC2+instances)
    (https://atrihub.atlassian.net/wiki/spaces/APST2/pages/722272320/Setup+Bastion+Host+to+SSH+into+EC2+instances)

-   AWS batch computing environments VPC with private subnet NAT creates
    issue

    -   TBD: push this back to March

### Action items

-    

### Decisions

2019-02-07 Meeting notes - TRC image pipeline
---------------------------------------------

### Date

07 Feb 2019

### Participants

-   [Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq)
    (https://atrihub.atlassian.net/wiki/display/\~hongmeiq)

-   [Pradeep
    Ravindranath](https://atrihub.atlassian.net/wiki/display/~paravindranath)
    (https://atrihub.atlassian.net/wiki/display/\~paravindranath)

-   [Emil Lerch](https://atrihub.atlassian.net/wiki/display/~emilerch)
    (https://atrihub.atlassian.net/wiki/display/\~emilerch)

### Goals

-   Lambda

    -   lambda layer

    -   Lambda CI/CD

        -   serverless repository approach (TODO: Emil will look into
            this later)

            -   private

        -   test lambda functions

            -   step function local (they have a docker) - java
                application

                <https://docs.aws.amazon.com/step-functions/latest/dg/sfn-local.html>
                (https://docs.aws.amazon.com/step-functions/latest/dg/sfn-local.html)

        -   AWS Vault - for credentials

            -   <https://github.com/99designs/aws-vault>
                (https://github.com/99designs/aws-vault)

-   cost and performance

    -   status:

        -   cost and duration scripts (lambda, batch, etc.) (TODO: Emil
            will look into this later)

        -   ecs agents (github fork) - stream script/container specific
            logs to CloudWatch - Emil: too overkill - just split the
            streams in our script into different s3 logs

            -   mime objects - multi-part

            -   s3 logs

            -   TODO: Emil will provide reference links to ecs agents
                fork (public github) just for future reference (looking
                for older version)

                -   <https://github.com/elerch/amazon-ecs-agent/tree/proxy_container>
                    (https://github.com/elerch/amazon-ecs-agent/tree/proxy\_container)

-   Pipeline CI/CD (CloudFormation)

    -   bring everything together: step function, lambda, batch, docker

-   Security (move this item to next meeting)

    -   Batch VPC private subnet with NAT - investigation (if time
        permits)

-   Emil feedback on build and push script for docker

    -   <https://github.com/atrihub/AWS-Deployment/issues/48>
        (https://github.com/atrihub/AWS-Deployment/issues/48)

### Discussion topics

  Time   Item   Presenter   Notes
  ------ ------ ----------- -------
                            -   
                            

### Action items

-    

### Decisions

2019-02-11 Meeting notes - TRC Image Pipeline
---------------------------------------------

### Date

11 Feb 2019

### Participants

-   [Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq)
    (https://atrihub.atlassian.net/wiki/display/\~hongmeiq)

-   [Emil Lerch](https://atrihub.atlassian.net/wiki/display/~emilerch)
    (https://atrihub.atlassian.net/wiki/display/\~emilerch)

-   [Mihir
    Kavatkar](https://atrihub.atlassian.net/wiki/display/~kavatkar)
    (https://atrihub.atlassian.net/wiki/display/\~kavatkar)

### Goals

-   file upload: aws sdk file upload

    -   GUI → API → django → boto3

    -   aws SDK - how to setup so the file can be uploaded directly to
        s3, and the hand off (key etc) is secure and light weight

-   can CloudTrail trigger on dynamic s3 prefix?

-   CloudTrail triggered step function, can job execution name be
    configured?

-   Batch job runs in separate environments?

-   Batch job runnable status

    -   what caused this?

    -   related to configuration?

-   Step function: Wait30Seconds

    -   stopping point

-   [Setup TRC Image Pipeline](#setup-a-new-image-pipeline)

-   logs: which is easier to parse through

    -   cloudwatch - metric filter (recommended)

    -   s3

### Discussion topics

  Time   Item   Presenter   Notes
  ------ ------ ----------- -------
                            -   
                            

### Action items

-    

### Decisions

2019-02-13 Meeting notes - TRC Image Pipeline
---------------------------------------------

### Date

13 Feb 2019

### Participants

-   [Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq)
    (https://atrihub.atlassian.net/wiki/display/\~hongmeiq)

-   [Emil Lerch](https://atrihub.atlassian.net/wiki/display/~emilerch)
    (https://atrihub.atlassian.net/wiki/display/\~emilerch)

-   [Mihir
    Kavatkar](https://atrihub.atlassian.net/wiki/display/~kavatkar)
    (https://atrihub.atlassian.net/wiki/display/\~kavatkar)

### Goals

-   [EDC File Upload Improvements](#edc-file-upload-improvements)
    (timeline for this pushed to Q2/Q3)

-   Runbook:

    -   <https://atrihub.app.box.com/file/399829398942>
        (https://atrihub.app.box.com/file/399829398942)

-   Batch Compute Environment: switch to private subnet with NAT

    -   <https://aws.amazon.com/security/security-bulletins/AWS-2019-002/>
        (https://aws.amazon.com/security/security-bulletins/AWS-2019-002/)

-   MIME multi-part generation and parsing (overkill)

    -   <https://github.com/broadinstitute/cromwell/blob/958411830ff100b705e27e0a4f2f09c86e02c705/supportedBackends/aws/src/main/scala/cromwell/backend/impl/aws/AwsBatchJob.scala>
        (https://github.com/broadinstitute/cromwell/blob/958411830ff100b705e27e0a4f2f09c86e02c705/supportedBackends/aws/src/main/scala/cromwell/backend/impl/aws/AwsBatchJob.scala)

curl/default/bab9ebde-71a6-4a27-8d6e-0092e39c3140\
\^\^\^ \^\^\^\^ \^\^\^\^\
| | ECS Task ID\
| ECS container name\
|\
|\
job definitioncurl -s \$ECS\_CONTAINER\_METADATA\_URI; env{\
"DockerId":
"dcc704d12b1dee27cf3d0ddc78d7a8ed6cb5bf09cc8e254d806928a71a5055e6",\
"Name": "default",\
"DockerName": "ecs-curl-1-default-a6f8d3ab8c8b8281e301",\
"Image": "appropriate/curl",\
"ImageID":
"sha256:d37e1f717dc01df3a838955d29a149c569352c0991b1d7cf11b4ebca8c6c7f55",\
"Labels": {\
"com.amazonaws.ecs.cluster":
"optimal\_Batch\_320ef3e9-690b-3be6-9009-62700d07ea28",\
"com.amazonaws.ecs.container-name": "default",\
"com.amazonaws.ecs.task-arn":
"arn:aws:ecs:us-east-2:931443760666:task/bab9ebde-71a6-4a27-8d6e-0092e39c3140",\
"com.amazonaws.ecs.task-definition-family": "curl",\
"com.amazonaws.ecs.task-definition-version": "1"\
},\
"DesiredStatus": "RUNNING",\
"KnownStatus": "RUNNING",\
"Limits": {\
"CPU": 1024,\
"Memory": 128\
},\
"CreatedAt": "2019-02-13T21:34:24.353330197Z",\
"StartedAt": "2019-02-13T21:34:24.834316277Z",\
"Type": "NORMAL"\
}SHLVL=2\
HOME=/root\
AWS\_CONTAINER\_CREDENTIALS\_RELATIVE\_URI=/v2/credentials/db4f5274-24e8-4fa4-ac51-2282a2286998\
AWS\_EXECUTION\_ENV=AWS\_ECS\_EC2\
AWS\_BATCH\_JOB\_ID=2c517fa4-e5cd-4e8d-90b3-0fd7efcb24f5\
AWS\_BATCH\_JQ\_NAME=optimal\
ECS\_CONTAINER\_METADATA\_URI=<http://169.254.170.2/v3/f3bf3225-88ea-4de2-a195-f285d1af1b41>
(http://169.254.170.2/v3/f3bf3225-88ea-4de2-a195-f285d1af1b41)\
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\
AWS\_BATCH\_JOB\_ATTEMPT=1\
PWD=/\
AWS\_BATCH\_CE\_NAME=optimal

### Discussion topics

  Time   Item   Presenter   Notes
  ------ ------ ----------- -------
                            -   
                            

### Action items

-    

### Decisions

2019-02-20 Meeting notes - TRC Image Pipeline
---------------------------------------------

### Date

20 Feb 2019

### Participants

-   [Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq)
    (https://atrihub.atlassian.net/wiki/display/\~hongmeiq)

-   [Emil Lerch](https://atrihub.atlassian.net/wiki/display/~emilerch)
    (https://atrihub.atlassian.net/wiki/display/\~emilerch)

-   [Mihir
    Kavatkar](https://atrihub.atlassian.net/wiki/display/~kavatkar)
    (https://atrihub.atlassian.net/wiki/display/\~kavatkar)

### Goals

-   cost report

    -   study

    -   service

    -   step/lambda

-   encryption/HIPAA

    -   revisit KMS key management (re-cycle, DR)

    -   Batch computing environment

        -   <https://aws.amazon.com/about-aws/whats-new/2017/09/aws-batch-is-now-a-hipaa-eligible-service/>
            (https://aws.amazon.com/about-aws/whats-new/2017/09/aws-batch-is-now-a-hipaa-eligible-service/)

    -   Step Function + Lambda

-   CloudFormation, CI/CD - best practices

    -   1 per study image pipeline? or

    -   1 per section?

    -   walk through
        [runbook](https://atrihub.app.box.com/file/399829398942)
        (https://atrihub.app.box.com/file/399829398942), and identify
        what can be automated?

-   Test - step functions/lambda

    -   Github → Travis CI

    -   Github → CodePipeline/CodeBuild

### Discussion topics

  Time   Item   Presenter   Notes
  ------ ------ ----------- -------
                            -   
                            

### Action items

-    

### Decisions

2019-02-25 Meeting notes - TRC Image Pipeline
---------------------------------------------

Attendees

-   [Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq)
    (https://atrihub.atlassian.net/wiki/display/\~hongmeiq)

-   [Mihir
    Kavatkar](https://atrihub.atlassian.net/wiki/display/~kavatkar)
    (https://atrihub.atlassian.net/wiki/display/\~kavatkar)

-   [Emil Lerch](https://atrihub.atlassian.net/wiki/display/~emilerch)
    (https://atrihub.atlassian.net/wiki/display/\~emilerch)

Agenda

CloudFormation

-   Step function execution name: how to customize?

-   Emil was pointing to the linux version used in the batch compute
    environment to test the private VPC in batch. We are currently using
    the managed amazon AMI. In order to do what Emil suggested I think
    we would need to create a custom AMI to run the docker image.

-   CloudTrail was suggested here:

    -   <https://docs.aws.amazon.com/step-functions/latest/dg/tutorial-cloudwatch-events-s3.html>
        (https://docs.aws.amazon.com/step-functions/latest/dg/tutorial-cloudwatch-events-s3.html)

-   S3 vs CloudWatch → both triggers lambda function

    -   Q: when is it useful to trigger step function directly?

    -   Q: S3 vs CloudWatch for logs?

-   Lambda trigger function → step function, example?

-   add tag to IAM role, not supported in CloudFormation?

    -   solution currently used: aws cli

    -   CloudFormation source tag:
        <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-resource-tags.html>
        (https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-resource-tags.html)

-   An error occurred (ValidationError) when calling the UpdateStack
    operation: No updates are to be performed.

    -   how to detect that?

-   CloudFormation drift status

2019-02-27 meeting notes - TRC Image Pipeline
---------------------------------------------

-   Compute Environment: use m3.medium/m5.large instead of optimal,
    consulted with Emil regarding our use case

-   lambda testing locally - docker container (Github)

    -   without the 15 min timeout

    -   load lambda through ECR - step functions (ECS cluster, docker
        container) → get ECS output with location to CloudWatch log →
        checkout outputs in the CloudWatch logs

2019-04-03 - meeting notes - internal meetup on processDCM
----------------------------------------------------------

### Date

02 Apr 2019

### Participants

-   [Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq)
    (https://atrihub.atlassian.net/wiki/display/\~hongmeiq)

-   [Pradeep
    Ravindranath](https://atrihub.atlassian.net/wiki/display/~paravindranath)
    (https://atrihub.atlassian.net/wiki/display/\~paravindranath)

-   [Rajat Khemka](https://atrihub.atlassian.net/wiki/display/~rkhemka)
    (https://atrihub.atlassian.net/wiki/display/\~rkhemka)

### Goals

-   Travis CI

-   drop error\_log api call, replace with proper print statement

-   introduce ErrorMessage class with error codes: [Pipeline
    Dictionary](#pipeline-dictionary)

### Discussion topics

  Time   Item   Presenter   Notes
  ------ ------ ----------- -------
                            -   
                            

### Action items

-    

### Decisions

Product requirements
====================

Create product requirement

  Title
  -------------------
  No content found.

Image Pipeline
--------------

  Status         **<span style="font-variant:small-caps;"> not started </span>**
  -------------- -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  Impact         **<span style="font-variant:small-caps;"> low </span>**
  Driver         [Stefania Bruschi](https://atrihub.atlassian.net/wiki/display/~bruschi) (https://atrihub.atlassian.net/wiki/display/\~bruschi), [Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq) (https://atrihub.atlassian.net/wiki/display/\~hongmeiq) 
  Approver       [Gustavo Jimenez-Maggiora](https://atrihub.atlassian.net/wiki/display/~gustavoj) (https://atrihub.atlassian.net/wiki/display/\~gustavoj)
  Contributors   [Stefania Bruschi](https://atrihub.atlassian.net/wiki/display/~bruschi) (https://atrihub.atlassian.net/wiki/display/\~bruschi), [Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq) (https://atrihub.atlassian.net/wiki/display/\~hongmeiq), [Jia-Shing So](https://atrihub.atlassian.net/wiki/display/~jiashins) (https://atrihub.atlassian.net/wiki/display/\~jiashins)
  Informed       [Pradeep Ravindranath](https://atrihub.atlassian.net/wiki/display/~paravindranath) (https://atrihub.atlassian.net/wiki/display/\~paravindranath)
  Due date       18 Jan 2019 
  Outcome        

note: subject and participant are interchangeable, Record ID =
subjecteventcrf.id, upload form name = ddcrf.name, upload field name =
ddfile.name

### Background

#### Objective

Design and create a pipeline that synchronizes image files between two
s3 buckets: EDC source bucket and image bucket.  Notify all stakeholders
when new image files are available in the image bucket 'quarantine'
folder.  Track the transaction logs in the EDC database.

The pipeline should be triggered manually on a specific file or set of
files.

##### EDC source bucket

Image file are uploaded by the EDC system users via the file uploader
widget and stored in the EDC source bucket.

-   bucket name: atri-edc-trc-production-*\[aws account ID\]*

-   source folder: subjecteventcrffile

-   file path:
    subjecteventcrffile/*\[subject.id\]*/*\[subjecteventcrf.id\]*/*\[ddfile.name\]*/

-   file name:  file version code + file extension

##### Image destination bucket

Image files in the destination bucket will be made available to
collaborators (e.g. labs) for further process.

-   bucket name: atri-edc-trc-production-img-*\[aws account ID\]*

-   destination folder: quarantine

-   file path: quarantine/\[ddcrf.name\]\[ddfile.name\]/

-   file name: \[ddcrf.name\]\_\[ddfile.name\]\_\[participant
    code\]\_\[event
    code\]\_\[subjecteventcrf.id\]\_\[subjecteventcrffile.revisionnumber\]\_\[edcpipelinefile.id\]\_\[timestamp\] +
    file extension

    -   note: strip out any whitespace

    -    timestamp

        -   Q: timestamp when file is uploaded to source bucket?
            destination bucket?

            -   when the file is first uploaded into the quarantine
                folder (edcpipelinefile.ts\_create)

        -   format: YYYYMMDD\_HHMMSS

### Brainstorming

#### Design

##### Flow

![\_scroll\_external/attachments/trc-image-pipeline-flow-1-xml-6557bfc18fddcd31215d3cf324071051a3b47ed5985c658059a2c018ee301716.png](media/image5.png){width="4.677083333333333in"
height="2.40625in"}

**Q: should we suggest to add an unquarantine folder? to keep quarantine
as read only for users? (depends on whether the SFTP wrapper can handle
folder level permissions)**

##### Track

Track the following information in the EDC database:

-   subjecteventcrffile.id

-   filepath - file path in the destination s3 bucket

-   filename - file name in the destination s3 bucket

-   FileID - unqiue ID for each image file transferred to the
    destination folder

    -   **Q: can we use SubjectEventCrfFile.id as the FileID?**

-   studyUID**: **DICOM HEADER  (0020,000D) Unique identifier for the
    Study.

-   serieUID**:** DICOM HEADER  (0020,000E) Unique identifier of the
    Series.

-   serienum**: **DICOM HEADER (0020,0011) A number that identifies this
    Series.

-   ScanID - a unique combination of studyUID and serieUID for each
    fileID

-   ATRIUID - Uniqeue ID store in DICOM header to identify the image
    set: \[fileID\].\[scanID\]

Track the following information in a log file (s3 bucket - **where?**):

-   execution error

-   execution result

##### Notification

###### Type of users

-   pipeline user: labs who reviews and process the image files when
    they are available in the quarantine folder

-   admin user: developers of the image pipeline

###### Type of notifications

-   for pipeline users: a digest report runs \[nightly|configurable
    schedule\]

    -   create a mailing list: <trc-images-l@atrihub.io>
        (mailto:trc-images-l@atrihub.io)

    -   report includes a list of new files made available to the
        quarantine folder

    -   report includes count of new files, count of files failed to be
        transferred/processed

-   for admin users: error logs (immediately after execution), success
    logs (**immediately? on a schedule?**)

    -   create a mailing list: <trc-images-admin-l@atrihub.io>
        (mailto:trc-images-admin-l@atrihub.io)

-   Q: do people need to be notified when new files uploaded to the
    quarantine folder?

#### Implementation

##### (AWS) EDC RDS read replica

-   Create a read only replica for the EDC database, so the pipeline can
    find subject, crf information during the transfer

    -   **Q: what's the delay between real database and the replica?
        (trigger wait time depends on this response)**

##### Database

File information tracked in the database tables.

###### Pipeline.EDCPipeline 

register each pipeline (e.g. pipeline for image file, pipeline for audio
files, etc.

  Field     
  --------- --
  ID        
  Code      
  Label     
  DDFiles   

###### pipeline.EDCPipelineFile

  Field Name               
  ------------------------ -----------------------------------------
  ID                       
  EDCPipeline.id           
  SubjectEventCrfFile.id   
  file\_name               
  Status                   Started, In Progress, Completed, Failed
  has\_error               T/F

[]{#scroll-bookmark-93 .anchor}~~\
~~

###### pipeline.EDCPipelineFileDicom

  Field Name
  -----------------------
  ID
  EDCPipelineFile.id
  ATRIUID
  studyUID
  serieUID
  serienum
  number\_of\_instances

##### API

/pipeline/edcpipeline/file

  ---------------------------------------------------------------------
  > input:
  >
  > {
  >
  > pipeline\_code: xxx
  >
  > subject\_event\_crf\_file\_id: xxx
  >
  > \*edc\_pipieline\_file\_id: xxx (required **for** update)
  >
  > }
  >
  >  
  >
  > output:
  >
  > {
  >
  > success: T/F
  >
  > error\_code: reference dictionary (only show **if** success is F)
  >
  > error: xxxx (only show **if** success is F)
  >
  > data: {"edc\_pipeline\_file: object}
  >
  > }
  ---------------------------------------------------------------------

/pipeline/edcpipeline/file/dicom/add\_scan\_info

-   post

    -   request body (json)

  -----------------------------------------------------------------------------
  > input:
  >
  > {
  >
  > pipeline\_code: xxx,
  >
  > subject\_event\_crf\_file\_id: xxx,
  >
  > edc\_pipieline\_file\_id: xxxx
  >
  > scans:\[
  >
  > {
  >
  > study\_uid: xxx,
  >
  > series: \[
  >
  > {series\_uid: xxx, series\_number: yyy, number\_of\_instance: 123},
  >
  > {series\_uid: blah, series\_number: halb, number\_of\_instance: 123},
  >
  > ...
  >
  > \]
  >
  > },
  >
  > {
  >
  > study\_uid: xxx,
  >
  > series: \[
  >
  > {series\_uid: xxx, series\_number: yyy, number\_of\_instance: 123},
  >
  > {series\_uid: blah, series\_number: halb, number\_of\_instance: 123}, ...
  >
  > \]
  >
  > }
  >
  > }
  -----------------------------------------------------------------------------

  -----------------------------------------------------------------------
  > output:
  >
  > {
  >
  > "success": **true**,
  >
  > "error\_code": reference dictionary (only show **if** success is F)
  >
  > "error": xxxx (only show **if** success is F)
  >
  > "data":
  >
  > {
  >
  > edc\_pipeline\_file\_id: 123,
  >
  > pipeline\_code: xxx,
  >
  > subject\_event\_crf\_file\_id: xxx,
  >
  > scans: \[
  >
  > {
  >
  > "study\_uid": xxx,
  >
  > "series": \[
  >
  > {"series\_uid": aaa, "atri\_uid": yyy},
  >
  > {"series\_uid": aaa, "atri\_uid": ddd},
  >
  > ...
  >
  > \]
  >
  > },
  >
  > {
  >
  > "studyuid": xxx,
  >
  > "series": \[
  >
  > {"series\_uid": aaa, "atri\_uid": yyy},
  >
  > {"series\_uid": aaa, "atri\_uid": ddd},
  >
  > }
  >
  > \]
  >
  > }
  >
  > }
  -----------------------------------------------------------------------

##### Mailing List

Study specific

-   <trc-images-l@atrihub.io> (mailto:trc-images-l@atrihub.io) - for
    users (e.g. labs)

-   <trc-images-admin-l@atrihub.io>
    (mailto:trc-images-admin-l@atrihub.io) - for admins

##### (AWS) S3 bucket - temporary

-   create a temporary s3 bucket used by the step function for file
    processing

-   bucket name: atri-edc-trc-production-img-tmp-\[AWS account ID\]

##### (AWS) Step Function

-   triggered when a new file is uploaded / updated in S3 source bucket
    folder "subjecteventcrffile"

-   Job name convention:
    \[subject.id\]\_\[subjecteventcrf.id\]\_\[ddfile.name\]\_\[file
    version code\]\_\[timestamp\]

![\_scroll\_external/attachments/screen-shot-2019-01-17-at-1-41-22-pm-e5866d37b3ac0070e2c2f10ca07f196d36a9f281b145357fd331e2b2f3f14e51.png](media/image6.png){width="2.8678794838145234in"
height="2.6041666666666665in"}

##### (AWS) Lambda Function

-   QUERY READ REPLICA:

    -   L1 - query file info from the read replica

        -   input: file path and file name from source bucket

        -   output: file metadata json

            -   if file is found

                -   ddcrf.name

                -   ddfile.name

                -   participant code

                -   event code

                -   subjecteventcrf.id

                -   subjecteventcrffile.revisionnumber

                -   subjecteventcrffile.id

                -   pipeline\_code

            -   if file is not found

                -   return ERROR

        -   step fn - retry function, checks return status of L1 (expect
            raised ERROR and try for max attempt)

        -   duration:15 minutes

        -   frequency: every 30 sec

-   Process DCM:

    -   **Notes:**

        -   All the following functions process the same file.

        -   Size may be a restriction for lambda.

        -   AWS batch can an be an alternate solution.

    -   L5 - parse file and extract the DICOM header

        -   input: file path and name

        -   output: DICOM header info for each scan (list)

            -   studyUID

            -   serieUID

            -   serienum

    -   L7 - write ATRIUID in DICOM header

    -   L4 - copy processed file from s3 source bucket to s3 temp
        bucket, rename the file

        -   input:

            -   source file path and name

            -   target file path and name

        -   output: successful (True/False)

-   ADDITIONAL PROCESS:

    -   L8 - additional process (such as LONI process)

-   WRITE META DATA:

    -   L6 - call API to write file metadata in study DB (set file
        status to "in progress")

        -   input: L1 and L5 output

        -   output: successful (True/False)

-   COPY TO DESTINATION:

    -   L9 - copy file from S3 temp bucket to S3 destination bucket

        -   input:

            -   s3 temp bucket

            -   s3 destination bucket

            -   file path

            -   file name

        -   output: successful (True/False)

-   UPDATE STATUS:

    -   L10 - call API to update file status in study DB to "done"

-   ErrorSNS

    -   L3 - email/log error for Admin

        -   input: error

        -   output: "status : error"

-   PROCESS COMPLETION SNS:

    -   L11 - email / log to Admin on summary or error

        -   if error: call API to update file status in study DB to
            "error"

        -   input: status

        -   output: successful (True/False)

-   USER DIGEST (This has to be post pipeline processing - separate
    Lambda not part of this step fn):

    -   L12 - (user digest) send batch summary to users 

        -   input: duration (last 24 hours etc.)

        -   output: successful (True/False)

##### (AWS) BatchEDCAWS-93

![\_scroll\_external/attachments/aws-batch-plan-xml-0ba6ff367a31e23af50a853fdd3b8314639f33723e69fe5bcd00f69a99323ae9.png](media/image7.png){width="5.833333333333333in"
height="6.583333333333333in"}

#### Error Logs

Pipeline errors will be logged in the S3 bucket

-   bucket name: atri-edc-trc-production-*\[aws account ID\]*

-   source folder: image\_pipelines

-   file path: image\_pipelines/error\_logs/\[edcpipeline.code\]/

-   file name: (matching closely with destination file name under
    quarantined folder)

    -   \[[ddcrf.name](http://ddcrf.name)
        (http://ddcrf.name)\]\_\[[ddfile.name](http://ddfile.name)
        (http://ddfile.name)\]\_\[participant code\]\_\[event
        code\]\_\[[subjecteventcrf.id](http://subjecteventcrf.id)
        (http://subjecteventcrf.id)\]\_\[subjecteventcrffile.revisionnumber\]\_\[[edcpipelinefile.id](http://edcpipelinefile.id)
        (http://edcpipelinefile.id)\]\_\[timestamp\]\_error\_log.txt

##### Error Flags in the Database

scenario 1: edcpipelinefile.status = completed, but
edcpipelinefile.has\_error = True

-   File is processed and is available in destination bucket quarantined
    folder, but some errors were generated during the process

    -   e.g. can't insert ATRIUID into the DICOM header etc.

scenario 2: edcpipelinefile.status = Failed

-   File is not available in the destination bucket quarantined folder,
    something more seriously wrong during the process

##### Error Codes and their meaning

Please refer to [Pipeline Dictionary](#pipeline-dictionary)

Q: should I promote error code to database table column? e.g.
edcpipelinefileerrorlog.error\_code

##### Error Notification Email

![\_scroll\_external/attachments/image2019-3-22\_0-29-26-3ea3e3f56b0b6afecd73ab5072b10bd1436be055e6ec637b98ffb29afb2d8efd.png](media/image8.png){width="5.9006944444444445in"
height="4.06590113735783in"}

### Relevant Data

#### ATRIUID / Batch script logic

![\_scroll\_external/attachments/img\_1369-1b6ac829ae406f5edc8a2dabbe4c7af5b39d225505079f7ddb12ee3d7cdb86ed.jpg](media/image9.jpeg){width="5.555555555555555in"
height="4.166666666666667in"}

#### Brainstorming Drawing Board

![\_scroll\_external/attachments/img\_1352-ac757a28186678e45fa0a20eef72449af4d66b0bfaf4b51c02dae2c209429c74.jpg](media/image10.jpeg){width="5.555555555555555in"
height="4.166666666666667in"}

[IMG\_6233.HEIC](#image-pipeline)

#### TRC Amyloid PET Scan & Data Flow

[TRC\_PET\_Data\_Flow.pdf](#image-pipeline)

### Pipeline Dictionary

#### Function List

  code   description                     lambda function                              script
  ------ ------------------------------- -------------------------------------------- ---------------
  L1     Lambda                          \\\[study portal name\]-imgpipe-query-info   
  L2     Lambda                          imgpipe-submit-batch-job                     
  S1     script processing image files                                                processDMC.py
  L3     Lambda                          imgpipe-get-batch-job-status                 
  L4     Lambda                          imgpipe-copy-to-destination                  
  L5     Lambda                          imgpipe-update-pipeline-status               
  L6     Lambda                          imgpipe-notification-process-error           
  L7     Lambda                          imgpipe-notification-process-completion      
  L8     Lambda                          img-pipe-create-pipeline-job                 
  L9     Lambda                          img-pipe-invoke-step-function                

#### Error List

  code       meaning                                                                                                                    
  ---------- -------------------------------------------------------------------------------------------------------------------------- --
  ERRL1001   Missing expected input                                                                                                     
  ERRL1002   Failed to create db connection                                                                                             
  ERRL1003   EDC record not found                                                                                                       
  ERRL1004   Failed to query EDC record                                                                                                 
  ERRL2001   Error submitting Batch Job.                                                                                                
  ERRL2002   missing required input                                                                                                     
  ERRS1001   Missing expected input parameter.                                                                                          
  ERRS1002   Failed to read DICOM file.                                                                                                 
  ERRS1003   Return subject\_event\_crf\_file\_id / pipeline\_code{} subject\_event\_crf\_file\_id / pipeline\_code {} does not match   
  ERRS1004   Failed to call API                                                                                                         
  ERRS1005   API returned failed response.                                                                                              
  ERRS1006   ATRIUID is empty string in the api response.                                                                               
  ERRS1007   ATRIUID key not present in the api response for study\_uid {} and series\_uid {}.                                          
  ERRS1008   ATRUID insert failed for image with study\_uid {} and series\_uid {}.                                                      
  ERRS1009   Failed to read DICOM file during ATRIUID insert for study\_uid {0} and series\_uid {1}                                     
  ERRS1010   Invalid input folder location.                                                                                             
  ERRS1011   Input files missing in input folder                                                                                        
  ERRL3001                                                                                                                              
  ERRL4001   Missing required input                                                                                                     
  ERRL4002   Error copy file to destination                                                                                             
  ERRL4003   API call failed                                                                                                            
  ERRL8001   Failed to call API                                                                                                         

### Image Pipeline File Transfer Methods

Compare methods for external ATRI collaborators to transfer files to and
from ATRI hosted s3 buckets.

                      CyberDuck/Mountain Duck           Commander One                     Transfer SFTP
  ------------------- --------------------------------- --------------------------------- -------------------
  authentication      AWS access key + AWS secret key   AWS access key + AWS secret key   username/password
  security            client-side encryption                                              
  connection          HTTPS                                                               
  price               OpenSource/Free software                                            
  logs                s3 logs                           s3 logs                           
  usability           client                            client                            
  platform            macOS, Windows                    mac only                          
  setup/maintenance                                                                       

Notes:

Direct connection to S3 method:  s3:ListAllMyBuckets  (listing all
buckets or access denied error) 

### Image Pipeline Process Flow Diagram - High Level

![\_scroll\_external/attachments/image\_pipeline\_flow-drawio-6c6b3f4d344a46be0f49759aa8bc1cec20c36781692bd4622a303df6f54393df.png](media/image11.png){width="5.114583333333333in"
height="6.78125in"}

### Image Pipeline Components and Resources

#### EDC Plugin

##### Resources

-   EDC\_config: <https://github.com/atrihub/EDC_config>
    (https://github.com/atrihub/EDC\_config)

    -   EDC\_IMAGE\_PIPELINE\_PLUGIN: flat to turn on and off plugin in
        EDC

-   EDC: <https://github.com/atrihub/EDC>
    (https://github.com/atrihub/EDC)

    -   settings: EDC\_IMAGE\_PIPELINE\_PLUGIN

    -   authcore: image\_pipeline\_aws\_integration group

    -   account management: authentication sync tool - (note: take it
        out in Phase I)

-   edc-image-pipeline:
    [https://github.com/atrihub/edc-plugin-image-pipeline](https://github.com/atrihub/edc-image-pipeline)
    (https://github.com/atrihub/edc-image-pipeline)

    -   image pipeline models, APIs etc.

-   S3 buckets:

    -   atri-edc-plugins-github-deployment

        -   edc-plugin-image-pipeline

            -   batch

            -   docker

            -   lambda

    -   atri-edc-logs

#### Pipeline Architecture

##### Resources

-   AWS-Deployment: <https://github.com/atrihub/AWS-Deployment>
    (https://github.com/atrihub/AWS-Deployment)

    -   Pipeline architecture

        -   Lambda function code

        -   Stepfunction configuration

        -   Image file processing

        -   Triggers

        -   CloudFormation CI/CD scripts

#### Runbook

##### Resources

Box location: <https://atrihub.app.box.com/file/399829398942>
(https://atrihub.app.box.com/file/399829398942)

#### Other Resources

-   [Image Pipeline - Parking Lot](#image-pipeline---parking-lot)

### Image Pipeline Architecture Diagram

![\_scroll\_external/attachments/untitled-diagram-drawio-99951be9a5ba7f9f935bb70cf0fa23261753124347f29bfa9c24abe2ee0c3f6d.png](media/image12.png){width="5.9006944444444445in"
height="2.265298556430446in"}

Decision log
============

Create decision

  Decision                                                                    Status                                                            Stakeholders   Outcome   Due date   Owner
  --------------------------------------------------------------------------- ----------------------------------------------------------------- -------------- --------- ---------- -------
  [EDC Image Pipeline Plugin - API](#edc-image-pipeline-plugin---api)         **<span style="font-variant:small-caps;"> in progress </span>**                                        
  [Image Pipeline - Parking Lot](#image-pipeline---parking-lot)               **<span style="font-variant:small-caps;"> in progress </span>**                                        
  [Image Pipeline - ProcessDCM.py](#image-pipeline---processdcm.py)           **<span style="font-variant:small-caps;"> not started </span>**                                        
  [Image Pipeline - Step Function](#image-pipeline---step-function)           **<span style="font-variant:small-caps;"> in progress </span>**                                        
  [Image Pipeline - Batch](#image-pipeline---batch)                           **<span style="font-variant:small-caps;"> not started </span>**                                        
  [Image Pipeline - Lambda](#image-pipeline---lambda)                         **<span style="font-variant:small-caps;"> in progress </span>**                                        
  [AWS Consultant Suggestions Summary](#aws-consultant-suggestions-summary)   **<span style="font-variant:small-caps;"> in progress </span>**                                        
  [EDC File Upload Improvements](#edc-file-upload-improvements)               **<span style="font-variant:small-caps;"> paused </span>**                                             
  [EDC Image Pipeline Plugin - Model](#edc-image-pipeline-plugin---model)     **<span style="font-variant:small-caps;"> in progress </span>**                                        

Decisions
---------

Record important project decisions and communicate them with your team.

Create from template

EDC File Upload Improvements
----------------------------

  ------------------------------------------------------------------------------------------------------
  > Add your comments directly to the page. Include links to any relevant research, data, or feedback.
  ------------------------------------------------------------------------------------------------------

  Status         **<span style="font-variant:small-caps;"> paused </span>**
  -------------- -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  Impact         **<span style="font-variant:small-caps;"> medium </span>**
  Driver         [Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq) (https://atrihub.atlassian.net/wiki/display/\~hongmeiq) 
  Approver       
  Contributors   [Gustavo Jimenez-Maggiora](https://atrihub.atlassian.net/wiki/display/~gustavoj) (https://atrihub.atlassian.net/wiki/display/\~gustavoj) [Jia-Shing So](https://atrihub.atlassian.net/wiki/display/~jiashins) (https://atrihub.atlassian.net/wiki/display/\~jiashins) [Mihir Kavatkar](https://atrihub.atlassian.net/wiki/display/~kavatkar) (https://atrihub.atlassian.net/wiki/display/\~kavatkar) 
  Informed       
  Due date       
  Outcome        

### Background

File uploading is very slow via the EDC file attachment widget.

The issue is we are loading everything in memory when go through
multiple layers to upload a file (GUI → API → Django → boto3 → write to
S3 bucket).

We need to look into a more optimal solution to improve the performance
of the file attachment widget. 

### Relevant data

-   AWS SDK for javascript

    -   <https://docs.aws.amazon.com/sdk-for-javascript/v2/developer-guide/s3-example-photo-album.html>
        (https://docs.aws.amazon.com/sdk-for-javascript/v2/developer-guide/s3-example-photo-album.html)

-   AWS Security Token Service STS

    -   <https://docs.aws.amazon.com/STS/latest/APIReference/Welcome.html>
        (https://docs.aws.amazon.com/STS/latest/APIReference/Welcome.html)

### Options considered

Upload file directory to s3 bucket using AWS SDK for Javascript and AWS
STS (for authentication).

Flow:

Client browser file uploaded → calls Django API to get a session token
via sts → with the access token AWS SDK for Javascript uploads the file
into s3 bucket, returns object key → calls Django API to update
SubjectEventCrfFile table with the file info

use STS assumed\_role() to get the session token, set the duration to
300sec (min value):

(access key, secret key, session token) =
sts.assumed\_role(upload\_only\_role\_policy, s3 key, duration seconds)

-   important: make sure to scoping down the role to only upload a
    specific object 

### Action items

-    

### Outcome

AWS Consultant Suggestions Summary
----------------------------------

  ------------------------------------------------------------------------------------------------------
  > Add your comments directly to the page. Include links to any relevant research, data, or feedback.
  ------------------------------------------------------------------------------------------------------

  Status         **<span style="font-variant:small-caps;"> in progress </span>**
  -------------- ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  Impact         **<span style="font-variant:small-caps;"> medium </span>**
  Driver         [Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq) (https://atrihub.atlassian.net/wiki/display/\~hongmeiq) 
  Approver       
  Contributors   [Pradeep Ravindranath](https://atrihub.atlassian.net/wiki/display/~paravindranath) (https://atrihub.atlassian.net/wiki/display/\~paravindranath) [Gustavo Jimenez-Maggiora](https://atrihub.atlassian.net/wiki/display/~gustavoj) (https://atrihub.atlassian.net/wiki/display/\~gustavoj) [Stefania Bruschi](https://atrihub.atlassian.net/wiki/display/~bruschi) (https://atrihub.atlassian.net/wiki/display/\~bruschi) [Mihir Kavatkar](https://atrihub.atlassian.net/wiki/display/~kavatkar) (https://atrihub.atlassian.net/wiki/display/\~kavatkar) 
  Informed       
  Due date       
  Outcome        

### Summary

#### Runbook

-   IAM user "atri-img-pipe-ec2-docker", Group
    "atri-img-pipe-ec2-docker" (item 7)

    -   If we push Docker from an EC2 instance instead of from local
        machine, we can use the role instead a user (timeline: future)

-   NEVER grant the following policies:

    -   AmazonVPCFullAccess

    -   AmazonS3FullAccess

-   Avoid using CloudWatchLogFullAccess policy, try
    AWSLambdaBasicExecutionRole

-   IAM roles, one per study portal per image pipeline

    -   then per lambda

        -   default: atri-lambda-basic-execution-role

        -   query-read-replica:
            atri-edc-trc-dev-img-pipe-query-read-replica-lambda-role

        -   submit-batch-job:
            atri-edc-trc-dev-img-pipe-submit-batch-job-lambda-role

        -   get-batch-job-status:
            atri-edc-trc-dev-img-pipe-get-batch-job-status-lambda-role

        -   copy-to-destination:
            atri-edc-trc-dev-img-pipe-copy-to-destination-lambda-role

#### CloudFormation

-   Anything marked as custom script in runbook under "CloudFormation"
    column can be hooked into CloudFormation (as a lambda function)
    using [Custom
    Resources](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/template-custom-resources.html)
    (https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/template-custom-resources.html)

#### Docker

-   When creating the temporary EC2 instance, *do not* use the same VPC
    for EDC/image pipeline (e.g. use the default VPC)

-   Use the latest AMI for docker: amazonlinux:2018.03

#### Trigger

-   since we have the CloudWatch logs, we don't need to setup the
    CloudTrail

### Relevant data

[Meeting notes](#meeting-notes)

[runbook](https://atrihub.app.box.com/file/399829398942)
(https://atrihub.app.box.com/file/399829398942)

### Action items

-    

### Outcome

Design for unit testing
-----------------------

![\_scroll\_external/attachments/was-unit-test-drawio-59d61c94905c4f1842d5ad2d6faced07246879327b3da967a64046b54fa0ec30.png](media/image13.png){width="5.9006944444444445in"
height="1.21208552055993in"}

Flow \#1\
code stored in github -&gt; pull request -&gt; triggers test run on
Travis CI -&gt; result + coverage reports come back to Github

reference .travis.yml configuration:
<https://github.com/nicor88/aws-python-lambdas/blob/master/.travis.yml>
(https://github.com/nicor88/aws-python-lambdas/blob/master/.travis.yml)

target: unit tests only for phase I

Lambda functions:

1.  img-pipe-invoke-step-function.py

2.  img-pipe-create-pipeline-job.py

3.  img-pipe-query-read-replica.py

4.  img-pipe-submit-batch-job.py

5.  img-pipe-get-batch-job-status.py

6.  img-pipe-copy-to-destination.py

7.  img-pipe-notification-for-error.py

8.  img-pipe-notification-for-completion.py

Image Processing script:

1.  processDCM.py

.travis.yml template

  ---------------------------------------------------------------------------
  > language: python
  >
  >  
  >
  > python: '3.6'
  >
  > sudo: false
  >
  >  
  >
  > \# We don't care about Travis' python versions, we install conda anyway
  >
  > \#env:
  >
  > \# global:
  >
  > \# - AWS\_DEFAULT\_REGION=eu-west-1
  >
  > \# - PYTHONPATH=\$TRAVIS\_BUILD\_DIR:\$PYTHONPATH
  >
  >  
  >
  > install:
  >
  > - pip install awscli
  >
  > - pip install boto3
  >
  >  
  >
  > \# \# install libs from the requirements of each single lambda
  >
  > \# - for i in src/\*/; do pip install -r \$i"requirements.txt"; done
  >
  >  
  >
  > script:
  >
  > \# run tests
  >
  > - pytest
  >
  >  
  >
  > \#before\_deploy:
  >
  > \# - mkdir -p dist
  >
  > \# \# create zip for each lambda folder in src
  >
  > \# - for i in src/\*/; do .travis/build\_lambda.sh "\$i"; done
  >
  > \# - cp src/\*.zip dist
  >
  >  
  >
  > \# deploy:
  >
  > \# provider: s3
  >
  > \# access\_key\_id: \$AWS\_ACCESS\_KEY\_ID
  >
  > \# secret\_access\_key: \$AWS\_SECRET\_ACCESS\_KEY
  >
  > \# bucket: \$AWS\_BUCKET
  >
  > \# region: \$AWS\_BUCKET\_REGION
  >
  > \# local\_dir: dist
  >
  > \# upload-dir: deployments/lambdas/travis\_build
  >
  > \# acl: private \# keep them private
  >
  > \# skip\_cleanup: true
  >
  > \# on:
  >
  > \# all\_branches: true
  >
  >  
  >
  > notifications:
  >
  > email: false
  ---------------------------------------------------------------------------

Code Block 1 Travis.yml

EDC Image Pipeline Plugin - Model
---------------------------------

  ------------------------------------------------------------------------------------------------------
  > Add your comments directly to the page. Include links to any relevant research, data, or feedback.
  ------------------------------------------------------------------------------------------------------

  Status         **<span style="font-variant:small-caps;"> in progress </span>**
  -------------- -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  Impact         **<span style="font-variant:small-caps;"> low </span>**
  Driver         [Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq) (https://atrihub.atlassian.net/wiki/display/\~hongmeiq) 
  Approver       
  Contributors   [Gustavo Jimenez-Maggiora](https://atrihub.atlassian.net/wiki/display/~gustavoj) (https://atrihub.atlassian.net/wiki/display/\~gustavoj) [Stefania Bruschi](https://atrihub.atlassian.net/wiki/display/~bruschi) (https://atrihub.atlassian.net/wiki/display/\~bruschi) [Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq) (https://atrihub.atlassian.net/wiki/display/\~hongmeiq) [Pradeep Ravindranath](https://atrihub.atlassian.net/wiki/display/~paravindranath) (https://atrihub.atlassian.net/wiki/display/\~paravindranath) 
  Informed       
  Due date       
  Outcome        

### Database

File information tracked in the database tables.

#### Pipeline.EDCPipeline

register each pipeline (e.g. pipeline for image file, pipeline for audio
files, etc.

  Field     
  --------- --
  ID        
  Code      
  Label     
  DDFiles   

#### pipeline.EDCPipelineFile

one pipeline execution per record, one source file can be processed more
than once.

  Field Name                                                                                
  ----------------------------------------------------------------------------------------- -----------------------------------------
  ID                                                                                        
  [EDCPipeline.id](http://EDCPipeline.id) (http://EDCPipeline.id)                           
  [SubjectEventCrfFile.id](http://SubjectEventCrfFile.id) (http://SubjectEventCrfFile.id)   
  file\_name                                                                                
  Status                                                                                    Started, In Progress, Completed, Failed
  has\_error                                                                                T/F

#### pipeline.EDCPipelineFileDicom

  Field Name
  -----------------------------------------------------------------------------
  ID
  [EDCPipelineFile.id](http://edcpipelinefile.id) (http://EDCPipelineFile.id)
  ATRIUID
  studyUID
  serieUID
  serienum
  number\_of\_instances

### Action items

-    

### Outcome

EDC Image Pipeline Plugin - API
-------------------------------

  ------------------------------------------------------------------------------------------------------
  > Add your comments directly to the page. Include links to any relevant research, data, or feedback.
  ------------------------------------------------------------------------------------------------------

  Status         **<span style="font-variant:small-caps;"> in progress </span>**
  -------------- ------------------------------------------------------------------------------------------------------------------------------
  Impact         **<span style="font-variant:small-caps;"> low </span>**
  Driver         [Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq) (https://atrihub.atlassian.net/wiki/display/\~hongmeiq) 
  Approver       
  Contributors   
  Informed       
  Due date       
  Outcome        

### API

/pipeline/edcpipeline/file

  ---------------------------------------------------------------------
  > input:
  >
  > {
  >
  > pipeline\_code: xxx
  >
  > subject\_event\_crf\_file\_id: xxx
  >
  > \*edc\_pipieline\_file\_id: xxx (required **for** update)
  >
  > }
  >
  >  
  >
  > output:
  >
  > {
  >
  > success: T/F
  >
  > error\_code: reference dictionary (only show **if** success is F)
  >
  > error: xxxx (only show **if** success is F)
  >
  > data: {"id": xxx, ...} // EDCPipelineFile object
  >
  > }
  ---------------------------------------------------------------------

/pipeline/edcpipeline/file/dicom/add\_scan\_info

-   post

    -   request body (json)

  -----------------------------------------------------------------------------
  > input:
  >
  > {
  >
  > pipeline\_code: xxx,
  >
  > subject\_event\_crf\_file\_id: xxx,
  >
  > edc\_pipieline\_file\_id: xxxx
  >
  > scans:\[
  >
  > {
  >
  > study\_uid: xxx,
  >
  > series: \[
  >
  > {series\_uid: xxx, series\_number: yyy, number\_of\_instance: 123},
  >
  > {series\_uid: blah, series\_number: halb, number\_of\_instance: 123},
  >
  > ...
  >
  > \]
  >
  > },
  >
  > {
  >
  > study\_uid: xxx,
  >
  > series: \[
  >
  > {series\_uid: xxx, series\_number: yyy, number\_of\_instance: 123},
  >
  > {series\_uid: blah, series\_number: halb, number\_of\_instance: 123}, ...
  >
  > \]
  >
  > }
  >
  > }
  -----------------------------------------------------------------------------

  -----------------------------------------------------------------------
  > output:
  >
  > {
  >
  > "success": **true**,
  >
  > "error\_code": reference dictionary (only show **if** success is F)
  >
  > "error": xxxx (only show **if** success is F)
  >
  > "data":
  >
  > {
  >
  > edc\_pipeline\_file\_id: 123,
  >
  > pipeline\_code: xxx,
  >
  > subject\_event\_crf\_file\_id: xxx,
  >
  > scans: \[
  >
  > {
  >
  > "study\_uid": xxx,
  >
  > "series": \[
  >
  > {"series\_uid": aaa, "atri\_uid": yyy},
  >
  > {"series\_uid": aaa, "atri\_uid": ddd},
  >
  > ...
  >
  > \]
  >
  > },
  >
  > {
  >
  > "studyuid": xxx,
  >
  > "series": \[
  >
  > {"series\_uid": aaa, "atri\_uid": yyy},
  >
  > {"series\_uid": aaa, "atri\_uid": ddd},
  >
  > }
  >
  > \]
  >
  > }
  >
  > }
  -----------------------------------------------------------------------

### Action items

-    

### Outcome

Image Pipeline - Lambda
-----------------------

  ------------------------------------------------------------------------------------------------------
  > Add your comments directly to the page. Include links to any relevant research, data, or feedback.
  ------------------------------------------------------------------------------------------------------

  Status         **<span style="font-variant:small-caps;"> in progress </span>**
  -------------- ------------------------------------------------------------------------------------------------------------------------------
  Impact         **<span style="font-variant:small-caps;"> low </span>**
  Driver         [Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq) (https://atrihub.atlassian.net/wiki/display/\~hongmeiq) 
  Approver       
  Contributors   
  Informed       
  Due date       
  Outcome        

### Naming convention

prefix + function name

-   prefix = atri-edc-\[study portal instance\]-\[image pipeline code\]

    -   e.g. atri-edc-trc-dev-img-pipe-amypet

-   function names:

    -   query-read-replica

    -   create-pipeline-job

    -   submit-batch-job

    -   get-batch-job-status

    -   copy-to-destination

    -   notification-for-error

    -   notification-for-completion

### Lambda Functions

-   query-read-replica

    -   query EDC source file meta data info from EDC RDS read replica

-   create-pipeline-job

    -   call image pipeline API to create a new job in the
        EDCPipelineFile table

-   submit-batch-job

    -   create a new batch job to process the image file

    -   copy source file to workspace s3 bucket

    -   optimistically process file as DICOM format and insert ATRIUID
        into the DICOM header

-   get-batch-job-status

    -   check batch job status

-   copy-to-destination

    -   copy processed file from workspace to destination s3 bucket

-   notification-for-error

    -   logs error message in s3 bucket

    -   send out notification to specific recipients

-   notification-for-completion

    -   send out notification to specific recipients

### Reference

Runbook: <https://atrihub.app.box.com/file/399829398942>
(https://atrihub.app.box.com/file/399829398942)

### Action items

-    

### Outcome

Image Pipeline - Step Function
------------------------------

  ------------------------------------------------------------------------------------------------------
  > Add your comments directly to the page. Include links to any relevant research, data, or feedback.
  ------------------------------------------------------------------------------------------------------

  Status         **<span style="font-variant:small-caps;"> in progress </span>**
  -------------- ------------------------------------------------------------------------------------------------------------------------------
  Impact         **<span style="font-variant:small-caps;"> low </span>**
  Driver         [Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq) (https://atrihub.atlassian.net/wiki/display/\~hongmeiq) 
  Approver       
  Contributors   
  Informed       
  Due date       
  Outcome        

### Step Function

The main component of the pipeline, setup one per pipeline.

Carries the pipeline process through the lambda functions.

-   triggered when a new file is uploaded / updated in S3 source bucket
    folder "subjecteventcrffile"

-   Job name convention: \[[subject.id](http://subject.id)
    (http://subject.id)\]\_\[[subjecteventcrf.id](http://subjecteventcrf.id)
    (http://subjecteventcrf.id)\]\_\[[ddfile.name](http://ddfile.name)
    (http://ddfile.name)\]\_\[file version code\]\_\[timestamp\]

State Diagram

![\_scroll\_external/attachments/screen-shot-2019-03-27-at-5-55-46-pm-51b5a6fa5b227bccf7ace72b58f570ec2a550b4abba1af74e28e334481c8b82a.png](media/image14.png){width="4.950495406824147in"
height="4.166666666666667in"}

### Action items

-    

### Outcome

Image Pipeline - ProcessDCM.py
------------------------------

  ------------------------------------------------------------------------------------------------------
  > Add your comments directly to the page. Include links to any relevant research, data, or feedback.
  ------------------------------------------------------------------------------------------------------

  Status         **<span style="font-variant:small-caps;"> not started </span>**
  -------------- ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  Impact         **<span style="font-variant:small-caps;"> high </span>** / **<span style="font-variant:small-caps;"> medium </span>** / **<span style="font-variant:small-caps;"> low </span>**
  Driver         [Pradeep Ravindranath](https://atrihub.atlassian.net/wiki/display/~paravindranath) (https://atrihub.atlassian.net/wiki/display/\~paravindranath) 
  Approver       [Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq) (https://atrihub.atlassian.net/wiki/display/\~hongmeiq) [Stefania Bruschi](https://atrihub.atlassian.net/wiki/display/~bruschi) (https://atrihub.atlassian.net/wiki/display/\~bruschi)
  Contributors   
  Informed       
  Due date       
  Outcome        
  Epic           [PIPE-1](https://atrihub.atlassian.net/browse/PIPE-1) (https://atrihub.atlassian.net/browse/PIPE-1)

### Background

### Relevant data

### Options considered

  ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
                   Option 1:                                                                                                                                                                                     Option 2:
  ---------------- --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  Description                                                                                                                                                                                                    

  Pros and cons    ![\_scroll\_external/icons/add-4f14d566cd4def8f170c1c0b689648e053a4bfb56dc2974f2dde0f1d3328fb60.png](media/image15.png){width="0.16666666666666666in" height="0.16666666666666666in"}         ![\_scroll\_external/icons/add-4f14d566cd4def8f170c1c0b689648e053a4bfb56dc2974f2dde0f1d3328fb60.png](media/image15.png){width="0.16666666666666666in" height="0.16666666666666666in"}
                                                                                                                                                                                                                 
                   ![\_scroll\_external/icons/forbidden-91ed7a9569c7f6084f7bfe65768d1813d768cfcd981b61d137b79eabd1f0fe11.png](media/image16.png){width="0.16666666666666666in" height="0.16666666666666666in"}   ![\_scroll\_external/icons/forbidden-91ed7a9569c7f6084f7bfe65768d1813d768cfcd981b61d137b79eabd1f0fe11.png](media/image16.png){width="0.16666666666666666in" height="0.16666666666666666in"}

  Estimated cost   **<span style="font-variant:small-caps;"> large </span>**                                                                                                                                     **<span style="font-variant:small-caps;"> medium </span>**
  ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

### Action items

-    

Updating the package name from pre-package-source to
pre\_package\_source to resolve import
issue[![\_scroll\_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](media/image4.png){width="0.16666666666666666in"
height="0.16666666666666666in"}PIPE-39](https://atrihub.atlassian.net/browse/PIPE-39?src=confmacro)
(https://atrihub.atlassian.net/browse/PIPE-39?src=confmacro) - **<span
style="font-variant:small-caps;"> in review </span>**\
Adding python path to
travis.yml[![\_scroll\_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](media/image4.png){width="0.16666666666666666in"
height="0.16666666666666666in"}PIPE-40](https://atrihub.atlassian.net/browse/PIPE-40?src=confmacro)
(https://atrihub.atlassian.net/browse/PIPE-40?src=confmacro) - **<span
style="font-variant:small-caps;"> in review </span>**

processDCM\_refactor.py[![\_scroll\_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](media/image4.png){width="0.16666666666666666in"
height="0.16666666666666666in"}PIPE-46](https://atrihub.atlassian.net/browse/PIPE-46?src=confmacro)
(https://atrihub.atlassian.net/browse/PIPE-46?src=confmacro) - **<span
style="font-variant:small-caps;"> in review </span>**

1.  Refactor the code 

test\_dcm\_check.py[![\_scroll\_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](media/image4.png){width="0.16666666666666666in"
height="0.16666666666666666in"}PIPE-45](https://atrihub.atlassian.net/browse/PIPE-45?src=confmacro)
(https://atrihub.atlassian.net/browse/PIPE-45?src=confmacro) - **<span
style="font-variant:small-caps;"> in review </span>**

1.  Add test case for pipeline code, extract meta and
    subject\_event\_crf\_file\_id

2.  Add comments to test\_insert\_atriuid

3.  fix the import statement 

4.  add path variable for input folder location

test\_dcm\_check\_for\_failure[![\_scroll\_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](media/image4.png){width="0.16666666666666666in"
height="0.16666666666666666in"}PIPE-47](https://atrihub.atlassian.net/browse/PIPE-47?src=confmacro)
(https://atrihub.atlassian.net/browse/PIPE-47?src=confmacro) - **<span
style="font-variant:small-caps;"> in review </span>**

1.  Add a test case to test failure scenario of dcm 

test\_for\_atri\_uid\_in\_data[![\_scroll\_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](media/image4.png){width="0.16666666666666666in"
height="0.16666666666666666in"}PIPE-48](https://atrihub.atlassian.net/browse/PIPE-48?src=confmacro)
(https://atrihub.atlassian.net/browse/PIPE-48?src=confmacro) - **<span
style="font-variant:small-caps;"> in review </span>**

test\_for\_atri\_uid\_key\_not\_present\_in\_data[![\_scroll\_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](media/image4.png){width="0.16666666666666666in"
height="0.16666666666666666in"}PIPE-49](https://atrihub.atlassian.net/browse/PIPE-49?src=confmacro)
(https://atrihub.atlassian.net/browse/PIPE-49?src=confmacro) - **<span
style="font-variant:small-caps;"> in review </span>**

test\_for\_non\_dicom\_files[![\_scroll\_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](media/image4.png){width="0.16666666666666666in"
height="0.16666666666666666in"}PIPE-50](https://atrihub.atlassian.net/browse/PIPE-50?src=confmacro)
(https://atrihub.atlassian.net/browse/PIPE-50?src=confmacro) - **<span
style="font-variant:small-caps;"> in review </span>**

test\_for\_error\_messages[![\$iconUrl](media/image17.png){width="0.29170713035870516in"
height="0.3125437445319335in"}PIPE-55](https://atrihub.atlassian.net/browse/PIPE-55?src=confmacro)
(https://atrihub.atlassian.net/browse/PIPE-55?src=confmacro) (
![\$statusIcon](media/image17.png){width="0.29170713035870516in"
height="0.3125437445319335in"} )

Add a non dicom file for
test[![\_scroll\_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](media/image4.png){width="0.16666666666666666in"
height="0.16666666666666666in"}PIPE-51](https://atrihub.atlassian.net/browse/PIPE-51?src=confmacro)
(https://atrihub.atlassian.net/browse/PIPE-51?src=confmacro) - **<span
style="font-variant:small-caps;"> in review </span>**

![\_scroll\_external/attachments/screen-shot-2019-04-02-at-4-30-05-pm-7b46a643546bd1b5f5251108c6bfccf3b9bb147ae476c50a2025d60be9b7e035.png](media/image18.png){width="5.9006944444444445in"
height="2.367302055993001in"}

### Outcome

Image Pipeline - Batch
----------------------

  ------------------------------------------------------------------------------------------------------
  > Add your comments directly to the page. Include links to any relevant research, data, or feedback.
  ------------------------------------------------------------------------------------------------------

  Status         **<span style="font-variant:small-caps;"> not started </span>**
  -------------- ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  Impact         **<span style="font-variant:small-caps;"> high </span>** / **<span style="font-variant:small-caps;"> medium </span>** / **<span style="font-variant:small-caps;"> low </span>**
  Driver         [Pradeep Ravindranath](https://atrihub.atlassian.net/wiki/display/~paravindranath) (https://atrihub.atlassian.net/wiki/display/\~paravindranath) 
  Approver       
  Contributors   
  Informed       
  Due date       
  Outcome        

### Background

### Relevant data

### Options considered

  ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
                   Option 1:                                                                                                                                                                                     Option 2:
  ---------------- --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  Description                                                                                                                                                                                                    

  Pros and cons    ![\_scroll\_external/icons/add-4f14d566cd4def8f170c1c0b689648e053a4bfb56dc2974f2dde0f1d3328fb60.png](media/image15.png){width="0.16666666666666666in" height="0.16666666666666666in"}         ![\_scroll\_external/icons/add-4f14d566cd4def8f170c1c0b689648e053a4bfb56dc2974f2dde0f1d3328fb60.png](media/image15.png){width="0.16666666666666666in" height="0.16666666666666666in"}
                                                                                                                                                                                                                 
                   ![\_scroll\_external/icons/forbidden-91ed7a9569c7f6084f7bfe65768d1813d768cfcd981b61d137b79eabd1f0fe11.png](media/image16.png){width="0.16666666666666666in" height="0.16666666666666666in"}   ![\_scroll\_external/icons/forbidden-91ed7a9569c7f6084f7bfe65768d1813d768cfcd981b61d137b79eabd1f0fe11.png](media/image16.png){width="0.16666666666666666in" height="0.16666666666666666in"}

  Estimated cost   **<span style="font-variant:small-caps;"> large </span>**                                                                                                                                     **<span style="font-variant:small-caps;"> medium </span>**
  ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

### Action items

-    

### Outcome

Image Pipeline - Parking Lot
----------------------------

  ------------------------------------------------------------------------------------------------------
  > Add your comments directly to the page. Include links to any relevant research, data, or feedback.
  ------------------------------------------------------------------------------------------------------

  Status         **<span style="font-variant:small-caps;"> in progress </span>**
  -------------- ------------------------------------------------------------------------------------------------------------------------------
  Impact         **<span style="font-variant:small-caps;"> low </span>**
  Driver         [Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq) (https://atrihub.atlassian.net/wiki/display/\~hongmeiq) 
  Approver       
  Contributors   
  Informed       
  Due date       
  Outcome        

### Immediate Needs

-   relocate scripts (processDCM, lambda) from workspace bucket to a
    > central bucket

    -   name: atri-edc-plugins-github-deployment

    -   location:

        -   processDCM:
            > /edc-plugin-image-pipeline/batch/job\_def\_scripts/

        -   docker: /edc-plugin-image-pipeline/docker/

        -   lambda functions: /edc-plugin-image-pipeline/lambda/

-   log errors in a central log bucket

    -   name: atri-edc-logs

    -   location: /\[study\]/edc-plugin-image-pipeline/

<!-- -->

-   add edc user for API call with privs
    > to image-pipeline-aws-integration to EDC\_Config

    -   name: image-pipeline-aws-integration-bot

-   setup google mailing lists:

    -   trc-img-pipe-amypet-l@atrihub.io

    -   trc-img-pipe-admin-l@atrihub.io

<!-- -->

-   rename github repo edc-image-pipeline to
    > **edc-plugin-image-pipeline**

-   rename processDCM.py to process\_dicom.py

-   migrate image\_pipeline folder from AWS-Deployment,
    > edc-plugin-image-pipeline repo

<!-- -->

-   review CloudWatch logs make sure they are all traceable, e.g.
    > include information such as study, pipeline, image type, file id,
    > timestamp etc. (this will be a continuous project through phase I
    > and phase II)

### Phase II

-   data export API for image inventory:

    -   EDCPipeline

    -   EDCPipelineFile

    -   EDCPipelineDicom

-   step function handle additional state 'status' = skip for query read
    replica lambda function (re-evaluate whether we need this state
    before implement)

-   Digest email notification (weekly, daily summary)

-   Revisit ProcessDCM logging error messages

    -   currently logged in CloudWatch logs through print

    -   determine whether we can utilize Emil's approach

-   (evaluate) RDS Read Replica (R&D required)

    -   if we can restrict access through policies, we may not need this
        replica

-   (evaluate) dispose workspace image files after execution is
    completed

-   process ECAT

-   update lambda query read replica to query API token info from EDC
    for user image-pipeline-aws-integration-bot

-   fetch\_and\_run.sh (docker)

-   replace arn:aws:lambda:us-east-1:898466741470:layer:psycopg2-py37:2
    with our own layer in our account

### Future

-   Codepipeline + Codebuild → deploy updated Lambda and processDCM code
    from Github

-   revisit code versioning (currently using Github for version control)

-   automate step to create RDS read replica (based on answers we found
    in Phase II, we may drop this)

-   GUI register new pipeline in EDC? (TBD)

-   Report error messages from s3 bucket

### Action items

-    

### Outcome

How-to articles
===============

Add how-to article

  Title                                                                                                                 Creator                                                                                                                                                                                                            Modified
  --------------------------------------------------------------------------------------------------------------------- ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ --------------
  [Setup A new Image Pipeline](#setup-a-new-image-pipeline)                                                             [Hongmei Qiu](https://atrihub.atlassian.net/people/557058:0e04da62-9320-49f9-8df3-3a744f02137a?ref=confluence) (https://atrihub.atlassian.net/people/557058:0e04da62-9320-49f9-8df3-3a744f02137a?ref=confluence)   Mar 27, 2019
  [How to manually trigger image pipeline in step function](#how-to-manually-trigger-image-pipeline-in-step-function)   [Hongmei Qiu](https://atrihub.atlassian.net/people/557058:0e04da62-9320-49f9-8df3-3a744f02137a?ref=confluence) (https://atrihub.atlassian.net/people/557058:0e04da62-9320-49f9-8df3-3a744f02137a?ref=confluence)   Mar 22, 2019

Setup A new Image Pipeline
--------------------------

### Runbook

<https://atrihub.app.box.com/file/399829398942>
(https://atrihub.app.box.com/file/399829398942)

### Step 0

(notes to [Hongmei
Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq)
(https://atrihub.atlassian.net/wiki/display/\~hongmeiq): improve this!)

register a new pipeline with code and label info in the EDCPipeline
table via Django Admin tool.

### CI/CD

github repo: <https://github.com/atrihub/AWS-Deployment>
(https://github.com/atrihub/AWS-Deployment)

run script: sh
image\_pipeline/cloudformation/scripts/create\_image\_pipeline.sh
\[configuration file\]

Script can be run multiple times on the same configuration, if a
component is already setup, the script will skip that component

#### Ouptput

pending...

#### Configuration File

location: image\_pipeline/cloudformation/config

file format: plain text

file name suggestion: \[study portal instance name\]-\[pipeline
code\].config

##### Variables

pending...

##### Example

  --------------------------------------------------------------------------------------------------------
  > \#\#\#\#\#\#\#\#\# you may change the following variables based on the study portal, image type etc.
  >
  > DEBUG=false
  >
  >  
  >
  > IS\_PRODUCTION=false
  >
  >  
  >
  > AWS\_PROFILE='sand-informatics'
  >
  > AWS\_PROFILE\_DR='dr'
  >
  >  
  >
  > \# Pipeline code registered in EDC
  >
  > EDC\_PIPELINE\_CODE='amypet'
  >
  >  
  >
  > \# Image Type: default to use EDC pipeline code if it is short enough
  >
  > IMG\_TYPE=\$EDC\_PIPELINE\_CODE
  >
  >  
  >
  > \# EDC Elastic Beanstalk and RDS instances
  >
  > EDC\_EB\_APP='IMAGE-PIPELINE'
  >
  > EDC\_EB\_ENV='hq-trc-dev'
  >
  > RDS\_READ\_REPLICA=\$EDC\_EB\_ENV"-aurora"
  >
  >  
  >
  > EDC\_HOST='hq-trc-dev.atrihub.mobi'
  >
  >  
  >
  > \# tags
  >
  > TAG\_STUDY='trc'
  >
  > TAG\_ENVIRONMENT='development'
  >
  > TAG\_PIPELINE='image'
  >
  > TAG\_IMG\_TYPE=\$IMG\_TYPE
  >
  >  
  >
  > \# VPC
  >
  > VPC\_NAME='sandbox'
  >
  >  
  >
  > \# image process script
  >
  > IMG\_SCRIPT='file://image\_pipeline/scripts/processDCM.py'
  >
  >  
  >
  > \# Email Notifications, comma separated
  >
  > EMAIL\_ERROR="hongmeiq@atrihub.io"
  >
  > EMAIL\_COMPLETION="hongmeiq@usc.edu"
  >
  >  
  >
  > \#\#\#\#\#\#\#\#\# provide a good reason when updating the following variables
  >
  > \# Pipeline Name
  >
  > PIPELINE\_NAME=\$EDC\_EB\_ENV"-img-pipe-"\$IMG\_TYPE
  >
  >  
  >
  > \# S3 buckets
  >
  > SOURCE\_BUCKET\_PREFIX=\$EDC\_EB\_ENV
  >
  > DESTINATION\_BUCKET\_PREFIX=\$SOURCE\_BUCKET\_PREFIX"-img-"\$IMG\_TYPE
  >
  > WORKSPACE\_BUCKET\_PREFIX=\$DESTINATION\_BUCKET\_PREFIX"-ws"
  >
  >  
  >
  > \# EC2 key pairs
  >
  > EC2\_KEY\_DOCKER="atri-img-pipe-ec2-docker"
  >
  > EC2\_KEY\_BATCH\_DEBUG="atri-img-pipe-batch-debug"
  >
  >  
  >
  > \# Container image
  >
  > \# ECR\_REPO\_NAME='atri-image-pipeline-docker-201803'
  >
  > ECR\_REPO\_NAME="par-custom-fetch-and-run-new"
  >
  >  
  >
  > \# IAM roles
  >
  > ROLE\_PREFIX=\$PIPELINE\_NAME
  >
  > LAMBDA\_ROLE\_SUFFIX="-lambda-role"
  >
  >  
  >
  > BATCH\_SERVICE\_ROLE="AWSBatchServiceRole"
  >
  > BATCH\_INSTANCE\_PROFILE="AWSBatchInstanceProfile"
  >
  > BATCH\_JOB\_ROLE=\$ROLE\_PREFIX"-batch-job-role"
  >
  >  
  >
  > LAMBDA\_BASIC\_ROLE='atri-lambda-basic-execution-role'
  >
  > LAMBDA\_QUERY\_READ\_REPLICA\_ROLE=\$ROLE\_PREFIX"-query-read-replica"\$LAMBDA\_ROLE\_SUFFIX
  >
  > LAMBDA\_SUBMIT\_BATCH\_JOB\_ROLE=\$ROLE\_PREFIX"-submit-batch-job"\$LAMBDA\_ROLE\_SUFFIX
  >
  > LAMBDA\_GET\_BATCH\_JOB\_STATUS\_ROLE=\$ROLE\_PREFIX"-get-batch-job-status"\$LAMBDA\_ROLE\_SUFFIX
  >
  > LAMBDA\_COPY\_TO\_DESTINATION\_ROLE=\$ROLE\_PREFIX"-copy-to-destination"\$LAMBDA\_ROLE\_SUFFIX
  >
  > LAMBDA\_NOTIFICATION\_ROLE=\$ROLE\_PREFIX"-notification"\$LAMBDA\_ROLE\_SUFFIX
  >
  >  
  >
  > STEP\_FUNCTION\_ROLE=\$ROLE\_PREFIX"-step-function-role"
  >
  > CLOUDWATCH\_ROLE=\$EDC\_EB\_ENV"-img-pipe-cloudwatch-role"
  >
  >  
  >
  > \# Lambda functions
  >
  > LAMBDA\_QUERY\_READ\_REPLICA=\$PIPELINE\_NAME"-query-read-replica"
  >
  > LAMBDA\_CREATE\_PIPELINE\_JOB=\$PIPELINE\_NAME"-create-pipeline-job"
  >
  > LAMBDA\_SUBMIT\_BATCH\_JOB=\$PIPELINE\_NAME"-submit-batch-job"
  >
  > LAMBDA\_GET\_BATCH\_JOB\_STATUS=\$PIPELINE\_NAME"-get-batch-job-status"
  >
  > LAMBDA\_COPY\_TO\_DESTINATION=\$PIPELINE\_NAME"-copy-to-destination"
  >
  > LAMBDA\_NOTIFICATION\_FOR\_ERROR=\$PIPELINE\_NAME"-notification-for-error"
  >
  > LAMBDA\_NOTIFICATION\_FOR\_COMPLETION=\$PIPELINE\_NAME"-notification-for-completion"
  >
  >  
  >
  > \# CloudFormation stacks
  >
  > IAM\_ROLE\_CF\_STACK=\$EDC\_EB\_ENV"-img-pipe-"\$IMG\_TYPE"-roles"
  >
  > BATCH\_CF\_STACK=\$EDC\_EB\_ENV"-img-pipe-"\$IMG\_TYPE"-batch"
  >
  > LAMBDA\_CF\_STACK=\$EDC\_EB\_ENV"-img-pipe-"\$IMG\_TYPE"-lambda"
  >
  > STEP\_FN\_CF\_STACK=\$EDC\_EB\_ENV"-img-pipe-"\$IMG\_TYPE"-step-fn"
  >
  > TRIGGER\_CF\_STACK=\$EDC\_EB\_ENV"-img-pipe-trigger"
  --------------------------------------------------------------------------------------------------------

Code Block 2 pipeline config file example

### Brainstorming (archive this to a decision log)

#### Prerequisite

-   Github repo:

    -   AWS-Deployment

    -   EDC

    -   EDC-Pipeline (future)

-   EDC study portal

    -   readonly replica

    -   pipeline plug-in (future)

-   S3 buckets:

    -   EDC study portal bucket (source)

        -   naming convention: atri-edc-studyportal-aws\_account\_id

    -   Image pipeline destination bucket (target)

        -   naming convention: atri-edc-studyportal-img-aws\_account\_id

    -   Image pipeline workspace bucket (workspace)

        -   naming convention:
            atri-edc-studyportal-img-workspace-aws\_account\_id

    -   1 source vs 1 target vs 1 workspace

        -   **area to improve**

-   Docker

    -   IAM user with credential to push to EC2 and ECS instances

        -   example on sandbox: user par-ec2-to-ecr with group
            par-aws-cli-access

        -   **area to improve**

    -   EC2 key pair 1 - docker

-   EC2 key pair 2 - debug batch computing environment

#### EDC Pipeline Plugin

pending...

Currently the pipeline code is in EDC github repo branch hq\_pipeline

Create a CodePipeline (CodeBuild) that pushes EDC code to EDC study
portal

#### Batch

##### Part 1: Docker

Download AWS-Deployment Github zip

Launch EC2 instance via AWS console

-   create new instance

    -   make sure only use the free tier one

-   use "Amazon Linux AMI 2018.03.0 (HVM), SSD Volume Type"
    (ami-0080e4c5bc078760e)

-   no other overrides, use the default values

-   **(area to improve the security: VPC)**

-   choose a key pair 1 - to shell into the EC2 instance

-   follow the popup instruction to shell into the instance

    -   scp -i \~/.ssh/your\_ssh\_key
        path\_to\_AWS-Deployment\_zip\_file EC2\_instance\_string:\~/

        -   EC2\_instance string example:
            ec2-user@ec2-3-92-236-127.compute-1.amazonaws.com:\~/.

    -   shell in to EC2 instance, unzip AWS-Deployment Github zip file

    -   setup IAM user credential to perform aws cli commands, so we can
        push to EC2 and ECS instances in the future

        -   aws configure

    -   update the package:

        -   sudo yum update -y

    -   Install Docker:

        -   sudo yum install docker -y

    -   Start docker service

        -   sudo service docker start

    -   Add the ec2-user to the docker group so you can execute Docker
        commands without using sudo.

        -   sudo usermod -a -G docker ec2-user

    -   if error: no basic auth credentials

        -   eval \$(aws ecr get-login --no-include-email | sed
            's|https://||')

            -   return: docker login ....

        -   sudo docker login ...

    -   go to AWS-Deployment folder:
        /trc\_image\_pipeline/pre-packaged-source/docker

    -   create / update docker image in ECR within EC2 instance

        -   sh **build\_and\_push.sh** &lt;ECR image name&gt;

        -   note: batch script to process the images (AWS-Deployment)

note: after dock image is created and stored to ECR, we can terminate
the EC2 instance

##### Part 1.1: Creating an encrypted compute resource AMI

Launch EC2 instance via AWS console

-   create new instance

    -   make sure only use the free tier one

-   use "Amazon Linux AMI 2018.03.0 (HVM), SSD Volume Type"
    (ami-0080e4c5bc078760e)

-   no other overrides, use the default values

-   choose a key pair 1 - to shell into the EC2 instance

-   shell into EC2 instance 

-   update the package:

    -   sudo yum update -y

-   Install Docker:

    -   sudo yum install docker -y

-   Start docker service

    -   sudo service docker start

-   Add the ec2-user to the docker group so you can execute Docker
    commands without using sudo.

    -   sudo usermod -a -G docker ec2-user

-   Install the ecs agent

    -   sudo yum install -y ecs-init

    -   (optional) sudo start ecs

-   Create /etc/ecs/ecs.config

    -   insert the following lines:\
        ECS\_ENABLE\_TASK\_IAM\_ROLE=true\
        ECS\_ENABLE\_TASK\_IAM\_ROLE\_NETWORK\_HOST=true\
        ECS\_LOGFILE=/log/ecs-agent.log\
        ECS\_AVAILABLE\_LOGGING\_DRIVERS=\["json-file","awslogs"\]\
        ECS\_LOGLEVEL=info\
        ECS\_CLUSTER=*default\
        *

-   (optional) sudo stop ecs

-   sudo rm -rf /var/lib/ecs/data/ecs\_agent\_data.json 

-   Create and encrypt AMI:

    -   Select the instance

    -   choose Actions → Image → create image

    -   Go to IMAGES → AMIs from the side menu

    -   select the created AMI

    -   Copy the AMI with encrypt option selected.

-   Provide the AMI id when creating the resource in AWS batch to use
    custom AMI after checking the “Enable user-specified Ami ID” option

-   Stop or terminate the
    instance.References:https://medium.com/@abbyfuller/not-containers-101-bringing-your-own-ami-or-configuring-on-the-fly-8f66ca7d7eefhttps://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-agent-install.htmlhttps://docs.aws.amazon.com/batch/latest/userguide/compute\_resource\_AMIs.html\#batch-ami-spec
    (https://medium.com/@abbyfuller/not-containers-101-bringing-your-own-ami-or-configuring-on-the-fly-8f66ca7d7eef)

##### Part 2: Batch

**convention: 1 environment, 1 job queue, 1 definition per pipeline**

###### create new compute environment

-   managed

-   service role: create new or use existing AWSBatchServiceRole

-   Instance role: create new ecsInstanceRole

-   key pair: key pair 2 for debugging purposes

-   instance type: (default value) optimal/m5

    -   **area to improve: review this choice later**

-   min vCPUs

    -   0: production

    -   1: testing

-   desired vCPUs: 2 (based on the instance type we choose)

    -   **area to improve: review this value**

-   Network:

    -   testing: sanbox

    -   production: edc-xxx

    -   **note: keep public for now, need to improve security by using
        private with NAT**

-   Tags

    -   name

    -   study

    -   environment

##### create a job queue

-   priority: 1

-   Enable job queue: check

-   compute environment: created in previous step

###### job definitions

-   name

-   job attempts: use default 1

-   execution timeout (seconds): 300

-   compute environment: created in previous step

-   job role: allows docker image to communicate to s3 bucket, or other
    AWS services in the future

    -   e.g. par-imgpipe-ecstask-s3

    -   **area to improve**

-   container image: ECR -&gt; image URI

-   environment variables

    -   SCRIPT\_S3\_IN: s3 bucket image workspace

    -   OUTPUT\_S3\_OUT: img-pipe-submit-batch-job defines this value

    -   INPUT\_S3\_IN: img-pipe-submit-batch-job defines this value

    -   OUT\_NAME: img-pipe-submit-batch-job defines this value

-   parameters: will be defined by img-pipe-submit-batch-job

    -   pipeline\_code

    -   subjecteventcrffile\_id

    -   edc\_pipeline\_file\_id

    -   api\_token

    -   api\_url\_dicom

    -   api\_url\_log\_error

<!-- -->

-   command: value will be overwritten by the Lambda Submit Job

    -   default sample command for pipeline: *python3 processDCM.py
        --pipelinecode Ref::pipeline\_code --subjecteventcrffileid
        Ref::subjecteventcrffile\_id --edcpipelinefileid
        Ref::edc\_pipeline\_file\_id --apitoken Ref::api\_token
        --apiurldicom Ref::api\_url\_dicom --apiurllogerror
        Ref::api\_url\_log\_error*

        -   Ref::xxxx = Ref::parameter

-   vCPUs: 1

-   Memory(MB): 1024

    -   **area to improve: define this value in the lambda function
        Submit Job as environment variable**

-   Security:

    -   privileged: check

    -   user: nobody

        -   **area to improve: review this value**

    -   area to improve: security, ask Emil

###### Job

-   submit a job (j**ust for testing for initial setup**)

    -   name

    -   job definition: created in previous step

    -   job queue: created in previous step

    -   job type: Single

    -   container properties:

        -   echo job name (just for testing)

        -   leave blank for production

#### Step function

step function name: same as the pipeline code

step function role: grant step function permission to invoke lambda
functions

-   par-imgpipe-sfn

##### Lambda

-   create the following lambda functions:

    -   list:

        -   img-pipe-query-read-replica

        -   img-pipe-create-pipeline-job

        -   img-pipe-submit-batch-job

        -   img-pipe-get-batch-job-status

        -   img-pipe-copy-to-destination

        -   img-pipe-notification-for-error

        -   img-pipe-notification-for-completion

        -   **area to improve: refactor the script and environment
            variables to be able to use for another image pipeline**

    -   service role: for step function used lambda function

        -   e.g. par-imgpipe

        -   **area to improve**

    -   VPC:

        -   area to improve: make sure the VPC is tight

    -   environment variables:

        -   img-pipe-query-read-replica

            -   edc\_pipeline\_api\_token

            -   edc\_pipeline\_api\_url\_dicom

            -   edc\_pipeline\_api\_url\_log\_error

            -   edc\_pipeline\_code

            -   rds\_db\_name

            -   rds\_db\_password

            -   rds\_db\_username

            -   rds\_host

            -   workspace\_bucket\_name

            -   workspace\_file\_path

            -   note: add layer for psycopg2 library, python version
                used: 3.7

        -   img-pipe-create-pipeline-job

        -   img-pipe-submit-batch-job

        -   img-pipe-get-batch-job-status

        -   img-pipe-copy-to-destination

            -   target\_bucket\_name

            -   target\_file\_path

        -   img-pipe-notification-for-error

        -   img-pipe-notification-for-completion

    -   **area to improve:**

        -   code refactor

        -   environment variables

##### State Machine Definition

  ----------------------------------------------------------------------------------------
  > {
  >
  > "StartAt":"Queryreadreplica",
  >
  > "States":{
  >
  > "Queryreadreplica":{
  >
  > "Type":"Task",
  >
  > "Resource":"arn:aws:lambda:us-east-1:xxx:function:img-pipe-query-read-replica",
  >
  > "Next":"Create-pipeline-job",
  >
  > "Retry":\[
  >
  > {
  >
  > "ErrorEquals":\[
  >
  > "Error"
  >
  > \],
  >
  > "IntervalSeconds":1,
  >
  > "BackoffRate":2.0,
  >
  > "MaxAttempts":3
  >
  > }
  >
  > \],
  >
  > "Catch":\[
  >
  > {
  >
  > "ErrorEquals":\[
  >
  > "States.ALL"
  >
  > \],
  >
  > "Next":"ErrorSNS"
  >
  > }
  >
  > \]
  >
  > },
  >
  > "Create-pipeline-job":{
  >
  > "Type":"Task",
  >
  > "Resource":"arn:aws:lambda:us-east-1:xxx:function:hq-create-pipeline-job",
  >
  > "Next":"SubmitJob",
  >
  > "Catch":\[
  >
  > {
  >
  > "ErrorEquals":\[
  >
  > "States.ALL"
  >
  > \],
  >
  > "Next":"ErrorSNS"
  >
  > }
  >
  > \]
  >
  > },
  >
  > "SubmitJob":{
  >
  > "Type":"Task",
  >
  > "Resource":"arn:aws:lambda:us-east-1:xxx:function:par-imgpipe-batchSubmitJob",
  >
  > "Next":"GetJobStatus",
  >
  > "Catch":\[
  >
  > {
  >
  > "ErrorEquals":\[
  >
  > "States.ALL"
  >
  > \],
  >
  > "Next":"ErrorSNS"
  >
  > }
  >
  > \]
  >
  > },
  >
  > "GetJobStatus":{
  >
  > "Type":"Task",
  >
  > "Resource":"arn:aws:lambda:us-east-1:xxx:function:par-imgpipe-batchGetJobStatus",
  >
  > "Next":"CheckJobStatus",
  >
  > "InputPath":"\$",
  >
  > "ResultPath":"\$.status"
  >
  > },
  >
  > "CheckJobStatus":{
  >
  > "Type":"Choice",
  >
  > "Choices":\[
  >
  > {
  >
  > "Variable":"\$.status",
  >
  > "StringEquals":"FAILED",
  >
  > "Next":"ErrorSNS"
  >
  > },
  >
  > {
  >
  > "Variable":"\$.status",
  >
  > "StringEquals":"SUCCEEDED",
  >
  > "Next":"par-imgpipe-copy2dest"
  >
  > }
  >
  > \],
  >
  > "Default":"Wait30Seconds"
  >
  > },
  >
  > "Wait30Seconds":{
  >
  > "Type":"Wait",
  >
  > "Seconds":15,
  >
  > "Next":"GetJobStatus"
  >
  > },
  >
  > "par-imgpipe-copy2dest":{
  >
  > "Type":"Task",
  >
  > "Resource":"arn:aws:lambda:us-east-1:xxx:function:par-imgpipe-copy2dest",
  >
  > "Next":"par-imgpipe-updateStatus",
  >
  > "Catch":\[
  >
  > {
  >
  > "ErrorEquals":\[
  >
  > "States.ALL"
  >
  > \],
  >
  > "Next":"ErrorSNS"
  >
  > }
  >
  > \]
  >
  > },
  >
  > "par-imgpipe-updateStatus":{
  >
  > "Type":"Task",
  >
  > "Resource":"arn:aws:lambda:us-east-1:xxx:function:par-imgpipe-updateStatus",
  >
  > "Next":"processCompletionSNS",
  >
  > "Catch":\[
  >
  > {
  >
  > "ErrorEquals":\[
  >
  > "States.ALL"
  >
  > \],
  >
  > "Next":"ErrorSNS"
  >
  > }
  >
  > \]
  >
  > },
  >
  > "ErrorSNS":{
  >
  > "Type":"Task",
  >
  > "Resource":"arn:aws:lambda:us-east-1:xxx:function:par-imgpipe-errorSNS",
  >
  > "Next":"processCompletionSNS"
  >
  > },
  >
  > "processCompletionSNS":{
  >
  > "Type":"Task",
  >
  > "Resource":"arn:aws:lambda:us-east-1:xxx:function:par-imgpipe-processCompletionSNS",
  >
  > "End":**true**
  >
  > }
  >
  > }
  >
  > }
  ----------------------------------------------------------------------------------------

Trigger

-   we have the state machine (step function)

-   we have source s3 bucket

-   create trail in CloudTrail

    -   trail name: same as step function for batch

    -   s3 bucket: workspace bucket

        -   prefix: subjecteventcrffile

        -   write only

    -   storage location (for logs)

        -   s3 bucket: workspace

        -   prefix: logs/pipeline\_code/trigger

### Relevant Documents

[AWS
Batch](https://atrihub.atlassian.net/wiki/spaces/RD/blog/2018/12/10/912261126/AWS+Batch)
(https://atrihub.atlassian.net/wiki/spaces/RD/blog/2018/12/10/912261126/AWS+Batch)

<https://docs.aws.amazon.com/step-functions/latest/dg/tutorial-cloudwatch-events-s3.html>
(https://docs.aws.amazon.com/step-functions/latest/dg/tutorial-cloudwatch-events-s3.html)

How to manually trigger image pipeline in step function
-------------------------------------------------------

  ------------------------------------------
  > {
  >
  > 
 "detail":{
  >
  > 
 "requestParameters":{
  >
  > 
 "bucketName": source s3 bucket name,
  >
  > 
 "key":s3 object key 

  >
  > } 

  >
  > } 

  >
  > }
  ------------------------------------------


<!--stackedit_data:
eyJoaXN0b3J5IjpbLTIwMDAyMzM1NzVdfQ==
-->