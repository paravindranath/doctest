<!\[endif\]-->

AWS Pipeline

AWS Pipeline

Exported on Apr 11, 2019 5:03 PM

  

Table of Contents

1  Recently Updated........................................................................................................ 5

2  How-to Articles............................................................................................................ 6

3  Open issues in JIRA.................................................................................................... 7

4  Meeting notes............................................................................................................ 10

4.1  Incomplete tasks from meetings................................................................................ 10

4.2  Task report.............................................................................................................. 10

4.3  All meeting notes..................................................................................................... 10

4.4  2019-01-25 Meeting notes - Pipelines....................................................................... 11

4.4.1  Date..................................................................................................................... 11

4.4.2  Participants............................................................................................................ 11

4.4.3  Goals.................................................................................................................... 11

4.4.4  Discussion topics.................................................................................................... 11

4.4.5  Action items........................................................................................................... 12

4.4.6  Decisions............................................................................................................... 12

4.5  2019-01-28 Meeting notes - TRC image pipeline........................................................ 12

4.5.1  Date..................................................................................................................... 12

4.5.2  Participants............................................................................................................ 12

4.5.3  Goals.................................................................................................................... 12

4.5.4  Discussion topics.................................................................................................... 12

4.5.5  Action items........................................................................................................... 13

4.5.6  Decisions............................................................................................................... 14

4.6  2019-01-30 Meeting notes - TRC Image Pipeline....................................................... 14

4.6.1  Date..................................................................................................................... 14

4.6.2  Participants............................................................................................................ 14

4.6.3  Goals.................................................................................................................... 14

4.6.4  Discussion topics - next meeting................................................................................. 14

4.6.5  Action items........................................................................................................... 15

4.6.6  Decisions............................................................................................................... 15

4.7  2019-02-07 Meeting notes - TRC image pipeline........................................................ 15

4.7.1  Date..................................................................................................................... 15

4.7.2  Participants............................................................................................................ 15

4.7.3  Goals.................................................................................................................... 16

4.7.4  Discussion topics.................................................................................................... 16

4.7.5  Action items........................................................................................................... 17

4.7.6  Decisions............................................................................................................... 17

4.8  2019-02-11 Meeting notes - TRC Image Pipeline....................................................... 17

4.8.1  Date..................................................................................................................... 17

4.8.2  Participants............................................................................................................ 17

4.8.3  Goals.................................................................................................................... 17

4.8.4  Discussion topics.................................................................................................... 17

4.8.5  Action items........................................................................................................... 18

4.8.6  Decisions............................................................................................................... 18

4.9  2019-02-13 Meeting notes - TRC Image Pipeline....................................................... 18

4.9.1  Date..................................................................................................................... 18

4.9.2  Participants............................................................................................................ 18

4.9.3  Goals.................................................................................................................... 18

4.9.4  Discussion topics.................................................................................................... 19

4.9.5  Action items........................................................................................................... 19

4.9.6  Decisions............................................................................................................... 19

4.10  2019-02-20 Meeting notes - TRC Image Pipeline.................................................... 19

4.10.1  Date..................................................................................................................... 19

4.10.2  Participants............................................................................................................ 19

4.10.3  Goals.................................................................................................................... 20

4.10.4  Discussion topics.................................................................................................... 20

4.10.5  Action items........................................................................................................... 20

4.10.6  Decisions............................................................................................................... 20

4.11  2019-02-25 Meeting notes - TRC Image Pipeline.................................................... 20

4.12  2019-02-27 meeting notes - TRC Image Pipeline.................................................... 21

4.13  2019-04-03 - meeting notes - internal meetup on processDCM................................ 21

4.13.1  Date..................................................................................................................... 21

4.13.2  Participants............................................................................................................ 21

4.13.3  Goals.................................................................................................................... 22

4.13.4  Discussion topics.................................................................................................... 22

4.13.5  Action items........................................................................................................... 22

4.13.6  Decisions............................................................................................................... 22

5  Product requirements............................................................................................... 23

5.1  Image Pipeline......................................................................................................... 23

5.1.1  Background............................................................................................................ 23

5.1.2  Brainstorming......................................................................................................... 24

5.1.3  Relevant Data......................................................................................................... 32

5.1.4  Pipeline Dictionary................................................................................................... 33

5.1.5  Image Pipeline File Transfer Methods.......................................................................... 34

5.1.6  Image Pipeline Process Flow Diagram - High Level........................................................ 35

5.1.7  Image Pipeline Components and Resources................................................................. 35

5.1.8  Image Pipeline Architecture Diagram........................................................................... 36

6  Decision log.............................................................................................................. 37

6.1  Decisions................................................................................................................ 37

6.2  EDC File Upload Improvements................................................................................ 37

6.2.1  Background............................................................................................................ 38

6.2.2  Relevant data......................................................................................................... 38

6.2.3  Options considered.................................................................................................. 38

6.2.4  Action items........................................................................................................... 38

6.2.5  Outcome............................................................................................................... 38

6.3  AWS Consultant Suggestions Summary.................................................................... 38

6.3.1  Summary............................................................................................................... 39

6.3.2  Relevant data......................................................................................................... 40

6.3.3  Action items........................................................................................................... 40

6.3.4  Outcome............................................................................................................... 40

6.4  Design for unit testing.............................................................................................. 40

6.5  EDC Image Pipeline Plugin - Model.......................................................................... 41

6.5.1  Database............................................................................................................... 42

6.5.2  Action items........................................................................................................... 43

6.5.3  Outcome............................................................................................................... 43

6.6  EDC Image Pipeline Plugin - API.............................................................................. 43

6.6.1  API....................................................................................................................... 43

6.6.2  Action items........................................................................................................... 45

6.6.3  Outcome............................................................................................................... 45

6.7  Image Pipeline - Lambda.......................................................................................... 45

6.7.1  Naming convention.................................................................................................. 46

6.7.2  Lambda Functions................................................................................................... 46

6.7.3  Reference.............................................................................................................. 46

6.7.4  Action items........................................................................................................... 46

6.7.5  Outcome............................................................................................................... 47

6.8  Image Pipeline - Step Function................................................................................. 47

6.8.1  Step Function......................................................................................................... 47

6.8.2  Action items........................................................................................................... 48

6.8.3  Outcome............................................................................................................... 48

6.9  Image Pipeline - ProcessDCM.py.............................................................................. 48

6.9.1  Background............................................................................................................ 49

6.9.2  Relevant data......................................................................................................... 49

6.9.3  Options considered.................................................................................................. 49

6.9.4  Action items........................................................................................................... 49

6.9.5  Outcome............................................................................................................... 50

6.10  Image Pipeline - Batch.......................................................................................... 50

6.10.1  Background............................................................................................................ 51

6.10.2  Relevant data......................................................................................................... 51

6.10.3  Options considered.................................................................................................. 51

6.10.4  Action items........................................................................................................... 51

6.10.5  Outcome............................................................................................................... 51

6.11  Image Pipeline - Parking Lot................................................................................. 51

6.11.1  Immediate Needs.................................................................................................... 51

6.11.2  Phase II................................................................................................................. 52

6.11.3  Future................................................................................................................... 52

6.11.4  Action items........................................................................................................... 53

6.11.5  Outcome............................................................................................................... 53

7  How-to articles.......................................................................................................... 54

7.1  Setup A new Image Pipeline..................................................................................... 54

7.1.1  Runbook................................................................................................................ 54

7.1.2  Step 0................................................................................................................... 54

7.1.3  CI/CD................................................................................................................... 54

7.1.4  Brainstorming (archive this to a decision log)................................................................. 56

7.1.5  Relevant Documents................................................................................................ 65

7.2  How to manually trigger image pipeline in step function.............................................. 65

  

# <!\[if !supportLists\]>1 <!\[endif\]>Recently Updated

<!\[if !supportLists\]>· <!\[endif\]>[<!\[if !vml\]>![_scroll_external/other/61561096f0786d2271838563d1301046-731be5b06b7ec3012033a1384ace652aa20b3c704a6d126b55fb16bef2f4df51](AWS%20Pipeline-v5-20190411_170412.fld/image004.jpg)<!\[endif\]>](https://atrihub.atlassian.net/wiki/display/~paravindranath)  (https://atrihub.atlassian.net/wiki/display/~paravindranath)

[Pradeep Ravindranath](https://atrihub.atlassian.net/wiki/display/~paravindranath) (https://atrihub.atlassian.net/wiki/display/~paravindranath)

<!\[if !supportLists\]>· <!\[endif\]>[Pipeline Dictionary](#scroll-bookmark-3)updated yesterday at 3:13 PM[view change](https://atrihub.atlassian.net/wiki/pages/diffpagesbyversion.action?pageId=927367226&selectedPageVersions=27&selectedPageVersions=28) (https://atrihub.atlassian.net/wiki/pages/diffpagesbyversion.action?pageId=927367226&selectedPageVersions=27&selectedPageVersions=28)

<!\[if !supportLists\]>· <!\[endif\]>[<!\[if !vml\]>![_scroll_external/other/f3c4d0a354f4494d0f0d983c01dc7a97-1e61ddbc78a5e70a976bd122c2dadcd8028b10ee948c7ec170eb5ea0e2f70816](AWS%20Pipeline-v5-20190411_170412.fld/image006.jpg)<!\[endif\]>](https://atrihub.atlassian.net/wiki/display/~hongmeiq)  (https://atrihub.atlassian.net/wiki/display/~hongmeiq)

[Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq) (https://atrihub.atlassian.net/wiki/display/~hongmeiq)

<!\[if !supportLists\]>· <!\[endif\]>[EDC Image Pipeline Plugin - API](#scroll-bookmark-4)updated Apr 09, 2019[view change](https://atrihub.atlassian.net/wiki/pages/diffpagesbyversion.action?pageId=965541910&selectedPageVersions=2&selectedPageVersions=3) (https://atrihub.atlassian.net/wiki/pages/diffpagesbyversion.action?pageId=965541910&selectedPageVersions=2&selectedPageVersions=3)

<!\[if !supportLists\]>· <!\[endif\]>[Image Pipeline - Parking Lot](#scroll-bookmark-5)updated Apr 08, 2019[view change](https://atrihub.atlassian.net/wiki/pages/diffpagesbyversion.action?pageId=967344202&selectedPageVersions=22&selectedPageVersions=23) (https://atrihub.atlassian.net/wiki/pages/diffpagesbyversion.action?pageId=967344202&selectedPageVersions=22&selectedPageVersions=23)

<!\[if !supportLists\]>· <!\[endif\]>[<!\[if !vml\]>![_scroll_external/other/9ac034177948210d7799e0c32d50265c-a038d8b47e2d6d08c4cde75a21827b6a1aecdfa5ff0dcf3dc120ce570044fb5c](AWS%20Pipeline-v5-20190411_170412.fld/image008.jpg)<!\[endif\]>](https://atrihub.atlassian.net/wiki/display/~rkhemka)  (https://atrihub.atlassian.net/wiki/display/~rkhemka)

[Rajat Khemka](https://atrihub.atlassian.net/wiki/display/~rkhemka) (https://atrihub.atlassian.net/wiki/display/~rkhemka)

<!\[if !supportLists\]>· <!\[endif\]>[Image Pipeline - ProcessDCM.py](#scroll-bookmark-6)updated Apr 04, 2019[view change](https://atrihub.atlassian.net/wiki/pages/diffpagesbyversion.action?pageId=965967879&selectedPageVersions=22&selectedPageVersions=23) (https://atrihub.atlassian.net/wiki/pages/diffpagesbyversion.action?pageId=965967879&selectedPageVersions=22&selectedPageVersions=23)

<!\[if !supportLists\]>· <!\[endif\]>[<!\[if !vml\]>![_scroll_external/other/f3c4d0a354f4494d0f0d983c01dc7a97-1e61ddbc78a5e70a976bd122c2dadcd8028b10ee948c7ec170eb5ea0e2f70816](AWS%20Pipeline-v5-20190411_170412.fld/image006.jpg)<!\[endif\]>](https://atrihub.atlassian.net/wiki/display/~hongmeiq)  (https://atrihub.atlassian.net/wiki/display/~hongmeiq)

[Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq) (https://atrihub.atlassian.net/wiki/display/~hongmeiq)

<!\[if !supportLists\]>· <!\[endif\]>[Image Pipeline Components and Resources](#scroll-bookmark-7)updated Apr 03, 2019[view change](https://atrihub.atlassian.net/wiki/pages/diffpagesbyversion.action?pageId=959873105&selectedPageVersions=4&selectedPageVersions=5) (https://atrihub.atlassian.net/wiki/pages/diffpagesbyversion.action?pageId=959873105&selectedPageVersions=4&selectedPageVersions=5)

# <!\[if !supportLists\]>2 <!\[endif\]>How-to Articles

<!\[if !supportLists\]>· <!\[endif\]>Page:[Setup A new Image Pipeline](#scroll-bookmark-9)(AWS Pipeline)

<!\[if !supportLists\]>o <!\[endif\]>[kb-how-to-article](https://atrihub.atlassian.net/wiki/label/AWSPIPE/kb-how-to-article) (https://atrihub.atlassian.net/wiki/label/AWSPIPE/kb-how-to-article)

<!\[if !supportLists\]>o <!\[endif\]>[runbook](https://atrihub.atlassian.net/wiki/label/AWSPIPE/runbook) (https://atrihub.atlassian.net/wiki/label/AWSPIPE/runbook)

<!\[if !supportLists\]>· <!\[endif\]>Page:[How to manually trigger image pipeline in step function](#scroll-bookmark-10)(AWS Pipeline)

<!\[if !supportLists\]>o <!\[endif\]>[kb-how-to-article](https://atrihub.atlassian.net/wiki/label/AWSPIPE/kb-how-to-article) (https://atrihub.atlassian.net/wiki/label/AWSPIPE/kb-how-to-article)

# <!\[if !supportLists\]>3 <!\[endif\]>Open issues in JIRA

Key

T

Created

Updated

Due

Assignee

Status

Resolution

[PIPE-58](https://atrihub.atlassian.net/browse/PIPE-58?src=confmacro) (https://atrihub.atlassian.net/browse/PIPE-58?src=confmacro)

[<!\[if !vml\]>![_scroll_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](AWS%20Pipeline-v5-20190411_170412.fld/image010.jpg)<!\[endif\]>](https://atrihub.atlassian.net/browse/PIPE-58?src=confmacro)  (https://atrihub.atlassian.net/browse/PIPE-58?src=confmacro)

Apr 08, 2019 16:51

Apr 08, 2019 16:51

Hongmei Qiu

**to do**

Unresolved

[PIPE-57](https://atrihub.atlassian.net/browse/PIPE-57?src=confmacro) (https://atrihub.atlassian.net/browse/PIPE-57?src=confmacro)

[<!\[if !vml\]>![_scroll_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](AWS%20Pipeline-v5-20190411_170412.fld/image010.jpg)<!\[endif\]>](https://atrihub.atlassian.net/browse/PIPE-57?src=confmacro)  (https://atrihub.atlassian.net/browse/PIPE-57?src=confmacro)

Apr 05, 2019 01:32

Apr 05, 2019 01:32

Hongmei Qiu

**to do**

Unresolved

[PIPE-56](https://atrihub.atlassian.net/browse/PIPE-56?src=confmacro) (https://atrihub.atlassian.net/browse/PIPE-56?src=confmacro)

[<!\[if !vml\]>![_scroll_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](AWS%20Pipeline-v5-20190411_170412.fld/image010.jpg)<!\[endif\]>](https://atrihub.atlassian.net/browse/PIPE-56?src=confmacro)  (https://atrihub.atlassian.net/browse/PIPE-56?src=confmacro)

Apr 04, 2019 23:52

Apr 04, 2019 23:52

Hongmei Qiu

**to do**

Unresolved

[PIPE-55](https://atrihub.atlassian.net/browse/PIPE-55?src=confmacro) (https://atrihub.atlassian.net/browse/PIPE-55?src=confmacro)

[<!\[if !vml\]>![_scroll_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](AWS%20Pipeline-v5-20190411_170412.fld/image010.jpg)<!\[endif\]>](https://atrihub.atlassian.net/browse/PIPE-55?src=confmacro)  (https://atrihub.atlassian.net/browse/PIPE-55?src=confmacro)

Apr 04, 2019 16:47

Apr 08, 2019 14:11

Unassigned

**in progress**

Unresolved

[PIPE-54](https://atrihub.atlassian.net/browse/PIPE-54?src=confmacro) (https://atrihub.atlassian.net/browse/PIPE-54?src=confmacro)

[<!\[if !vml\]>![_scroll_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](AWS%20Pipeline-v5-20190411_170412.fld/image010.jpg)<!\[endif\]>](https://atrihub.atlassian.net/browse/PIPE-54?src=confmacro)  (https://atrihub.atlassian.net/browse/PIPE-54?src=confmacro)

Apr 04, 2019 12:47

Apr 04, 2019 12:47

Hongmei Qiu

**to do**

Unresolved

[PIPE-53](https://atrihub.atlassian.net/browse/PIPE-53?src=confmacro) (https://atrihub.atlassian.net/browse/PIPE-53?src=confmacro)

[<!\[if !vml\]>![_scroll_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](AWS%20Pipeline-v5-20190411_170412.fld/image010.jpg)<!\[endif\]>](https://atrihub.atlassian.net/browse/PIPE-53?src=confmacro)  (https://atrihub.atlassian.net/browse/PIPE-53?src=confmacro)

Apr 03, 2019 00:45

Apr 03, 2019 00:47

Hongmei Qiu

**in progress**

Unresolved

[PIPE-52](https://atrihub.atlassian.net/browse/PIPE-52?src=confmacro) (https://atrihub.atlassian.net/browse/PIPE-52?src=confmacro)

[<!\[if !vml\]>![_scroll_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](AWS%20Pipeline-v5-20190411_170412.fld/image010.jpg)<!\[endif\]>](https://atrihub.atlassian.net/browse/PIPE-52?src=confmacro)  (https://atrihub.atlassian.net/browse/PIPE-52?src=confmacro)

Apr 03, 2019 00:45

Apr 03, 2019 00:47

Hongmei Qiu

**in progress**

Unresolved

[PIPE-51](https://atrihub.atlassian.net/browse/PIPE-51?src=confmacro) (https://atrihub.atlassian.net/browse/PIPE-51?src=confmacro)

[<!\[if !vml\]>![_scroll_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](AWS%20Pipeline-v5-20190411_170412.fld/image010.jpg)<!\[endif\]>](https://atrihub.atlassian.net/browse/PIPE-51?src=confmacro)  (https://atrihub.atlassian.net/browse/PIPE-51?src=confmacro)

Apr 02, 2019 16:28

Apr 04, 2019 16:50

Unassigned

**in review**

Unresolved

[PIPE-50](https://atrihub.atlassian.net/browse/PIPE-50?src=confmacro) (https://atrihub.atlassian.net/browse/PIPE-50?src=confmacro)

[<!\[if !vml\]>![_scroll_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](AWS%20Pipeline-v5-20190411_170412.fld/image010.jpg)<!\[endif\]>](https://atrihub.atlassian.net/browse/PIPE-50?src=confmacro)  (https://atrihub.atlassian.net/browse/PIPE-50?src=confmacro)

Apr 02, 2019 16:17

Apr 04, 2019 16:50

Unassigned

**in review**

Unresolved

[PIPE-49](https://atrihub.atlassian.net/browse/PIPE-49?src=confmacro) (https://atrihub.atlassian.net/browse/PIPE-49?src=confmacro)

[<!\[if !vml\]>![_scroll_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](AWS%20Pipeline-v5-20190411_170412.fld/image010.jpg)<!\[endif\]>](https://atrihub.atlassian.net/browse/PIPE-49?src=confmacro)  (https://atrihub.atlassian.net/browse/PIPE-49?src=confmacro)

Apr 02, 2019 16:17

Apr 04, 2019 16:50

Unassigned

**in review**

Unresolved

[PIPE-48](https://atrihub.atlassian.net/browse/PIPE-48?src=confmacro) (https://atrihub.atlassian.net/browse/PIPE-48?src=confmacro)

[<!\[if !vml\]>![_scroll_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](AWS%20Pipeline-v5-20190411_170412.fld/image010.jpg)<!\[endif\]>](https://atrihub.atlassian.net/browse/PIPE-48?src=confmacro)  (https://atrihub.atlassian.net/browse/PIPE-48?src=confmacro)

Apr 02, 2019 16:17

Apr 04, 2019 16:50

Unassigned

**in review**

Unresolved

[PIPE-47](https://atrihub.atlassian.net/browse/PIPE-47?src=confmacro) (https://atrihub.atlassian.net/browse/PIPE-47?src=confmacro)

[<!\[if !vml\]>![_scroll_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](AWS%20Pipeline-v5-20190411_170412.fld/image010.jpg)<!\[endif\]>](https://atrihub.atlassian.net/browse/PIPE-47?src=confmacro)  (https://atrihub.atlassian.net/browse/PIPE-47?src=confmacro)

Apr 02, 2019 16:17

Apr 04, 2019 16:50

Unassigned

**in review**

Unresolved

[PIPE-46](https://atrihub.atlassian.net/browse/PIPE-46?src=confmacro) (https://atrihub.atlassian.net/browse/PIPE-46?src=confmacro)

[<!\[if !vml\]>![_scroll_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](AWS%20Pipeline-v5-20190411_170412.fld/image010.jpg)<!\[endif\]>](https://atrihub.atlassian.net/browse/PIPE-46?src=confmacro)  (https://atrihub.atlassian.net/browse/PIPE-46?src=confmacro)

Apr 02, 2019 16:12

Apr 04, 2019 16:50

Unassigned

**in review**

Unresolved

[PIPE-45](https://atrihub.atlassian.net/browse/PIPE-45?src=confmacro) (https://atrihub.atlassian.net/browse/PIPE-45?src=confmacro)

[<!\[if !vml\]>![_scroll_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](AWS%20Pipeline-v5-20190411_170412.fld/image010.jpg)<!\[endif\]>](https://atrihub.atlassian.net/browse/PIPE-45?src=confmacro)  (https://atrihub.atlassian.net/browse/PIPE-45?src=confmacro)

Apr 02, 2019 16:07

Apr 04, 2019 16:50

Unassigned

**in review**

Unresolved

[PIPE-44](https://atrihub.atlassian.net/browse/PIPE-44?src=confmacro) (https://atrihub.atlassian.net/browse/PIPE-44?src=confmacro)

[<!\[if !vml\]>![_scroll_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](AWS%20Pipeline-v5-20190411_170412.fld/image010.jpg)<!\[endif\]>](https://atrihub.atlassian.net/browse/PIPE-44?src=confmacro)  (https://atrihub.atlassian.net/browse/PIPE-44?src=confmacro)

Apr 01, 2019 15:44

Apr 03, 2019 00:44

Hongmei Qiu

**in progress**

Unresolved

[PIPE-43](https://atrihub.atlassian.net/browse/PIPE-43?src=confmacro) (https://atrihub.atlassian.net/browse/PIPE-43?src=confmacro)

[<!\[if !vml\]>![_scroll_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](AWS%20Pipeline-v5-20190411_170412.fld/image010.jpg)<!\[endif\]>](https://atrihub.atlassian.net/browse/PIPE-43?src=confmacro)  (https://atrihub.atlassian.net/browse/PIPE-43?src=confmacro)

Apr 01, 2019 15:44

Apr 03, 2019 00:44

Hongmei Qiu

**in progress**

Unresolved

[PIPE-42](https://atrihub.atlassian.net/browse/PIPE-42?src=confmacro) (https://atrihub.atlassian.net/browse/PIPE-42?src=confmacro)

[<!\[if !vml\]>![_scroll_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](AWS%20Pipeline-v5-20190411_170412.fld/image010.jpg)<!\[endif\]>](https://atrihub.atlassian.net/browse/PIPE-42?src=confmacro)  (https://atrihub.atlassian.net/browse/PIPE-42?src=confmacro)

Apr 01, 2019 09:15

Apr 01, 2019 09:16

Hongmei Qiu

**in progress**

Unresolved

[PIPE-41](https://atrihub.atlassian.net/browse/PIPE-41?src=confmacro) (https://atrihub.atlassian.net/browse/PIPE-41?src=confmacro)

[<!\[if !vml\]>![_scroll_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](AWS%20Pipeline-v5-20190411_170412.fld/image010.jpg)<!\[endif\]>](https://atrihub.atlassian.net/browse/PIPE-41?src=confmacro)  (https://atrihub.atlassian.net/browse/PIPE-41?src=confmacro)

Apr 01, 2019 09:14

Apr 01, 2019 09:16

Hongmei Qiu

**in progress**

Unresolved

[PIPE-40](https://atrihub.atlassian.net/browse/PIPE-40?src=confmacro) (https://atrihub.atlassian.net/browse/PIPE-40?src=confmacro)

[<!\[if !vml\]>![_scroll_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](AWS%20Pipeline-v5-20190411_170412.fld/image010.jpg)<!\[endif\]>](https://atrihub.atlassian.net/browse/PIPE-40?src=confmacro)  (https://atrihub.atlassian.net/browse/PIPE-40?src=confmacro)

Apr 01, 2019 08:29

Apr 04, 2019 16:50

Unassigned

**in review**

Unresolved

[PIPE-39](https://atrihub.atlassian.net/browse/PIPE-39?src=confmacro) (https://atrihub.atlassian.net/browse/PIPE-39?src=confmacro)

[<!\[if !vml\]>![_scroll_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](AWS%20Pipeline-v5-20190411_170412.fld/image010.jpg)<!\[endif\]>](https://atrihub.atlassian.net/browse/PIPE-39?src=confmacro)  (https://atrihub.atlassian.net/browse/PIPE-39?src=confmacro)

Mar 29, 2019 16:01

Apr 04, 2019 16:50

Rajat Khemka

**in review**

Unresolved

Showing 20 out of [57 issues](https://atrihub.atlassian.net/secure/IssueNavigator.jspa?reset=true&jqlQuery=project%3DPIPE+AND+status+not+in+%28DONE%2C+RESOLVED%2C+CLOSED%29+&src=confmacro) (https://atrihub.atlassian.net/secure/IssueNavigator.jspa?reset=true&jqlQuery=project%3DPIPE+AND+status+not+in+%28DONE%2C+RESOLVED%2C+CLOSED%29+&src=confmacro)

# <!\[if !supportLists\]>4 <!\[endif\]>Meeting notes

Create meeting note

## <!\[if !supportLists\]>4.1 <!\[endif\]>Incomplete tasks from meetings

## <!\[if !supportLists\]>4.2 <!\[endif\]>Task report

Looking good, no incomplete tasks.

## <!\[if !supportLists\]>4.3 <!\[endif\]>All meeting notes

Title

Creator

Modified

[2019-04-03 - meeting notes - internal meetup on processDCM](#scroll-bookmark-16)

[Hongmei Qiu](https://atrihub.atlassian.net/people/557058:0e04da62-9320-49f9-8df3-3a744f02137a?ref=confluence) (https://atrihub.atlassian.net/people/557058:0e04da62-9320-49f9-8df3-3a744f02137a?ref=confluence)

Apr 02, 2019

[2019-02-27 meeting notes - TRC Image Pipeline](#scroll-bookmark-17)

[Hongmei Qiu](https://atrihub.atlassian.net/people/557058:0e04da62-9320-49f9-8df3-3a744f02137a?ref=confluence) (https://atrihub.atlassian.net/people/557058:0e04da62-9320-49f9-8df3-3a744f02137a?ref=confluence)

Feb 27, 2019

[2019-02-25 Meeting notes - TRC Image Pipeline](#scroll-bookmark-18)

[Hongmei Qiu](https://atrihub.atlassian.net/people/557058:0e04da62-9320-49f9-8df3-3a744f02137a?ref=confluence) (https://atrihub.atlassian.net/people/557058:0e04da62-9320-49f9-8df3-3a744f02137a?ref=confluence)

Feb 25, 2019

[2019-02-20 Meeting notes - TRC Image Pipeline](#scroll-bookmark-19)

[Hongmei Qiu](https://atrihub.atlassian.net/people/557058:0e04da62-9320-49f9-8df3-3a744f02137a?ref=confluence) (https://atrihub.atlassian.net/people/557058:0e04da62-9320-49f9-8df3-3a744f02137a?ref=confluence)

Feb 20, 2019

[2019-02-13 Meeting notes - TRC Image Pipeline](#scroll-bookmark-20)

[Hongmei Qiu](https://atrihub.atlassian.net/people/557058:0e04da62-9320-49f9-8df3-3a744f02137a?ref=confluence) (https://atrihub.atlassian.net/people/557058:0e04da62-9320-49f9-8df3-3a744f02137a?ref=confluence)

Feb 13, 2019

[2019-02-11 Meeting notes - TRC Image Pipeline](#scroll-bookmark-21)

[Hongmei Qiu](https://atrihub.atlassian.net/people/557058:0e04da62-9320-49f9-8df3-3a744f02137a?ref=confluence) (https://atrihub.atlassian.net/people/557058:0e04da62-9320-49f9-8df3-3a744f02137a?ref=confluence)

Feb 11, 2019

[2019-02-07 Meeting notes - TRC image pipeline](#scroll-bookmark-22)

[Hongmei Qiu](https://atrihub.atlassian.net/people/557058:0e04da62-9320-49f9-8df3-3a744f02137a?ref=confluence) (https://atrihub.atlassian.net/people/557058:0e04da62-9320-49f9-8df3-3a744f02137a?ref=confluence)

Feb 07, 2019

[2019-01-30 Meeting notes - TRC Image Pipeline](#scroll-bookmark-23)

[Hongmei Qiu](https://atrihub.atlassian.net/people/557058:0e04da62-9320-49f9-8df3-3a744f02137a?ref=confluence) (https://atrihub.atlassian.net/people/557058:0e04da62-9320-49f9-8df3-3a744f02137a?ref=confluence)

Feb 05, 2019

[2019-01-28 Meeting notes - TRC image pipeline](#scroll-bookmark-24)

[Hongmei Qiu](https://atrihub.atlassian.net/people/557058:0e04da62-9320-49f9-8df3-3a744f02137a?ref=confluence) (https://atrihub.atlassian.net/people/557058:0e04da62-9320-49f9-8df3-3a744f02137a?ref=confluence)

Jan 30, 2019

[2019-01-25 Meeting notes - Pipelines](#scroll-bookmark-25)

[Hongmei Qiu](https://atrihub.atlassian.net/people/557058:0e04da62-9320-49f9-8df3-3a744f02137a?ref=confluence) (https://atrihub.atlassian.net/people/557058:0e04da62-9320-49f9-8df3-3a744f02137a?ref=confluence)

Jan 28, 2019

## <!\[if !supportLists\]>4.4 <!\[endif\]>2019-01-25 Meeting notes - Pipelines

### <!\[if !supportLists\]>4.4.1 <!\[endif\]>Date

25 Jan 2019

### <!\[if !supportLists\]>4.4.2 <!\[endif\]>Participants

<!\[if !supportLists\]>· <!\[endif\]>[Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq) (https://atrihub.atlassian.net/wiki/display/~hongmeiq)

<!\[if !supportLists\]>· <!\[endif\]>[Pradeep Ravindranath](https://atrihub.atlassian.net/wiki/display/~paravindranath) (https://atrihub.atlassian.net/wiki/display/~paravindranath)

<!\[if !supportLists\]>· <!\[endif\]>[Stefania Bruschi](https://atrihub.atlassian.net/wiki/display/~bruschi) (https://atrihub.atlassian.net/wiki/display/~bruschi)

<!\[if !supportLists\]>· <!\[endif\]>[Gustavo Jimenez-Maggiora](https://atrihub.atlassian.net/wiki/display/~gustavoj) (https://atrihub.atlassian.net/wiki/display/~gustavoj)

<!\[if !supportLists\]>· <!\[endif\]>[Emil Lerch](https://atrihub.atlassian.net/wiki/display/~emilerch) (https://atrihub.atlassian.net/wiki/display/~emilerch)

<!\[if !supportLists\]>· <!\[endif\]>Heather Stratton

<!\[if !supportLists\]>· <!\[endif\]>[Adam Hunter](https://atrihub.atlassian.net/wiki/display/~adamhunt) (https://atrihub.atlassian.net/wiki/display/~adamhunt)

### <!\[if !supportLists\]>4.4.3 <!\[endif\]>Goals

<!\[if !supportLists\]>· <!\[endif\]>Project Overview​

<!\[if !supportLists\]>· <!\[endif\]>Timeline​

<!\[if !supportLists\]>· <!\[endif\]>Architecture Overview ​

<!\[if !supportLists\]>· <!\[endif\]>Challenges​

<!\[if !supportLists\]>· <!\[endif\]>Deliverables ​

<!\[if !supportLists\]>· <!\[endif\]>Collaboration – discussion​

<!\[if !supportLists\]>· <!\[endif\]>Next Step – discussion​

<!\[if !supportLists\]>· <!\[endif\]>​

<!\[if !supportLists\]>· <!\[endif\]>

<!\[if !supportLists\]>· <!\[endif\]>Slides: [https://atrihub.app.box.com/file/389348050296](https://atrihub.app.box.com/file/389348050296) (https://atrihub.app.box.com/file/389348050296)

### <!\[if !supportLists\]>4.4.4 <!\[endif\]>Discussion topics

Time

Item

Presenter

Notes

Emil suggested use Glue to retrieve and process files in chunks

note for developers: look into this approach in phase 2

Emil suggested SFTP

[https://aws.amazon.com/sftp/](https://aws.amazon.com/sftp/) (https://aws.amazon.com/sftp/)

vzip/ Snappy

Large file upload GUI

JS components, multi-part upload

### <!\[if !supportLists\]>4.4.5 <!\[endif\]>Action items

<!\[if !supportLists\]> ![*](AWS%20Pipeline-v5-20190411_170412.fld/) <!\[endif\]>[Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq) (https://atrihub.atlassian.net/wiki/display/~hongmeiq) create IAM readonly account for Emil on sandbox

<!\[if !supportLists\]> ![*](AWS%20Pipeline-v5-20190411_170412.fld/) <!\[endif\]>[Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq) (https://atrihub.atlassian.net/wiki/display/~hongmeiq) share sample phantom files with Emil

<!\[if !supportLists\]> ![*](AWS%20Pipeline-v5-20190411_170412.fld/) <!\[endif\]>[Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq) (https://atrihub.atlassian.net/wiki/display/~hongmeiq) send out doodle poll for weekly touch base meetings

<!\[if !supportLists\]> ![*](AWS%20Pipeline-v5-20190411_170412.fld/) <!\[endif\]>[Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq) (https://atrihub.atlassian.net/wiki/display/~hongmeiq) create slack space and invite Emil to it

<!\[if !supportLists\]> ![*](AWS%20Pipeline-v5-20190411_170412.fld/) <!\[endif\]>[Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq) (https://atrihub.atlassian.net/wiki/display/~hongmeiq) share Emil Github repo with lambda code

### <!\[if !supportLists\]>4.4.6 <!\[endif\]>Decisions

## <!\[if !supportLists\]>4.5 <!\[endif\]>2019-01-28 Meeting notes - TRC image pipeline

### <!\[if !supportLists\]>4.5.1 <!\[endif\]>Date

28 Jan 2019

### <!\[if !supportLists\]>4.5.2 <!\[endif\]>Participants

<!\[if !supportLists\]>· <!\[endif\]>[Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq) (https://atrihub.atlassian.net/wiki/display/~hongmeiq)

<!\[if !supportLists\]>· <!\[endif\]>[Emil Lerch](https://atrihub.atlassian.net/wiki/display/~emilerch) (https://atrihub.atlassian.net/wiki/display/~emilerch)

<!\[if !supportLists\]>· <!\[endif\]>[Pradeep Ravindranath](https://atrihub.atlassian.net/wiki/display/~paravindranath) (https://atrihub.atlassian.net/wiki/display/~paravindranath)

<!\[if !supportLists\]>· <!\[endif\]>Tom Christensen

### <!\[if !supportLists\]>4.5.3 <!\[endif\]>Goals

<!\[if !supportLists\]>· <!\[endif\]>Meeting recording: [https://atrihub.app.box.com/folder/65237095772](https://atrihub.app.box.com/folder/65237095772) (https://atrihub.app.box.com/folder/65237095772)

### <!\[if !supportLists\]>4.5.4 <!\[endif\]>Discussion topics

Time

Item

Presenter

Notes

<!\[if !supportLists\]>· <!\[endif\]>

AWS Batch: Job Role IAM for S3 access

solved: create a role with s3 access policy → ecstatics → Tasks ([https://aws.amazon.com/blogs/compute/creating-a-simple-fetch-and-run-aws-batch-job/](https://aws.amazon.com/blogs/compute/creating-a-simple-fetch-and-run-aws-batch-job/) (https://aws.amazon.com/blogs/compute/creating-a-simple-fetch-and-run-aws-batch-job/))

AWS Batch: environment, queue, definition - should we create them through lambda or feed them as parameters

(Emil) feed them. Do not create them in lambda - no benefit, longer

What does multi-node configuration do

for array jobs. For jobs that requires to run parallel execution.

What are node properties? Can we use it to by pass docker container for execution

node ami is just to run ecstatics and docker container. Docker container can be used to work with node ami only at kernel level.

Cannot bypass container. for running and scaling only with AMIs use SQS → scale ec2. This is required when more control is required.

Debug RUNNABLE state is batch.

Can be done ssh’ing into a single node running job instance, and checking the ecstatics agent.

ECS agent can be customized to write docker logs. Have to create our own log driver

What happens when we kill the ecs spun instance

Exact relation not known. waits and runs the available/next available tasks.

VPC and subnets.

Public VPC and public subnets in private VPC works.

private subnets keep the jobs in runnable state.

(emil) create an endpoint letting ec2 access to ecs - not working (have to check again recreating the ecs cluster - probably it had old configurations)

custom AMI

have to include ecstatics agent.

### <!\[if !supportLists\]>4.5.5 <!\[endif\]>Action items

<!\[if !supportLists\]> ![*](AWS%20Pipeline-v5-20190411_170412.fld/) <!\[endif\]>

### <!\[if !supportLists\]>4.5.6 <!\[endif\]>Decisions

## <!\[if !supportLists\]>4.6 <!\[endif\]>2019-01-30 Meeting notes - TRC Image Pipeline

### <!\[if !supportLists\]>4.6.1 <!\[endif\]>Date

30 Jan 2019

### <!\[if !supportLists\]>4.6.2 <!\[endif\]>Participants

<!\[if !supportLists\]>· <!\[endif\]>[Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq) (https://atrihub.atlassian.net/wiki/display/~hongmeiq)

<!\[if !supportLists\]>· <!\[endif\]>[Pradeep Ravindranath](https://atrihub.atlassian.net/wiki/display/~paravindranath) (https://atrihub.atlassian.net/wiki/display/~paravindranath)

<!\[if !supportLists\]>· <!\[endif\]>[Emil Lerch](https://atrihub.atlassian.net/wiki/display/~emilerch) (https://atrihub.atlassian.net/wiki/display/~emilerch)

<!\[if !supportLists\]>· <!\[endif\]>Tom Christensen

### <!\[if !supportLists\]>4.6.3 <!\[endif\]>Goals

<!\[if !supportLists\]>· <!\[endif\]>Meeting recording: [https://atrihub.box.com/s/efczd3bqe0n49osxochwfwzc3aivp4s0](https://atrihub.box.com/s/efczd3bqe0n49osxochwfwzc3aivp4s0) (https://atrihub.box.com/s/efczd3bqe0n49osxochwfwzc3aivp4s0)

### <!\[if !supportLists\]>4.6.4 <!\[endif\]>Discussion topics - next meeting

<!\[if !supportLists\]>· <!\[endif\]>Show status - demo

<!\[if !supportLists\]>o <!\[endif\]>Best practice: where to store batch configuration variables (e.g. computing environment job queue and job definition)

<!\[if !supportLists\]>§ <!\[endif\]>**Emil suggestion:**

<!\[if !supportLists\]>· <!\[endif\]>token: parameter store

<!\[if !supportLists\]>· <!\[endif\]>db password: secret manager

<!\[if !supportLists\]>· <!\[endif\]>for variables pass to next lambda function, e.g. computing environment, just definite those variables in each lambda function (so those info won’t be go through function call via network)

<!\[if !supportLists\]>o <!\[endif\]>1 study portal per step function + 1st lambda function

<!\[if !supportLists\]>o <!\[endif\]>store configurations in 1st lambda function

<!\[if !supportLists\]>o <!\[endif\]>Any concerns on: passing API token through lambda to batch job as an update to job definition?

<!\[if !supportLists\]>· <!\[endif\]>batch

<!\[if !supportLists\]>o <!\[endif\]>passing parameters to batch

<!\[if !supportLists\]>§ <!\[endif\]>override job definition is ok for same type of pipeline

<!\[if !supportLists\]>o <!\[endif\]>best practice to update batch job submission

<!\[if !supportLists\]>§ <!\[endif\]>e.g. file path, file name different for each s3 object that triggers the job run

<!\[if !supportLists\]>o <!\[endif\]>batch error output to step function

<!\[if !supportLists\]>§ <!\[endif\]>cloudwatch logs, error text (grabs from log stream)

<!\[if !supportLists\]>· <!\[endif\]>what goes into cloudwatch logs? stdout and stderr …

<!\[if !supportLists\]>§ <!\[endif\]>aws batch return code makes its way back to step functionalt

<!\[if !supportLists\]>§ <!\[endif\]>alternatives: s3 log, cloudwatch insights (still needs to split stdout and stderr)

<!\[if !supportLists\]>§ <!\[endif\]>Emil recommended:mime approach, modify ecs agent to write to separate logs (won’t work for our case)

<!\[if !supportLists\]>· <!\[endif\]>ecs environment variable: which log streams

<!\[if !supportLists\]>· <!\[endif\]>error → s3 → cloudwatch log streams

<!\[if !supportLists\]>· <!\[endif\]>**todo: Emil share your example code with us**

<!\[if !supportLists\]>o <!\[endif\]>How to raise errors to next step function from batch (repeated from last question)

<!\[if !supportLists\]>§ <!\[endif\]>best practice - combine step 2 (process image) and step 3 (write metadata)? other options

<!\[if !supportLists\]>· <!\[endif\]>modify ECS agent

<!\[if !supportLists\]>· <!\[endif\]>Templates/scripts: log the cost and duration matrix (Emil)

<!\[if !supportLists\]>o <!\[endif\]>**TBD**

<!\[if !supportLists\]>· <!\[endif\]>Lambda CI/CD (serverless repository)

<!\[if !supportLists\]>o <!\[endif\]>Emil look into seamless flow:

<!\[if !supportLists\]>§ <!\[endif\]>**TODO: share link jetbridge (through slack)**

<!\[if !supportLists\]>o <!\[endif\]>restrictions:

<!\[if !supportLists\]>§ <!\[endif\]>total amount of code (layer will count toward it)

<!\[if !supportLists\]>§ <!\[endif\]>space (/tmp, /opt)

<!\[if !supportLists\]>· <!\[endif\]>Bastion Host: [Setup Bastion Host to SSH into EC2 instances](https://atrihub.atlassian.net/wiki/spaces/APST2/pages/722272320/Setup+Bastion+Host+to+SSH+into+EC2+instances) (https://atrihub.atlassian.net/wiki/spaces/APST2/pages/722272320/Setup+Bastion+Host+to+SSH+into+EC2+instances)

<!\[if !supportLists\]>· <!\[endif\]>AWS batch computing environments VPC with private subnet NAT creates issue

<!\[if !supportLists\]>o <!\[endif\]>TBD: push this back to March

### <!\[if !supportLists\]>4.6.5 <!\[endif\]>Action items

<!\[if !supportLists\]> ![*](AWS%20Pipeline-v5-20190411_170412.fld/) <!\[endif\]>

### <!\[if !supportLists\]>4.6.6 <!\[endif\]>Decisions

## <!\[if !supportLists\]>4.7 <!\[endif\]>2019-02-07 Meeting notes - TRC image pipeline

### <!\[if !supportLists\]>4.7.1 <!\[endif\]>Date

07 Feb 2019

### <!\[if !supportLists\]>4.7.2 <!\[endif\]>Participants

<!\[if !supportLists\]>· <!\[endif\]>[Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq) (https://atrihub.atlassian.net/wiki/display/~hongmeiq)

<!\[if !supportLists\]>· <!\[endif\]>[Pradeep Ravindranath](https://atrihub.atlassian.net/wiki/display/~paravindranath) (https://atrihub.atlassian.net/wiki/display/~paravindranath)

<!\[if !supportLists\]>· <!\[endif\]>[Emil Lerch](https://atrihub.atlassian.net/wiki/display/~emilerch) (https://atrihub.atlassian.net/wiki/display/~emilerch)

### <!\[if !supportLists\]>4.7.3 <!\[endif\]>Goals

<!\[if !supportLists\]>· <!\[endif\]>Lambda

<!\[if !supportLists\]>o <!\[endif\]>lambda layer

<!\[if !supportLists\]>o <!\[endif\]>Lambda CI/CD

<!\[if !supportLists\]>§ <!\[endif\]>serverless repository approach (TODO: Emil will look into this later)

<!\[if !supportLists\]>· <!\[endif\]>private

<!\[if !supportLists\]>§ <!\[endif\]>test lambda functions

<!\[if !supportLists\]>· <!\[endif\]>step function local (they have a docker) - java application

[https://docs.aws.amazon.com/step-functions/latest/dg/sfn-local.html](https://docs.aws.amazon.com/step-functions/latest/dg/sfn-local.html) (https://docs.aws.amazon.com/step-functions/latest/dg/sfn-local.html)

<!\[if !supportLists\]>§ <!\[endif\]>AWS Vault - for credentials

<!\[if !supportLists\]>· <!\[endif\]>[https://github.com/99designs/aws-vault](https://github.com/99designs/aws-vault) (https://github.com/99designs/aws-vault)

<!\[if !supportLists\]>· <!\[endif\]>cost and performance

<!\[if !supportLists\]>o <!\[endif\]>status:

<!\[if !supportLists\]>§ <!\[endif\]>cost and duration scripts (lambda, batch, etc.) (TODO: Emil will look into this later)

<!\[if !supportLists\]>§ <!\[endif\]>ecs agents (github fork) - stream script/container specific logs to CloudWatch - Emil: too overkill - just split the streams in our script into different s3 logs

<!\[if !supportLists\]>· <!\[endif\]>mime objects - multi-part

<!\[if !supportLists\]>· <!\[endif\]>s3 logs

<!\[if !supportLists\]>· <!\[endif\]>TODO: Emil will provide reference links to ecs agents fork (public github) just for future reference (looking for older version)

<!\[if !supportLists\]>o <!\[endif\]>[https://github.com/elerch/amazon-ecs-agent/tree/proxy_container](https://github.com/elerch/amazon-ecs-agent/tree/proxy_container) (https://github.com/elerch/amazon-ecs-agent/tree/proxy_container)

<!\[if !supportLists\]>· <!\[endif\]>Pipeline CI/CD (CloudFormation)

<!\[if !supportLists\]>o <!\[endif\]>bring everything together: step function, lambda, batch, docker

<!\[if !supportLists\]>· <!\[endif\]>Security (move this item to next meeting)

<!\[if !supportLists\]>o <!\[endif\]>Batch VPC private subnet with NAT - investigation (if time permits)

<!\[if !supportLists\]>· <!\[endif\]>Emil feedback on build and push script for docker

<!\[if !supportLists\]>o <!\[endif\]>[https://github.com/atrihub/AWS-Deployment/issues/48](https://github.com/atrihub/AWS-Deployment/issues/48) (https://github.com/atrihub/AWS-Deployment/issues/48)

### <!\[if !supportLists\]>4.7.4 <!\[endif\]>Discussion topics

Time

Item

Presenter

Notes

<!\[if !supportLists\]>· <!\[endif\]>

### <!\[if !supportLists\]>4.7.5 <!\[endif\]>Action items

<!\[if !supportLists\]> ![*](AWS%20Pipeline-v5-20190411_170412.fld/) <!\[endif\]>

### <!\[if !supportLists\]>4.7.6 <!\[endif\]>Decisions

## <!\[if !supportLists\]>4.8 <!\[endif\]>2019-02-11 Meeting notes - TRC Image Pipeline

### <!\[if !supportLists\]>4.8.1 <!\[endif\]>Date

11 Feb 2019

### <!\[if !supportLists\]>4.8.2 <!\[endif\]>Participants

<!\[if !supportLists\]>· <!\[endif\]>[Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq) (https://atrihub.atlassian.net/wiki/display/~hongmeiq)

<!\[if !supportLists\]>· <!\[endif\]>[Emil Lerch](https://atrihub.atlassian.net/wiki/display/~emilerch) (https://atrihub.atlassian.net/wiki/display/~emilerch)

<!\[if !supportLists\]>· <!\[endif\]>[Mihir Kavatkar](https://atrihub.atlassian.net/wiki/display/~kavatkar) (https://atrihub.atlassian.net/wiki/display/~kavatkar)

### <!\[if !supportLists\]>4.8.3 <!\[endif\]>Goals

<!\[if !supportLists\]>· <!\[endif\]>file upload: aws sdk file upload

<!\[if !supportLists\]>o <!\[endif\]>GUI → API → django → boto3

<!\[if !supportLists\]>o <!\[endif\]>aws SDK - how to setup so the file can be uploaded directly to s3, and the hand off (key etc) is secure and light weight

<!\[if !supportLists\]>· <!\[endif\]>can CloudTrail trigger on dynamic s3 prefix?

<!\[if !supportLists\]>· <!\[endif\]>CloudTrail triggered step function, can job execution name be configured?

<!\[if !supportLists\]>· <!\[endif\]>Batch job runs in separate environments?

<!\[if !supportLists\]>· <!\[endif\]>Batch job runnable status

<!\[if !supportLists\]>o <!\[endif\]>what caused this?

<!\[if !supportLists\]>o <!\[endif\]>related to configuration?

<!\[if !supportLists\]>· <!\[endif\]>Step function: Wait30Seconds

<!\[if !supportLists\]>o <!\[endif\]>stopping point

<!\[if !supportLists\]>· <!\[endif\]>[Setup TRC Image Pipeline](#scroll-bookmark-9)

<!\[if !supportLists\]>· <!\[endif\]>logs: which is easier to parse through

<!\[if !supportLists\]>o <!\[endif\]>cloudwatch - metric filter (recommended)

<!\[if !supportLists\]>o <!\[endif\]>s3

### <!\[if !supportLists\]>4.8.4 <!\[endif\]>Discussion topics

Time

Item

Presenter

Notes

<!\[if !supportLists\]>· <!\[endif\]>

### <!\[if !supportLists\]>4.8.5 <!\[endif\]>Action items

<!\[if !supportLists\]> ![*](AWS%20Pipeline-v5-20190411_170412.fld/) <!\[endif\]>

### <!\[if !supportLists\]>4.8.6 <!\[endif\]>Decisions

## <!\[if !supportLists\]>4.9 <!\[endif\]>2019-02-13 Meeting notes - TRC Image Pipeline

### <!\[if !supportLists\]>4.9.1 <!\[endif\]>Date

13 Feb 2019

### <!\[if !supportLists\]>4.9.2 <!\[endif\]>Participants

<!\[if !supportLists\]>· <!\[endif\]>[Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq) (https://atrihub.atlassian.net/wiki/display/~hongmeiq)

<!\[if !supportLists\]>· <!\[endif\]>[Emil Lerch](https://atrihub.atlassian.net/wiki/display/~emilerch) (https://atrihub.atlassian.net/wiki/display/~emilerch)

<!\[if !supportLists\]>· <!\[endif\]>[Mihir Kavatkar](https://atrihub.atlassian.net/wiki/display/~kavatkar) (https://atrihub.atlassian.net/wiki/display/~kavatkar)

### <!\[if !supportLists\]>4.9.3 <!\[endif\]>Goals

<!\[if !supportLists\]>· <!\[endif\]>[EDC File Upload Improvements](#scroll-bookmark-59) (timeline for this pushed to Q2/Q3)

<!\[if !supportLists\]>· <!\[endif\]>Runbook:

<!\[if !supportLists\]>o <!\[endif\]>[https://atrihub.app.box.com/file/399829398942](https://atrihub.app.box.com/file/399829398942) (https://atrihub.app.box.com/file/399829398942)

<!\[if !supportLists\]>· <!\[endif\]>Batch Compute Environment: switch to private subnet with NAT

<!\[if !supportLists\]>o <!\[endif\]>[https://aws.amazon.com/security/security-bulletins/AWS-2019-002/](https://aws.amazon.com/security/security-bulletins/AWS-2019-002/) (https://aws.amazon.com/security/security-bulletins/AWS-2019-002/)

<!\[if !supportLists\]>· <!\[endif\]>MIME multi-part generation and parsing (overkill)

<!\[if !supportLists\]>o <!\[endif\]>[https://github.com/broadinstitute/cromwell/blob/958411830ff100b705e27e0a4f2f09c86e02c705/supportedBackends/aws/src/main/scala/cromwell/backend/impl/aws/AwsBatchJob.scala](https://github.com/broadinstitute/cromwell/blob/958411830ff100b705e27e0a4f2f09c86e02c705/supportedBackends/aws/src/main/scala/cromwell/backend/impl/aws/AwsBatchJob.scala) (https://github.com/broadinstitute/cromwell/blob/958411830ff100b705e27e0a4f2f09c86e02c705/supportedBackends/aws/src/main/scala/cromwell/backend/impl/aws/AwsBatchJob.scala)

curl/default/bab9ebde-71a6-4a27-8d6e-0092e39c3140  
^^^ ^^^^ ^^^^  
| | ECS Task ID  
| ECS container name  
|  
|  
job definitioncurl -s $ECS\_CONTAINER\_METADATA_URI; env{  
"DockerId": "dcc704d12b1dee27cf3d0ddc78d7a8ed6cb5bf09cc8e254d806928a71a5055e6",  
"Name": "default",  
"DockerName": "ecs-curl-1-default-a6f8d3ab8c8b8281e301",  
"Image": "appropriate/curl",  
"ImageID": "sha256:d37e1f717dc01df3a838955d29a149c569352c0991b1d7cf11b4ebca8c6c7f55",  
"Labels": {  
"com.amazonaws.ecs.cluster": "optimal\_Batch\_320ef3e9-690b-3be6-9009-62700d07ea28",  
"com.amazonaws.ecs.container-name": "default",  
"com.amazonaws.ecs.task-arn": "arn:aws:ecs:us-east-2:931443760666:task/bab9ebde-71a6-4a27-8d6e-0092e39c3140",  
"com.amazonaws.ecs.task-definition-family": "curl",  
"com.amazonaws.ecs.task-definition-version": "1"  
},  
"DesiredStatus": "RUNNING",  
"KnownStatus": "RUNNING",  
"Limits": {  
"CPU": 1024,  
"Memory": 128  
},  
"CreatedAt": "2019-02-13T21:34:24.353330197Z",  
"StartedAt": "2019-02-13T21:34:24.834316277Z",  
"Type": "NORMAL"  
}SHLVL=2  
HOME=/root  
AWS\_CONTAINER\_CREDENTIALS\_RELATIVE\_URI=/v2/credentials/db4f5274-24e8-4fa4-ac51-2282a2286998  
AWS\_EXECUTION\_ENV=AWS\_ECS\_EC2  
AWS\_BATCH\_JOB_ID=2c517fa4-e5cd-4e8d-90b3-0fd7efcb24f5  
AWS\_BATCH\_JQ_NAME=optimal  
ECS\_CONTAINER\_METADATA_URI=[http://169.254.170.2/v3/f3bf3225-88ea-4de2-a195-f285d1af1b41](http://169.254.170.2/v3/f3bf3225-88ea-4de2-a195-f285d1af1b41) (http://169.254.170.2/v3/f3bf3225-88ea-4de2-a195-f285d1af1b41)  
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin  
AWS\_BATCH\_JOB_ATTEMPT=1  
PWD=/  
AWS\_BATCH\_CE_NAME=optimal

### <!\[if !supportLists\]>4.9.4 <!\[endif\]>Discussion topics

Time

Item

Presenter

Notes

<!\[if !supportLists\]>· <!\[endif\]>

### <!\[if !supportLists\]>4.9.5 <!\[endif\]>Action items

<!\[if !supportLists\]> ![*](AWS%20Pipeline-v5-20190411_170412.fld/) <!\[endif\]>

### <!\[if !supportLists\]>4.9.6 <!\[endif\]>Decisions

## <!\[if !supportLists\]>4.10 <!\[endif\]>2019-02-20 Meeting notes - TRC Image Pipeline

### <!\[if !supportLists\]>4.10.1 <!\[endif\]>Date

20 Feb 2019

### <!\[if !supportLists\]>4.10.2 <!\[endif\]>Participants

<!\[if !supportLists\]>· <!\[endif\]>[Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq) (https://atrihub.atlassian.net/wiki/display/~hongmeiq)

<!\[if !supportLists\]>· <!\[endif\]>[Emil Lerch](https://atrihub.atlassian.net/wiki/display/~emilerch) (https://atrihub.atlassian.net/wiki/display/~emilerch)

<!\[if !supportLists\]>· <!\[endif\]>[Mihir Kavatkar](https://atrihub.atlassian.net/wiki/display/~kavatkar) (https://atrihub.atlassian.net/wiki/display/~kavatkar)

### <!\[if !supportLists\]>4.10.3 <!\[endif\]>Goals

<!\[if !supportLists\]>· <!\[endif\]>cost report

<!\[if !supportLists\]>o <!\[endif\]>study

<!\[if !supportLists\]>o <!\[endif\]>service

<!\[if !supportLists\]>o <!\[endif\]>step/lambda

<!\[if !supportLists\]>· <!\[endif\]>encryption/HIPAA

<!\[if !supportLists\]>o <!\[endif\]>revisit KMS key management (re-cycle, DR)

<!\[if !supportLists\]>o <!\[endif\]>Batch computing environment

<!\[if !supportLists\]>§ <!\[endif\]>[https://aws.amazon.com/about-aws/whats-new/2017/09/aws-batch-is-now-a-hipaa-eligible-service/](https://aws.amazon.com/about-aws/whats-new/2017/09/aws-batch-is-now-a-hipaa-eligible-service/) (https://aws.amazon.com/about-aws/whats-new/2017/09/aws-batch-is-now-a-hipaa-eligible-service/)

<!\[if !supportLists\]>o <!\[endif\]>Step Function + Lambda

<!\[if !supportLists\]>· <!\[endif\]>CloudFormation, CI/CD - best practices

<!\[if !supportLists\]>o <!\[endif\]>1 per study image pipeline? or

<!\[if !supportLists\]>o <!\[endif\]>1 per section?

<!\[if !supportLists\]>o <!\[endif\]>walk through [runbook](https://atrihub.app.box.com/file/399829398942) (https://atrihub.app.box.com/file/399829398942), and identify what can be automated?

<!\[if !supportLists\]>· <!\[endif\]>Test - step functions/lambda

<!\[if !supportLists\]>o <!\[endif\]>Github → Travis CI

<!\[if !supportLists\]>o <!\[endif\]>Github → CodePipeline/CodeBuild

### <!\[if !supportLists\]>4.10.4 <!\[endif\]>Discussion topics

Time

Item

Presenter

Notes

<!\[if !supportLists\]>· <!\[endif\]>

### <!\[if !supportLists\]>4.10.5 <!\[endif\]>Action items

<!\[if !supportLists\]> ![*](AWS%20Pipeline-v5-20190411_170412.fld/) <!\[endif\]>

### <!\[if !supportLists\]>4.10.6 <!\[endif\]>Decisions

## <!\[if !supportLists\]>4.11 <!\[endif\]>2019-02-25 Meeting notes - TRC Image Pipeline

Attendees

<!\[if !supportLists\]>· <!\[endif\]>[Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq) (https://atrihub.atlassian.net/wiki/display/~hongmeiq)

<!\[if !supportLists\]>· <!\[endif\]>[Mihir Kavatkar](https://atrihub.atlassian.net/wiki/display/~kavatkar) (https://atrihub.atlassian.net/wiki/display/~kavatkar)

<!\[if !supportLists\]>· <!\[endif\]>[Emil Lerch](https://atrihub.atlassian.net/wiki/display/~emilerch) (https://atrihub.atlassian.net/wiki/display/~emilerch)

Agenda

CloudFormation

<!\[if !supportLists\]>· <!\[endif\]>Step function execution name: how to customize?

<!\[if !supportLists\]>· <!\[endif\]>Emil was pointing to the linux version used in the batch compute environment to test the private VPC in batch. We are currently using the managed amazon AMI. In order to do what Emil suggested I think we would need to create a custom AMI to run the docker image.

<!\[if !supportLists\]>· <!\[endif\]>CloudTrail was suggested here:

<!\[if !supportLists\]>o <!\[endif\]>[https://docs.aws.amazon.com/step-functions/latest/dg/tutorial-cloudwatch-events-s3.html](https://docs.aws.amazon.com/step-functions/latest/dg/tutorial-cloudwatch-events-s3.html) (https://docs.aws.amazon.com/step-functions/latest/dg/tutorial-cloudwatch-events-s3.html)

<!\[if !supportLists\]>· <!\[endif\]>S3 vs CloudWatch → both triggers lambda function

<!\[if !supportLists\]>o <!\[endif\]>Q: when is it useful to trigger step function directly?

<!\[if !supportLists\]>o <!\[endif\]>Q: S3 vs CloudWatch for logs?

<!\[if !supportLists\]>· <!\[endif\]>Lambda trigger function → step function, example?

<!\[if !supportLists\]>· <!\[endif\]>add tag to IAM role, not supported in CloudFormation?

<!\[if !supportLists\]>o <!\[endif\]>solution currently used: aws cli

<!\[if !supportLists\]>o <!\[endif\]>CloudFormation source tag: [https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-resource-tags.html](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-resource-tags.html) (https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-resource-tags.html)

<!\[if !supportLists\]>· <!\[endif\]>An error occurred (ValidationError) when calling the UpdateStack operation: No updates are to be performed.

<!\[if !supportLists\]>o <!\[endif\]>how to detect that?

<!\[if !supportLists\]>· <!\[endif\]>CloudFormation drift status

## <!\[if !supportLists\]>4.12 <!\[endif\]>2019-02-27 meeting notes - TRC Image Pipeline

<!\[if !supportLists\]>· <!\[endif\]>Compute Environment: use m3.medium/m5.large instead of optimal, consulted with Emil regarding our use case

<!\[if !supportLists\]>· <!\[endif\]>lambda testing locally - docker container (Github)

<!\[if !supportLists\]>o <!\[endif\]>without the 15 min timeout

<!\[if !supportLists\]>o <!\[endif\]>load lambda through ECR - step functions (ECS cluster, docker container) → get ECS output with location to CloudWatch log → checkout outputs in the CloudWatch logs

## <!\[if !supportLists\]>4.13 <!\[endif\]>2019-04-03 - meeting notes - internal meetup on processDCM

### <!\[if !supportLists\]>4.13.1 <!\[endif\]>Date

02 Apr 2019

### <!\[if !supportLists\]>4.13.2 <!\[endif\]>Participants

<!\[if !supportLists\]>· <!\[endif\]>[Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq) (https://atrihub.atlassian.net/wiki/display/~hongmeiq)

<!\[if !supportLists\]>· <!\[endif\]>[Pradeep Ravindranath](https://atrihub.atlassian.net/wiki/display/~paravindranath) (https://atrihub.atlassian.net/wiki/display/~paravindranath)

<!\[if !supportLists\]>· <!\[endif\]>[Rajat Khemka](https://atrihub.atlassian.net/wiki/display/~rkhemka) (https://atrihub.atlassian.net/wiki/display/~rkhemka)

### <!\[if !supportLists\]>4.13.3 <!\[endif\]>Goals

<!\[if !supportLists\]>· <!\[endif\]>Travis CI

<!\[if !supportLists\]>· <!\[endif\]>drop error_log api call, replace with proper print statement

<!\[if !supportLists\]>· <!\[endif\]>introduce ErrorMessage class with error codes: [Pipeline Dictionary](#scroll-bookmark-3)

### <!\[if !supportLists\]>4.13.4 <!\[endif\]>Discussion topics

Time

Item

Presenter

Notes

<!\[if !supportLists\]>· <!\[endif\]>

### <!\[if !supportLists\]>4.13.5 <!\[endif\]>Action items

<!\[if !supportLists\]> ![*](AWS%20Pipeline-v5-20190411_170412.fld/) <!\[endif\]>

### <!\[if !supportLists\]>4.13.6 <!\[endif\]>Decisions

# <!\[if !supportLists\]>5 <!\[endif\]>Product requirements

Create product requirement

Title

No content found.

## <!\[if !supportLists\]>5.1 <!\[endif\]>Image Pipeline

**Status**

**not started**

**Impact**

**low**

**Driver**

[Stefania Bruschi](https://atrihub.atlassian.net/wiki/display/~bruschi) (https://atrihub.atlassian.net/wiki/display/~bruschi), [Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq) (https://atrihub.atlassian.net/wiki/display/~hongmeiq)

**Approver**

[Gustavo Jimenez-Maggiora](https://atrihub.atlassian.net/wiki/display/~gustavoj) (https://atrihub.atlassian.net/wiki/display/~gustavoj)

**Contributors**

[Stefania Bruschi](https://atrihub.atlassian.net/wiki/display/~bruschi) (https://atrihub.atlassian.net/wiki/display/~bruschi), [Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq) (https://atrihub.atlassian.net/wiki/display/~hongmeiq), [Jia-Shing So](https://atrihub.atlassian.net/wiki/display/~jiashins) (https://atrihub.atlassian.net/wiki/display/~jiashins)

**Informed**

[Pradeep Ravindranath](https://atrihub.atlassian.net/wiki/display/~paravindranath) (https://atrihub.atlassian.net/wiki/display/~paravindranath)

**Due date**

18 Jan 2019

**Outcome**

note: subject and participant are interchangeable, Record ID = subjecteventcrf.id, upload form name = ddcrf.name, upload field name = ddfile.name

### <!\[if !supportLists\]>5.1.1 <!\[endif\]>Background

#### <!\[if !supportLists\]>5.1.1.1 <!\[endif\]>Objective

Design and create a pipeline that synchronizes image files between two s3 buckets: EDC source bucket and image bucket. Notify all stakeholders when new image files are available in the image bucket 'quarantine' folder. Track the transaction logs in the EDC database.

The pipeline should be triggered manually on a specific file or set of files.

##### <!\[if !supportLists\]>5.1.1.1.1 <!\[endif\]>EDC source bucket

Image file are uploaded by the EDC system users via the file uploader widget and stored in the EDC source bucket.

<!\[if !supportLists\]>· <!\[endif\]>bucket name: atri-edc-trc-production-_\[aws account ID\]_

<!\[if !supportLists\]>· <!\[endif\]>source folder: subjecteventcrffile

<!\[if !supportLists\]>· <!\[endif\]>file path: subjecteventcrffile/_\[subject.id\]_/_\[subjecteventcrf.id\]_/_\[ddfile.name\]_/

<!\[if !supportLists\]>· <!\[endif\]>file name: file version code + file extension

##### <!\[if !supportLists\]>5.1.1.1.2 <!\[endif\]>Image destination bucket

Image files in the destination bucket will be made available to collaborators (e.g. labs) for further process.

<!\[if !supportLists\]>· <!\[endif\]>bucket name: atri-edc-trc-production-img-_\[aws account ID\]_

<!\[if !supportLists\]>· <!\[endif\]>destination folder: quarantine

<!\[if !supportLists\]>· <!\[endif\]>file path: quarantine/\[ddcrf.name\]\[ddfile.name\]/

<!\[if !supportLists\]>· <!\[endif\]>file name: \[ddcrf.name\]_\[ddfile.name\]_\[participant code\]_\[event code\]_\[subjecteventcrf.id\]_\[subjecteventcrffile.revisionnumber\]_\[edcpipelinefile.id\]_\[timestamp\] + file extension

<!\[if !supportLists\]>o <!\[endif\]>note: strip out any whitespace

<!\[if !supportLists\]>o <!\[endif\]> timestamp

<!\[if !supportLists\]>§ <!\[endif\]>Q: timestamp when file is uploaded to source bucket? destination bucket?

<!\[if !supportLists\]>· <!\[endif\]>when the file is first uploaded into the quarantine folder (edcpipelinefile.ts_create)  
<!\[if !supportLineBreakNewLine\]>  
<!\[endif\]>

<!\[if !supportLists\]>§ <!\[endif\]>format: YYYYMMDD_HHMMSS

### <!\[if !supportLists\]>5.1.2 <!\[endif\]>Brainstorming

#### <!\[if !supportLists\]>5.1.2.1 <!\[endif\]>Design

##### <!\[if !supportLists\]>5.1.2.1.1 <!\[endif\]>Flow

<!\[if !vml\]>![_scroll_external/attachments/trc-image-pipeline-flow-1-xml-6557bfc18fddcd31215d3cf324071051a3b47ed5985c658059a2c018ee301716.png](AWS%20Pipeline-v5-20190411_170412.fld/image012.jpg)<!\[endif\]>

**Q: should we suggest to add an unquarantine folder? to keep quarantine as read only for users? (depends on whether the SFTP wrapper can handle folder level permissions)**

##### <!\[if !supportLists\]>5.1.2.1.2 <!\[endif\]>Track

Track the following information in the EDC database:

<!\[if !supportLists\]>· <!\[endif\]>subjecteventcrffile.id

<!\[if !supportLists\]>· <!\[endif\]>filepath - file path in the destination s3 bucket

<!\[if !supportLists\]>· <!\[endif\]>filename - file name in the destination s3 bucket

<!\[if !supportLists\]>· <!\[endif\]>FileID - unqiue ID for each image file transferred to the destination folder

<!\[if !supportLists\]>o <!\[endif\]>**Q: can we use SubjectEventCrfFile.id as the FileID?**

<!\[if !supportLists\]>· <!\[endif\]>studyUID**:** DICOM HEADER (0020,000D) Unique identifier for the Study.

<!\[if !supportLists\]>· <!\[endif\]>serieUID**:** DICOM HEADER (0020,000E) Unique identifier of the Series.

<!\[if !supportLists\]>· <!\[endif\]>serienum**:** DICOM HEADER (0020,0011) A number that identifies this Series.

<!\[if !supportLists\]>· <!\[endif\]>ScanID - a unique combination of studyUID and serieUID for each fileID

<!\[if !supportLists\]>· <!\[endif\]>ATRIUID - Uniqeue ID store in DICOM header to identify the image set: \[fileID\].\[scanID\]

Track the following information in a log file (s3 bucket - **where?**):

<!\[if !supportLists\]>· <!\[endif\]>execution error

<!\[if !supportLists\]>· <!\[endif\]>execution result

##### <!\[if !supportLists\]>5.1.2.1.3 <!\[endif\]>Notification

###### <!\[if !supportLists\]>5.1.2.1.3.1 <!\[endif\]>Type of users

<!\[if !supportLists\]>· <!\[endif\]>pipeline user: labs who reviews and process the image files when they are available in the quarantine folder

<!\[if !supportLists\]>· <!\[endif\]>admin user: developers of the image pipeline

###### <!\[if !supportLists\]>5.1.2.1.3.2 <!\[endif\]>Type of notifications

<!\[if !supportLists\]>· <!\[endif\]>for pipeline users: a digest report runs \[nightly|configurable schedule\]

<!\[if !supportLists\]>o <!\[endif\]>create a mailing list: [trc-images-l@atrihub.io](mailto:trc-images-l@atrihub.io) (mailto:trc-images-l@atrihub.io)

<!\[if !supportLists\]>o <!\[endif\]>report includes a list of new files made available to the quarantine folder

<!\[if !supportLists\]>o <!\[endif\]>report includes count of new files, count of files failed to be transferred/processed

<!\[if !supportLists\]>· <!\[endif\]>for admin users: error logs (immediately after execution), success logs (**immediately? on a schedule?**)

<!\[if !supportLists\]>o <!\[endif\]>create a mailing list: [trc-images-admin-l@atrihub.io](mailto:trc-images-admin-l@atrihub.io) (mailto:trc-images-admin-l@atrihub.io)

<!\[if !supportLists\]>· <!\[endif\]>Q: do people need to be notified when new files uploaded to the quarantine folder?

#### <!\[if !supportLists\]>5.1.2.2 <!\[endif\]>Implementation

##### <!\[if !supportLists\]>5.1.2.2.1 <!\[endif\]>(AWS) EDC RDS read replica

<!\[if !supportLists\]>· <!\[endif\]>Create a read only replica for the EDC database, so the pipeline can find subject, crf information during the transfer

<!\[if !supportLists\]>o <!\[endif\]>**Q: what's the delay between real database and the replica? (trigger wait time depends on this response)**

##### <!\[if !supportLists\]>5.1.2.2.2 <!\[endif\]>Database

File information tracked in the database tables.

###### <!\[if !supportLists\]>5.1.2.2.2.1 <!\[endif\]>Pipeline.EDCPipeline

register each pipeline (e.g. pipeline for image file, pipeline for audio files, etc.

Field

ID

Code

Label

DDFiles

###### <!\[if !supportLists\]>5.1.2.2.2.2 <!\[endif\]>pipeline.EDCPipelineFile

Field Name

ID

EDCPipeline.id

SubjectEventCrfFile.id

file_name

Status

Started, In Progress, Completed, Failed

has_error

T/F

  
<!\[if !supportLineBreakNewLine\]>  
<!\[endif\]>

###### <!\[if !supportLists\]>5.1.2.2.2.3 <!\[endif\]>pipeline.EDCPipelineFileDicom

Field Name

ID

EDCPipelineFile.id

ATRIUID

studyUID

serieUID

serienum

number\_of\_instances

##### <!\[if !supportLists\]>5.1.2.2.3 <!\[endif\]>API

/pipeline/edcpipeline/file

input:

{

pipeline_code: xxx

subject\_event\_crf\_file\_id: xxx

*edc\_pipieline\_file_id: xxx (required for update)

}

output:

{

success: T/F

error_code: reference dictionary (only show if success is F)

error: xxxx (only show if success is F)

data: {"edc\_pipeline\_file: object}

}

/pipeline/edcpipeline/file/dicom/add\_scan\_info

<!\[if !supportLists\]>· <!\[endif\]>post

<!\[if !supportLists\]>o <!\[endif\]>request body (json)

input:

{

pipeline_code: xxx,

subject\_event\_crf\_file\_id: xxx,

edc\_pipieline\_file_id: xxxx

scans:\[

{

study_uid: xxx,

series: \[

{series\_uid: xxx, series\_number: yyy, number\_of\_instance: 123},

{series\_uid: blah, series\_number: halb, number\_of\_instance: 123},

...

\]

},

{

study_uid: xxx,

series: \[

{series\_uid: xxx, series\_number: yyy, number\_of\_instance: 123},

{series\_uid: blah, series\_number: halb, number\_of\_instance: 123}, ...

\]

}

}

output:

{

"success": true,

"error_code": reference dictionary (only show if success is F)

"error": xxxx (only show if success is F)

"data":

{

edc\_pipeline\_file_id: 123,

pipeline_code: xxx,

subject\_event\_crf\_file\_id: xxx,

scans: \[

{

"study_uid": xxx,

"series": \[

{"series_uid": aaa, "atri_uid": yyy},

{"series_uid": aaa, "atri_uid": ddd},

...

\]

},

{

"studyuid": xxx,

"series": \[

{"series_uid": aaa, "atri_uid": yyy},

{"series_uid": aaa, "atri_uid": ddd},

}

\]

}

}

##### <!\[if !supportLists\]>5.1.2.2.4 <!\[endif\]>Mailing List

Study specific

<!\[if !supportLists\]>· <!\[endif\]>[trc-images-l@atrihub.io](mailto:trc-images-l@atrihub.io) (mailto:trc-images-l@atrihub.io) - for users (e.g. labs)

<!\[if !supportLists\]>· <!\[endif\]>[trc-images-admin-l@atrihub.io](mailto:trc-images-admin-l@atrihub.io) (mailto:trc-images-admin-l@atrihub.io) - for admins

##### <!\[if !supportLists\]>5.1.2.2.5 <!\[endif\]>(AWS) S3 bucket - temporary

<!\[if !supportLists\]>· <!\[endif\]>create a temporary s3 bucket used by the step function for file processing

<!\[if !supportLists\]>· <!\[endif\]>bucket name: atri-edc-trc-production-img-tmp-\[AWS account ID\]

##### <!\[if !supportLists\]>5.1.2.2.6 <!\[endif\]>(AWS) Step Function

<!\[if !supportLists\]>· <!\[endif\]>triggered when a new file is uploaded / updated in S3 source bucket folder "subjecteventcrffile"

<!\[if !supportLists\]>· <!\[endif\]>Job name convention: \[subject.id\]_\[subjecteventcrf.id\]_\[ddfile.name\]_\[file version code\]_\[timestamp\]

<!\[if !vml\]>![_scroll_external/attachments/screen-shot-2019-01-17-at-1-41-22-pm-e5866d37b3ac0070e2c2f10ca07f196d36a9f281b145357fd331e2b2f3f14e51.png](AWS%20Pipeline-v5-20190411_170412.fld/image014.jpg)<!\[endif\]>

##### <!\[if !supportLists\]>5.1.2.2.7 <!\[endif\]>(AWS) Lambda Function

<!\[if !supportLists\]>· <!\[endif\]>QUERY READ REPLICA:

<!\[if !supportLists\]>o <!\[endif\]>L1 - query file info from the read replica

<!\[if !supportLists\]>§ <!\[endif\]>input: file path and file name from source bucket

<!\[if !supportLists\]>§ <!\[endif\]>output: file metadata json

<!\[if !supportLists\]>· <!\[endif\]>if file is found

<!\[if !supportLists\]>o <!\[endif\]>ddcrf.name

<!\[if !supportLists\]>o <!\[endif\]>ddfile.name

<!\[if !supportLists\]>o <!\[endif\]>participant code

<!\[if !supportLists\]>o <!\[endif\]>event code

<!\[if !supportLists\]>o <!\[endif\]>subjecteventcrf.id

<!\[if !supportLists\]>o <!\[endif\]>subjecteventcrffile.revisionnumber

<!\[if !supportLists\]>o <!\[endif\]>subjecteventcrffile.id

<!\[if !supportLists\]>o <!\[endif\]>pipeline_code

<!\[if !supportLists\]>· <!\[endif\]>if file is not found

<!\[if !supportLists\]>o <!\[endif\]>return ERROR

<!\[if !supportLists\]>§ <!\[endif\]>step fn - retry function, checks return status of L1 (expect raised ERROR and try for max attempt)

<!\[if !supportLists\]>§ <!\[endif\]>duration:15 minutes

<!\[if !supportLists\]>§ <!\[endif\]>frequency: every 30 sec

<!\[if !supportLists\]>· <!\[endif\]>Process DCM:

<!\[if !supportLists\]>o <!\[endif\]>**Notes:**

<!\[if !supportLists\]>§ <!\[endif\]>All the following functions process the same file.

<!\[if !supportLists\]>§ <!\[endif\]>Size may be a restriction for lambda.

<!\[if !supportLists\]>§ <!\[endif\]>AWS batch can an be an alternate solution.

<!\[if !supportLists\]>o <!\[endif\]>L5 - parse file and extract the DICOM header

<!\[if !supportLists\]>§ <!\[endif\]>input: file path and name

<!\[if !supportLists\]>§ <!\[endif\]>output: DICOM header info for each scan (list)

<!\[if !supportLists\]>· <!\[endif\]>studyUID

<!\[if !supportLists\]>· <!\[endif\]>serieUID

<!\[if !supportLists\]>· <!\[endif\]>serienum

<!\[if !supportLists\]>o <!\[endif\]>L7 - write ATRIUID in DICOM header

<!\[if !supportLists\]>o <!\[endif\]>L4 - copy processed file from s3 source bucket to s3 temp bucket, rename the file

<!\[if !supportLists\]>§ <!\[endif\]>input:

<!\[if !supportLists\]>· <!\[endif\]>source file path and name

<!\[if !supportLists\]>· <!\[endif\]>target file path and name

<!\[if !supportLists\]>§ <!\[endif\]>output: successful (True/False)

<!\[if !supportLists\]>· <!\[endif\]>ADDITIONAL PROCESS:

<!\[if !supportLists\]>o <!\[endif\]>L8 - additional process (such as LONI process)

<!\[if !supportLists\]>· <!\[endif\]>WRITE META DATA:

<!\[if !supportLists\]>o <!\[endif\]>L6 - call API to write file metadata in study DB (set file status to "in progress")

<!\[if !supportLists\]>§ <!\[endif\]>input: L1 and L5 output

<!\[if !supportLists\]>§ <!\[endif\]>output: successful (True/False)

<!\[if !supportLists\]>· <!\[endif\]>COPY TO DESTINATION:

<!\[if !supportLists\]>o <!\[endif\]>L9 - copy file from S3 temp bucket to S3 destination bucket

<!\[if !supportLists\]>§ <!\[endif\]>input:

<!\[if !supportLists\]>· <!\[endif\]>s3 temp bucket

<!\[if !supportLists\]>· <!\[endif\]>s3 destination bucket

<!\[if !supportLists\]>· <!\[endif\]>file path

<!\[if !supportLists\]>· <!\[endif\]>file name

<!\[if !supportLists\]>§ <!\[endif\]>output: successful (True/False)

<!\[if !supportLists\]>· <!\[endif\]>UPDATE STATUS:

<!\[if !supportLists\]>o <!\[endif\]>L10 - call API to update file status in study DB to "done"

<!\[if !supportLists\]>· <!\[endif\]>ErrorSNS

<!\[if !supportLists\]>o <!\[endif\]>L3 - email/log error for Admin

<!\[if !supportLists\]>§ <!\[endif\]>input: error

<!\[if !supportLists\]>§ <!\[endif\]>output: "status : error"

<!\[if !supportLists\]>· <!\[endif\]>PROCESS COMPLETION SNS:

<!\[if !supportLists\]>o <!\[endif\]>L11 - email / log to Admin on summary or error

<!\[if !supportLists\]>§ <!\[endif\]>if error: call API to update file status in study DB to "error"

<!\[if !supportLists\]>§ <!\[endif\]>input: status

<!\[if !supportLists\]>§ <!\[endif\]>output: successful (True/False)

<!\[if !supportLists\]>· <!\[endif\]>USER DIGEST (This has to be post pipeline processing - separate Lambda not part of this step fn):

<!\[if !supportLists\]>o <!\[endif\]>L12 - (user digest) send batch summary to users

<!\[if !supportLists\]>§ <!\[endif\]>input: duration (last 24 hours etc.)

<!\[if !supportLists\]>§ <!\[endif\]>output: successful (True/False)

##### <!\[if !supportLists\]>5.1.2.2.8 <!\[endif\]>(AWS) BatchEDCAWS-93

<!\[if !vml\]>![_scroll_external/attachments/aws-batch-plan-xml-0ba6ff367a31e23af50a853fdd3b8314639f33723e69fe5bcd00f69a99323ae9.png](AWS%20Pipeline-v5-20190411_170412.fld/image016.jpg)<!\[endif\]>

#### <!\[if !supportLists\]>5.1.2.3 <!\[endif\]>Error Logs

Pipeline errors will be logged in the S3 bucket

<!\[if !supportLists\]>· <!\[endif\]>bucket name: atri-edc-trc-production-_\[aws account ID\]_

<!\[if !supportLists\]>· <!\[endif\]>source folder: image_pipelines

<!\[if !supportLists\]>· <!\[endif\]>file path: image\_pipelines/error\_logs/\[edcpipeline.code\]/

<!\[if !supportLists\]>· <!\[endif\]>file name: (matching closely with destination file name under quarantined folder)

<!\[if !supportLists\]>o <!\[endif\]>\[[ddcrf.name](http://ddcrf.name) (http://ddcrf.name)\]_\[[ddfile.name](http://ddfile.name) (http://ddfile.name)\]_\[participant code\]_\[event code\]_\[[subjecteventcrf.id](http://subjecteventcrf.id) (http://subjecteventcrf.id)\]_\[subjecteventcrffile.revisionnumber\]_\[[edcpipelinefile.id](http://edcpipelinefile.id) (http://edcpipelinefile.id)\]_\[timestamp\]\_error\_log.txt

##### <!\[if !supportLists\]>5.1.2.3.1 <!\[endif\]>Error Flags in the Database

scenario 1: edcpipelinefile.status = completed, but edcpipelinefile.has_error = True

<!\[if !supportLists\]>· <!\[endif\]>File is processed and is available in destination bucket quarantined folder, but some errors were generated during the process

<!\[if !supportLists\]>o <!\[endif\]>e.g. can't insert ATRIUID into the DICOM header etc.

scenario 2: edcpipelinefile.status = Failed

<!\[if !supportLists\]>· <!\[endif\]>File is not available in the destination bucket quarantined folder, something more seriously wrong during the process

##### <!\[if !supportLists\]>5.1.2.3.2 <!\[endif\]>Error Codes and their meaning

Please refer to [Pipeline Dictionary](#scroll-bookmark-3)

Q: should I promote error code to database table column? e.g. edcpipelinefileerrorlog.error_code

##### <!\[if !supportLists\]>5.1.2.3.3 <!\[endif\]>Error Notification Email

<!\[if !vml\]>![_scroll_external/attachments/image2019-3-22_0-29-26-3ea3e3f56b0b6afecd73ab5072b10bd1436be055e6ec637b98ffb29afb2d8efd.png](AWS%20Pipeline-v5-20190411_170412.fld/image018.jpg)<!\[endif\]>

### <!\[if !supportLists\]>5.1.3 <!\[endif\]>Relevant Data

#### <!\[if !supportLists\]>5.1.3.1 <!\[endif\]>ATRIUID / Batch script logic

<!\[if !vml\]>![_scroll_external/attachments/img_1369-1b6ac829ae406f5edc8a2dabbe4c7af5b39d225505079f7ddb12ee3d7cdb86ed.jpg](AWS%20Pipeline-v5-20190411_170412.fld/image019.jpg)<!\[endif\]>

#### <!\[if !supportLists\]>5.1.3.2 <!\[endif\]>Brainstorming Drawing Board

<!\[if !vml\]>![_scroll_external/attachments/img_1352-ac757a28186678e45fa0a20eef72449af4d66b0bfaf4b51c02dae2c209429c74.jpg](AWS%20Pipeline-v5-20190411_170412.fld/image020.jpg)<!\[endif\]>

[IMG_6233.HEIC](#scroll-bookmark-76)

#### <!\[if !supportLists\]>5.1.3.3 <!\[endif\]>TRC Amyloid PET Scan & Data Flow

[TRC\_PET\_Data_Flow.pdf](#scroll-bookmark-76)

### <!\[if !supportLists\]>5.1.4 <!\[endif\]>Pipeline Dictionary

#### <!\[if !supportLists\]>5.1.4.1 <!\[endif\]>Function List

code

description

lambda function

script

L1

Lambda

\\\[study portal name\]-imgpipe-query-info

L2

Lambda

imgpipe-submit-batch-job

S1

script processing image files

processDMC.py

L3

Lambda

imgpipe-get-batch-job-status

L4

Lambda

imgpipe-copy-to-destination

L5

Lambda

imgpipe-update-pipeline-status

L6

Lambda

imgpipe-notification-process-error

L7

Lambda

imgpipe-notification-process-completion

L8

Lambda

img-pipe-create-pipeline-job

L9

Lambda

img-pipe-invoke-step-function

#### <!\[if !supportLists\]>5.1.4.2 <!\[endif\]>Error List

code

meaning

ERRL1001

Missing expected input

ERRL1002

Failed to create db connection

ERRL1003

EDC record not found

ERRL1004

Failed to query EDC record

ERRL2001

Error submitting Batch Job.

ERRL2002

missing required input

ERRS1001

Missing expected input parameter.

ERRS1002

Failed to read DICOM file.

ERRS1003

Return subject\_event\_crf\_file\_id / pipeline\_code{} subject\_event\_crf\_file\_id / pipeline\_code {} does not match

ERRS1004

Failed to call API

ERRS1005

API returned failed response.

ERRS1006

ATRIUID is empty string in the api response.

ERRS1007

ATRIUID key not present in the api response for study\_uid {} and series\_uid {}.

ERRS1008

ATRUID insert failed for image with study\_uid {} and series\_uid {}.

ERRS1009

Failed to read DICOM file during ATRIUID insert for study\_uid {0} and series\_uid {1}

ERRS1010

Invalid input folder location.

ERRS1011

Input files missing in input folder

ERRL3001

ERRL4001

Missing required input

ERRL4002

Error copy file to destination

ERRL4003

API call failed

ERRL8001

Failed to call API

### <!\[if !supportLists\]>5.1.5 <!\[endif\]>Image Pipeline File Transfer Methods

Compare methods for external ATRI collaborators to transfer files to and from ATRI hosted s3 buckets.

CyberDuck/Mountain Duck

Commander One

Transfer SFTP

authentication

AWS access key + AWS secret key

AWS access key + AWS secret key

username/password

security

client-side encryption

connection

HTTPS

price

OpenSource/Free software

logs

s3 logs

s3 logs

usability

client

client

platform

macOS, Windows

mac only

setup/maintenance

Notes:

Direct connection to S3 method: s3:ListAllMyBuckets (listing all buckets or access denied error)

### <!\[if !supportLists\]>5.1.6 <!\[endif\]>Image Pipeline Process Flow Diagram - High Level

<!\[if !vml\]>![_scroll_external/attachments/image_pipeline_flow-drawio-6c6b3f4d344a46be0f49759aa8bc1cec20c36781692bd4622a303df6f54393df.png](AWS%20Pipeline-v5-20190411_170412.fld/image022.jpg)<!\[endif\]>

### <!\[if !supportLists\]>5.1.7 <!\[endif\]>Image Pipeline Components and Resources

#### <!\[if !supportLists\]>5.1.7.1 <!\[endif\]>EDC Plugin

##### <!\[if !supportLists\]>5.1.7.1.1 <!\[endif\]>Resources

<!\[if !supportLists\]>· <!\[endif\]>EDC_config: [https://github.com/atrihub/EDC_config](https://github.com/atrihub/EDC_config) (https://github.com/atrihub/EDC_config)

<!\[if !supportLists\]>o <!\[endif\]>EDC\_IMAGE\_PIPELINE_PLUGIN: flat to turn on and off plugin in EDC

<!\[if !supportLists\]>· <!\[endif\]>EDC: [https://github.com/atrihub/EDC](https://github.com/atrihub/EDC) (https://github.com/atrihub/EDC)

<!\[if !supportLists\]>o <!\[endif\]>settings: EDC\_IMAGE\_PIPELINE_PLUGIN

<!\[if !supportLists\]>o <!\[endif\]>authcore: image\_pipeline\_aws_integration group

<!\[if !supportLists\]>o <!\[endif\]>account management: authentication sync tool - (note: take it out in Phase I)

<!\[if !supportLists\]>· <!\[endif\]>edc-image-pipeline: [https://github.com/atrihub/edc-plugin-image-pipeline](https://github.com/atrihub/edc-image-pipeline) (https://github.com/atrihub/edc-image-pipeline)

<!\[if !supportLists\]>o <!\[endif\]>image pipeline models, APIs etc.

<!\[if !supportLists\]>· <!\[endif\]>S3 buckets:

<!\[if !supportLists\]>o <!\[endif\]>atri-edc-plugins-github-deployment

<!\[if !supportLists\]>§ <!\[endif\]>edc-plugin-image-pipeline

<!\[if !supportLists\]>· <!\[endif\]>batch

<!\[if !supportLists\]>· <!\[endif\]>docker

<!\[if !supportLists\]>· <!\[endif\]>lambda

<!\[if !supportLists\]>o <!\[endif\]>atri-edc-logs

#### <!\[if !supportLists\]>5.1.7.2 <!\[endif\]>Pipeline Architecture

##### <!\[if !supportLists\]>5.1.7.2.1 <!\[endif\]>Resources

<!\[if !supportLists\]>· <!\[endif\]>AWS-Deployment: [https://github.com/atrihub/AWS-Deployment](https://github.com/atrihub/AWS-Deployment) (https://github.com/atrihub/AWS-Deployment)

<!\[if !supportLists\]>o <!\[endif\]>Pipeline architecture

<!\[if !supportLists\]>§ <!\[endif\]>Lambda function code

<!\[if !supportLists\]>§ <!\[endif\]>Stepfunction configuration

<!\[if !supportLists\]>§ <!\[endif\]>Image file processing

<!\[if !supportLists\]>§ <!\[endif\]>Triggers

<!\[if !supportLists\]>§ <!\[endif\]>CloudFormation CI/CD scripts

#### <!\[if !supportLists\]>5.1.7.3 <!\[endif\]>Runbook

##### <!\[if !supportLists\]>5.1.7.3.1 <!\[endif\]>Resources

Box location: [https://atrihub.app.box.com/file/399829398942](https://atrihub.app.box.com/file/399829398942) (https://atrihub.app.box.com/file/399829398942)

#### <!\[if !supportLists\]>5.1.7.4 <!\[endif\]>Other Resources

<!\[if !supportLists\]>· <!\[endif\]>[Image Pipeline - Parking Lot](#scroll-bookmark-5)

### <!\[if !supportLists\]>5.1.8 <!\[endif\]>Image Pipeline Architecture Diagram

<!\[if !vml\]>![_scroll_external/attachments/untitled-diagram-drawio-99951be9a5ba7f9f935bb70cf0fa23261753124347f29bfa9c24abe2ee0c3f6d.png](AWS%20Pipeline-v5-20190411_170412.fld/image024.jpg)<!\[endif\]>

# <!\[if !supportLists\]>6 <!\[endif\]>Decision log

Create decision

Decision

Status

Stakeholders

Outcome

Due date

Owner

[EDC Image Pipeline Plugin - API](#scroll-bookmark-4)

**in progress**

[Image Pipeline - Parking Lot](#scroll-bookmark-5)

**in progress**

[Image Pipeline - ProcessDCM.py](#scroll-bookmark-6)

**not started**

[Image Pipeline - Step Function](#scroll-bookmark-122)

**in progress**

[Image Pipeline - Batch](#scroll-bookmark-123)

**not started**

[Image Pipeline - Lambda](#scroll-bookmark-124)

**in progress**

[AWS Consultant Suggestions Summary](#scroll-bookmark-125)

**in progress**

[EDC File Upload Improvements](#scroll-bookmark-59)

**paused**

[EDC Image Pipeline Plugin - Model](#scroll-bookmark-126)

**in progress**

## <!\[if !supportLists\]>6.1 <!\[endif\]>Decisions

Record important project decisions and communicate them with your team.

Create from template

## <!\[if !supportLists\]>6.2 <!\[endif\]>EDC File Upload Improvements

Add your comments directly to the page. Include links to any relevant research, data, or feedback.

**Status**

**paused**

**Impact**

**medium**

**Driver**

[Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq) (https://atrihub.atlassian.net/wiki/display/~hongmeiq)

**Approver**

**Contributors**

[Gustavo Jimenez-Maggiora](https://atrihub.atlassian.net/wiki/display/~gustavoj) (https://atrihub.atlassian.net/wiki/display/~gustavoj) [Jia-Shing So](https://atrihub.atlassian.net/wiki/display/~jiashins) (https://atrihub.atlassian.net/wiki/display/~jiashins) [Mihir Kavatkar](https://atrihub.atlassian.net/wiki/display/~kavatkar) (https://atrihub.atlassian.net/wiki/display/~kavatkar)

**Informed**

**Due date**

**Outcome**

### <!\[if !supportLists\]>6.2.1 <!\[endif\]>Background

File uploading is very slow via the EDC file attachment widget.

The issue is we are loading everything in memory when go through multiple layers to upload a file (GUI → API → Django → boto3 → write to S3 bucket).

We need to look into a more optimal solution to improve the performance of the file attachment widget.

### <!\[if !supportLists\]>6.2.2 <!\[endif\]>Relevant data

<!\[if !supportLists\]>· <!\[endif\]>AWS SDK for javascript

<!\[if !supportLists\]>o <!\[endif\]>[https://docs.aws.amazon.com/sdk-for-javascript/v2/developer-guide/s3-example-photo-album.html](https://docs.aws.amazon.com/sdk-for-javascript/v2/developer-guide/s3-example-photo-album.html) (https://docs.aws.amazon.com/sdk-for-javascript/v2/developer-guide/s3-example-photo-album.html)

<!\[if !supportLists\]>· <!\[endif\]>AWS Security Token Service STS

<!\[if !supportLists\]>o <!\[endif\]>[https://docs.aws.amazon.com/STS/latest/APIReference/Welcome.html](https://docs.aws.amazon.com/STS/latest/APIReference/Welcome.html) (https://docs.aws.amazon.com/STS/latest/APIReference/Welcome.html)

### <!\[if !supportLists\]>6.2.3 <!\[endif\]>Options considered

Upload file directory to s3 bucket using AWS SDK for Javascript and AWS STS (for authentication).

Flow:

Client browser file uploaded → calls Django API to get a session token via sts → with the access token AWS SDK for Javascript uploads the file into s3 bucket, returns object key → calls Django API to update SubjectEventCrfFile table with the file info

use STS assumed_role() to get the session token, set the duration to 300sec (min value):

(access key, secret key, session token) = sts.assumed\_role(upload\_only\_role\_policy, s3 key, duration seconds)

<!\[if !supportLists\]>· <!\[endif\]>important: make sure to scoping down the role to only upload a specific object

### <!\[if !supportLists\]>6.2.4 <!\[endif\]>Action items

<!\[if !supportLists\]> ![*](AWS%20Pipeline-v5-20190411_170412.fld/) <!\[endif\]>

### <!\[if !supportLists\]>6.2.5 <!\[endif\]>Outcome

## <!\[if !supportLists\]>6.3 <!\[endif\]>AWS Consultant Suggestions Summary

Add your comments directly to the page. Include links to any relevant research, data, or feedback.

**Status**

**in progress**

**Impact**

**medium**

**Driver**

[Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq) (https://atrihub.atlassian.net/wiki/display/~hongmeiq)

**Approver**

**Contributors**

[Pradeep Ravindranath](https://atrihub.atlassian.net/wiki/display/~paravindranath) (https://atrihub.atlassian.net/wiki/display/~paravindranath) [Gustavo Jimenez-Maggiora](https://atrihub.atlassian.net/wiki/display/~gustavoj) (https://atrihub.atlassian.net/wiki/display/~gustavoj) [Stefania Bruschi](https://atrihub.atlassian.net/wiki/display/~bruschi) (https://atrihub.atlassian.net/wiki/display/~bruschi) [Mihir Kavatkar](https://atrihub.atlassian.net/wiki/display/~kavatkar) (https://atrihub.atlassian.net/wiki/display/~kavatkar)

**Informed**

**Due date**

**Outcome**

### <!\[if !supportLists\]>6.3.1 <!\[endif\]>Summary

#### <!\[if !supportLists\]>6.3.1.1 <!\[endif\]>Runbook

<!\[if !supportLists\]>· <!\[endif\]>IAM user "atri-img-pipe-ec2-docker", Group "atri-img-pipe-ec2-docker" (item 7)

<!\[if !supportLists\]>o <!\[endif\]>If we push Docker from an EC2 instance instead of from local machine, we can use the role instead a user (timeline: future)

<!\[if !supportLists\]>· <!\[endif\]>NEVER grant the following policies:

<!\[if !supportLists\]>o <!\[endif\]>AmazonVPCFullAccess

<!\[if !supportLists\]>o <!\[endif\]>AmazonS3FullAccess

<!\[if !supportLists\]>· <!\[endif\]>Avoid using CloudWatchLogFullAccess policy, try AWSLambdaBasicExecutionRole

<!\[if !supportLists\]>· <!\[endif\]>IAM roles, one per study portal per image pipeline

<!\[if !supportLists\]>o <!\[endif\]>then per lambda

<!\[if !supportLists\]>§ <!\[endif\]>default: atri-lambda-basic-execution-role

<!\[if !supportLists\]>§ <!\[endif\]>query-read-replica: atri-edc-trc-dev-img-pipe-query-read-replica-lambda-role

<!\[if !supportLists\]>§ <!\[endif\]>submit-batch-job: atri-edc-trc-dev-img-pipe-submit-batch-job-lambda-role

<!\[if !supportLists\]>§ <!\[endif\]>get-batch-job-status: atri-edc-trc-dev-img-pipe-get-batch-job-status-lambda-role

<!\[if !supportLists\]>§ <!\[endif\]>copy-to-destination: atri-edc-trc-dev-img-pipe-copy-to-destination-lambda-role

#### <!\[if !supportLists\]>6.3.1.2 <!\[endif\]>CloudFormation

<!\[if !supportLists\]>· <!\[endif\]>Anything marked as custom script in runbook under "CloudFormation" column can be hooked into CloudFormation (as a lambda function) using [Custom Resources](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/template-custom-resources.html) (https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/template-custom-resources.html)

#### <!\[if !supportLists\]>6.3.1.3 <!\[endif\]>Docker

<!\[if !supportLists\]>· <!\[endif\]>When creating the temporary EC2 instance, do not use the same VPC for EDC/image pipeline (e.g. use the default VPC)

<!\[if !supportLists\]>· <!\[endif\]>Use the latest AMI for docker: amazonlinux:2018.03

#### <!\[if !supportLists\]>6.3.1.4 <!\[endif\]>Trigger

<!\[if !supportLists\]>· <!\[endif\]>since we have the CloudWatch logs, we don't need to setup the CloudTrail

### <!\[if !supportLists\]>6.3.2 <!\[endif\]>Relevant data

[Meeting notes](#scroll-bookmark-12)

[runbook](https://atrihub.app.box.com/file/399829398942) (https://atrihub.app.box.com/file/399829398942)

### <!\[if !supportLists\]>6.3.3 <!\[endif\]>Action items

<!\[if !supportLists\]> ![*](AWS%20Pipeline-v5-20190411_170412.fld/) <!\[endif\]>

### <!\[if !supportLists\]>6.3.4 <!\[endif\]>Outcome

## <!\[if !supportLists\]>6.4 <!\[endif\]>Design for unit testing

<!\[if !vml\]>![_scroll_external/attachments/was-unit-test-drawio-59d61c94905c4f1842d5ad2d6faced07246879327b3da967a64046b54fa0ec30.png](AWS%20Pipeline-v5-20190411_170412.fld/image026.jpg)<!\[endif\]>

Flow #1  
code stored in github -> pull request -> triggers test run on Travis CI -> result + coverage reports come back to Github

reference .travis.yml configuration: [https://github.com/nicor88/aws-python-lambdas/blob/master/.travis.yml](https://github.com/nicor88/aws-python-lambdas/blob/master/.travis.yml) (https://github.com/nicor88/aws-python-lambdas/blob/master/.travis.yml)

target: unit tests only for phase I

Lambda functions:

<!\[if !supportLists\]>1. <!\[endif\]>img-pipe-invoke-step-function.py

<!\[if !supportLists\]>2. <!\[endif\]>img-pipe-create-pipeline-job.py

<!\[if !supportLists\]>3. <!\[endif\]>img-pipe-query-read-replica.py

<!\[if !supportLists\]>4. <!\[endif\]>img-pipe-submit-batch-job.py

<!\[if !supportLists\]>5. <!\[endif\]>img-pipe-get-batch-job-status.py

<!\[if !supportLists\]>6. <!\[endif\]>img-pipe-copy-to-destination.py

<!\[if !supportLists\]>7. <!\[endif\]>img-pipe-notification-for-error.py

<!\[if !supportLists\]>8. <!\[endif\]>img-pipe-notification-for-completion.py

Image Processing script:

<!\[if !supportLists\]>1. <!\[endif\]>processDCM.py

.travis.yml template

language: python

python: '3.6'

sudo: false

\# We don't care about Travis' python versions, we install conda anyway

#env:

#  global:

#  \- AWS\_DEFAULT\_REGION=eu-west-1

#  \- PYTHONPATH=$TRAVIS\_BUILD\_DIR:$PYTHONPATH

install:

\- pip install awscli

\- pip install boto3

#  \# install libs from the requirements of each single lambda

#  \- for i in src/*/; do pip install -r $i"requirements.txt"; done

script:

\# run tests

\- pytest

#before_deploy:

#  \- mkdir -p dist

#  \# create zip for each lambda folder in src

#  \- for i in src/*/; do .travis/build_lambda.sh "$i"; done

#  \- cp src/*.zip dist

\# deploy:

#  provider:  s3

#  access\_key\_id:  $AWS\_ACCESS\_KEY_ID

#  secret\_access\_key: $AWS\_SECRET\_ACCESS_KEY

#  bucket:  $AWS_BUCKET

#  region:  $AWS\_BUCKET\_REGION

#  local_dir:  dist

#  upload-dir:  deployments/lambdas/travis_build

#  acl:  private # keep them private

#  skip_cleanup:  true

#  on:

#  all_branches: true

notifications:

email: false

Code Block 1 Travis.yml

## <!\[if !supportLists\]>6.5 <!\[endif\]>EDC Image Pipeline Plugin - Model

Add your comments directly to the page. Include links to any relevant research, data, or feedback.

**Status**

**in progress**

**Impact**

**low**

**Driver**

[Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq) (https://atrihub.atlassian.net/wiki/display/~hongmeiq)

**Approver**

**Contributors**

[Gustavo Jimenez-Maggiora](https://atrihub.atlassian.net/wiki/display/~gustavoj) (https://atrihub.atlassian.net/wiki/display/~gustavoj) [Stefania Bruschi](https://atrihub.atlassian.net/wiki/display/~bruschi) (https://atrihub.atlassian.net/wiki/display/~bruschi) [Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq) (https://atrihub.atlassian.net/wiki/display/~hongmeiq) [Pradeep Ravindranath](https://atrihub.atlassian.net/wiki/display/~paravindranath) (https://atrihub.atlassian.net/wiki/display/~paravindranath)

**Informed**

**Due date**

**Outcome**

### <!\[if !supportLists\]>6.5.1 <!\[endif\]>Database

File information tracked in the database tables.

#### <!\[if !supportLists\]>6.5.1.1 <!\[endif\]>Pipeline.EDCPipeline

register each pipeline (e.g. pipeline for image file, pipeline for audio files, etc.

Field

ID

Code

Label

DDFiles

#### <!\[if !supportLists\]>6.5.1.2 <!\[endif\]>pipeline.EDCPipelineFile

one pipeline execution per record, one source file can be processed more than once.

Field Name

ID

[EDCPipeline.id](http://EDCPipeline.id) (http://EDCPipeline.id)

[SubjectEventCrfFile.id](http://SubjectEventCrfFile.id) (http://SubjectEventCrfFile.id)

file_name

Status

Started, In Progress, Completed, Failed

has_error

T/F

#### <!\[if !supportLists\]>6.5.1.3 <!\[endif\]>pipeline.EDCPipelineFileDicom

Field Name

ID

[EDCPipelineFile.id](http://edcpipelinefile.id) (http://EDCPipelineFile.id)

ATRIUID

studyUID

serieUID

serienum

number\_of\_instances

### <!\[if !supportLists\]>6.5.2 <!\[endif\]>Action items

<!\[if !supportLists\]> ![*](AWS%20Pipeline-v5-20190411_170412.fld/) <!\[endif\]>

### <!\[if !supportLists\]>6.5.3 <!\[endif\]>Outcome

## <!\[if !supportLists\]>6.6 <!\[endif\]>EDC Image Pipeline Plugin - API

Add your comments directly to the page. Include links to any relevant research, data, or feedback.

**Status**

**in progress**

**Impact**

**low**

**Driver**

[Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq) (https://atrihub.atlassian.net/wiki/display/~hongmeiq)

**Approver**

**Contributors**

**Informed**

**Due date**

**Outcome**

### <!\[if !supportLists\]>6.6.1 <!\[endif\]>API

/pipeline/edcpipeline/file

input:

{

pipeline_code: xxx

subject\_event\_crf\_file\_id: xxx

*edc\_pipieline\_file_id: xxx (required for update)

}

output:

{

success: T/F

error_code: reference dictionary (only show if success is F)

error: xxxx (only show if success is F)

data: {"id": xxx, ...} // EDCPipelineFile object

}

/pipeline/edcpipeline/file/dicom/add\_scan\_info

<!\[if !supportLists\]>· <!\[endif\]>post

<!\[if !supportLists\]>o <!\[endif\]>request body (json)

input:

{

pipeline_code: xxx,

subject\_event\_crf\_file\_id: xxx,

edc\_pipieline\_file_id: xxxx

scans:\[

{

study_uid: xxx,

series: \[

{series\_uid: xxx, series\_number: yyy, number\_of\_instance: 123},

{series\_uid: blah, series\_number: halb, number\_of\_instance: 123},

...

\]

},

{

study_uid: xxx,

series: \[

{series\_uid: xxx, series\_number: yyy, number\_of\_instance: 123},

{series\_uid: blah, series\_number: halb, number\_of\_instance: 123}, ...

\]

}

}

output:

{

"success": true,

"error_code": reference dictionary (only show if success is F)

"error": xxxx (only show if success is F)

"data":

{

edc\_pipeline\_file_id: 123,

pipeline_code: xxx,

subject\_event\_crf\_file\_id: xxx,

scans: \[

{

"study_uid": xxx,

"series": \[

{"series_uid": aaa, "atri_uid": yyy},

{"series_uid": aaa, "atri_uid": ddd},

...

\]

},

{

"studyuid": xxx,

"series": \[

{"series_uid": aaa, "atri_uid": yyy},

{"series_uid": aaa, "atri_uid": ddd},

}

\]

}

}

### <!\[if !supportLists\]>6.6.2 <!\[endif\]>Action items

<!\[if !supportLists\]> ![*](AWS%20Pipeline-v5-20190411_170412.fld/) <!\[endif\]>

### <!\[if !supportLists\]>6.6.3 <!\[endif\]>Outcome

## <!\[if !supportLists\]>6.7 <!\[endif\]>Image Pipeline - Lambda

Add your comments directly to the page. Include links to any relevant research, data, or feedback.

**Status**

**in progress**

**Impact**

**low**

**Driver**

[Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq) (https://atrihub.atlassian.net/wiki/display/~hongmeiq)

**Approver**

**Contributors**

**Informed**

**Due date**

**Outcome**

### <!\[if !supportLists\]>6.7.1 <!\[endif\]>Naming convention

prefix + function name

<!\[if !supportLists\]>· <!\[endif\]>prefix = atri-edc-\[study portal instance\]-\[image pipeline code\]

<!\[if !supportLists\]>o <!\[endif\]>e.g. atri-edc-trc-dev-img-pipe-amypet

<!\[if !supportLists\]>· <!\[endif\]>function names:

<!\[if !supportLists\]>o <!\[endif\]>query-read-replica

<!\[if !supportLists\]>o <!\[endif\]>create-pipeline-job

<!\[if !supportLists\]>o <!\[endif\]>submit-batch-job

<!\[if !supportLists\]>o <!\[endif\]>get-batch-job-status

<!\[if !supportLists\]>o <!\[endif\]>copy-to-destination

<!\[if !supportLists\]>o <!\[endif\]>notification-for-error

<!\[if !supportLists\]>o <!\[endif\]>notification-for-completion

### <!\[if !supportLists\]>6.7.2 <!\[endif\]>Lambda Functions

<!\[if !supportLists\]>· <!\[endif\]>query-read-replica

<!\[if !supportLists\]>o <!\[endif\]>query EDC source file meta data info from EDC RDS read replica

<!\[if !supportLists\]>· <!\[endif\]>create-pipeline-job

<!\[if !supportLists\]>o <!\[endif\]>call image pipeline API to create a new job in the EDCPipelineFile table

<!\[if !supportLists\]>· <!\[endif\]>submit-batch-job

<!\[if !supportLists\]>o <!\[endif\]>create a new batch job to process the image file

<!\[if !supportLists\]>o <!\[endif\]>copy source file to workspace s3 bucket

<!\[if !supportLists\]>o <!\[endif\]>optimistically process file as DICOM format and insert ATRIUID into the DICOM header

<!\[if !supportLists\]>· <!\[endif\]>get-batch-job-status

<!\[if !supportLists\]>o <!\[endif\]>check batch job status

<!\[if !supportLists\]>· <!\[endif\]>copy-to-destination

<!\[if !supportLists\]>o <!\[endif\]>copy processed file from workspace to destination s3 bucket

<!\[if !supportLists\]>· <!\[endif\]>notification-for-error

<!\[if !supportLists\]>o <!\[endif\]>logs error message in s3 bucket

<!\[if !supportLists\]>o <!\[endif\]>send out notification to specific recipients

<!\[if !supportLists\]>· <!\[endif\]>notification-for-completion

<!\[if !supportLists\]>o <!\[endif\]>send out notification to specific recipients

### <!\[if !supportLists\]>6.7.3 <!\[endif\]>Reference

Runbook: [https://atrihub.app.box.com/file/399829398942](https://atrihub.app.box.com/file/399829398942) (https://atrihub.app.box.com/file/399829398942)

### <!\[if !supportLists\]>6.7.4 <!\[endif\]>Action items

<!\[if !supportLists\]> ![*](AWS%20Pipeline-v5-20190411_170412.fld/) <!\[endif\]>

### <!\[if !supportLists\]>6.7.5 <!\[endif\]>Outcome

## <!\[if !supportLists\]>6.8 <!\[endif\]>Image Pipeline - Step Function

Add your comments directly to the page. Include links to any relevant research, data, or feedback.

**Status**

**in progress**

**Impact**

**low**

**Driver**

[Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq) (https://atrihub.atlassian.net/wiki/display/~hongmeiq)

**Approver**

**Contributors**

**Informed**

**Due date**

**Outcome**

### <!\[if !supportLists\]>6.8.1 <!\[endif\]>Step Function

The main component of the pipeline, setup one per pipeline.

Carries the pipeline process through the lambda functions.

<!\[if !supportLists\]>· <!\[endif\]>triggered when a new file is uploaded / updated in S3 source bucket folder "subjecteventcrffile"

<!\[if !supportLists\]>· <!\[endif\]>Job name convention: \[[subject.id](http://subject.id) (http://subject.id)\]_\[[subjecteventcrf.id](http://subjecteventcrf.id) (http://subjecteventcrf.id)\]_\[[ddfile.name](http://ddfile.name) (http://ddfile.name)\]_\[file version code\]_\[timestamp\]

State Diagram

<!\[if !vml\]>![_scroll_external/attachments/screen-shot-2019-03-27-at-5-55-46-pm-51b5a6fa5b227bccf7ace72b58f570ec2a550b4abba1af74e28e334481c8b82a.png](AWS%20Pipeline-v5-20190411_170412.fld/image028.jpg)<!\[endif\]>

### <!\[if !supportLists\]>6.8.2 <!\[endif\]>Action items

<!\[if !supportLists\]> ![*](AWS%20Pipeline-v5-20190411_170412.fld/) <!\[endif\]>

### <!\[if !supportLists\]>6.8.3 <!\[endif\]>Outcome

## <!\[if !supportLists\]>6.9 <!\[endif\]>Image Pipeline - ProcessDCM.py

Add your comments directly to the page. Include links to any relevant research, data, or feedback.

**Status**

**not started**

**Impact**

**high** / **medium** / **low**

**Driver**

[Pradeep Ravindranath](https://atrihub.atlassian.net/wiki/display/~paravindranath) (https://atrihub.atlassian.net/wiki/display/~paravindranath)

**Approver**

[Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq) (https://atrihub.atlassian.net/wiki/display/~hongmeiq) [Stefania Bruschi](https://atrihub.atlassian.net/wiki/display/~bruschi) (https://atrihub.atlassian.net/wiki/display/~bruschi)

**Contributors**

**Informed**

**Due date**

**Outcome**

**Epic**

[PIPE-1](https://atrihub.atlassian.net/browse/PIPE-1) (https://atrihub.atlassian.net/browse/PIPE-1)

### <!\[if !supportLists\]>6.9.1 <!\[endif\]>Background

### <!\[if !supportLists\]>6.9.2 <!\[endif\]>Relevant data

### <!\[if !supportLists\]>6.9.3 <!\[endif\]>Options considered

Option 1:

Option 2:

**Description**

**Pros and cons**

<!\[if !vml\]>![_scroll_external/icons/add-4f14d566cd4def8f170c1c0b689648e053a4bfb56dc2974f2dde0f1d3328fb60.png](AWS%20Pipeline-v5-20190411_170412.fld/image030.jpg)<!\[endif\]>

<!\[if !vml\]>![_scroll_external/icons/forbidden-91ed7a9569c7f6084f7bfe65768d1813d768cfcd981b61d137b79eabd1f0fe11.png](AWS%20Pipeline-v5-20190411_170412.fld/image032.jpg)<!\[endif\]>

<!\[if !vml\]>![_scroll_external/icons/add-4f14d566cd4def8f170c1c0b689648e053a4bfb56dc2974f2dde0f1d3328fb60.png](AWS%20Pipeline-v5-20190411_170412.fld/image030.jpg)<!\[endif\]>

<!\[if !vml\]>![_scroll_external/icons/forbidden-91ed7a9569c7f6084f7bfe65768d1813d768cfcd981b61d137b79eabd1f0fe11.png](AWS%20Pipeline-v5-20190411_170412.fld/image032.jpg)<!\[endif\]>

**Estimated cost**

**large**

**medium**

### <!\[if !supportLists\]>6.9.4 <!\[endif\]>Action items

<!\[if !supportLists\]> ![*](AWS%20Pipeline-v5-20190411_170412.fld/) <!\[endif\]>

Updating the package name from pre-package-source to pre\_package\_source to resolve import issue[<!\[if !vml\]>![_scroll_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](AWS%20Pipeline-v5-20190411_170412.fld/image010.jpg)<!\[endif\]>PIPE-39](https://atrihub.atlassian.net/browse/PIPE-39?src=confmacro) (https://atrihub.atlassian.net/browse/PIPE-39?src=confmacro) - ** in review**  
Adding python path to travis.yml[<!\[if !vml\]>![_scroll_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](AWS%20Pipeline-v5-20190411_170412.fld/image010.jpg)<!\[endif\]>PIPE-40](https://atrihub.atlassian.net/browse/PIPE-40?src=confmacro) (https://atrihub.atlassian.net/browse/PIPE-40?src=confmacro) - ** in review**

processDCM_refactor.py[<!\[if !vml\]>![_scroll_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](AWS%20Pipeline-v5-20190411_170412.fld/image010.jpg)<!\[endif\]>PIPE-46](https://atrihub.atlassian.net/browse/PIPE-46?src=confmacro) (https://atrihub.atlassian.net/browse/PIPE-46?src=confmacro) - ** in review**

<!\[if !supportLists\]>1. <!\[endif\]>Refactor the code

test\_dcm\_check.py[<!\[if !vml\]>![_scroll_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](AWS%20Pipeline-v5-20190411_170412.fld/image010.jpg)<!\[endif\]>PIPE-45](https://atrihub.atlassian.net/browse/PIPE-45?src=confmacro) (https://atrihub.atlassian.net/browse/PIPE-45?src=confmacro) - ** in review**

<!\[if !supportLists\]>1. <!\[endif\]>Add test case for pipeline code, extract meta and subject\_event\_crf\_file\_id

<!\[if !supportLists\]>2. <!\[endif\]>Add comments to test\_insert\_atriuid

<!\[if !supportLists\]>3. <!\[endif\]>fix the import statement

<!\[if !supportLists\]>4. <!\[endif\]>add path variable for input folder location

test\_dcm\_check\_for\_failure[<!\[if !vml\]>![_scroll_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](AWS%20Pipeline-v5-20190411_170412.fld/image010.jpg)<!\[endif\]>PIPE-47](https://atrihub.atlassian.net/browse/PIPE-47?src=confmacro) (https://atrihub.atlassian.net/browse/PIPE-47?src=confmacro) - ** in review**

<!\[if !supportLists\]>1. <!\[endif\]>Add a test case to test failure scenario of dcm

test\_for\_atri\_uid\_in_data[<!\[if !vml\]>![_scroll_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](AWS%20Pipeline-v5-20190411_170412.fld/image010.jpg)<!\[endif\]>PIPE-48](https://atrihub.atlassian.net/browse/PIPE-48?src=confmacro) (https://atrihub.atlassian.net/browse/PIPE-48?src=confmacro) - ** in review**

test\_for\_atri\_uid\_key\_not\_present\_in\_data[<!\[if !vml\]>![_scroll_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](AWS%20Pipeline-v5-20190411_170412.fld/image010.jpg)<!\[endif\]>PIPE-49](https://atrihub.atlassian.net/browse/PIPE-49?src=confmacro) (https://atrihub.atlassian.net/browse/PIPE-49?src=confmacro) - ** in review**

test\_for\_non\_dicom\_files[<!\[if !vml\]>![_scroll_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](AWS%20Pipeline-v5-20190411_170412.fld/image010.jpg)<!\[endif\]>PIPE-50](https://atrihub.atlassian.net/browse/PIPE-50?src=confmacro) (https://atrihub.atlassian.net/browse/PIPE-50?src=confmacro) - ** in review**

test\_for\_error_messages[<!\[if !vml\]>![$iconUrl](AWS%20Pipeline-v5-20190411_170412.fld/image034.jpg)<!\[endif\]>PIPE-55](https://atrihub.atlassian.net/browse/PIPE-55?src=confmacro) (https://atrihub.atlassian.net/browse/PIPE-55?src=confmacro) ( <!\[if !vml\]>![$statusIcon](AWS%20Pipeline-v5-20190411_170412.fld/image035.jpg)<!\[endif\]>  )

Add a non dicom file for test[<!\[if !vml\]>![_scroll_external/remote/viewavatar-ce35ef42002ee78f375d9cc5729af4363e774d106c6e020eabe990d1394ab56c](AWS%20Pipeline-v5-20190411_170412.fld/image010.jpg)<!\[endif\]>PIPE-51](https://atrihub.atlassian.net/browse/PIPE-51?src=confmacro) (https://atrihub.atlassian.net/browse/PIPE-51?src=confmacro) - ** in review**

<!\[if !vml\]>![_scroll_external/attachments/screen-shot-2019-04-02-at-4-30-05-pm-7b46a643546bd1b5f5251108c6bfccf3b9bb147ae476c50a2025d60be9b7e035.png](AWS%20Pipeline-v5-20190411_170412.fld/image037.jpg)<!\[endif\]>

### <!\[if !supportLists\]>6.9.5 <!\[endif\]>Outcome

## <!\[if !supportLists\]>6.10 <!\[endif\]>Image Pipeline - Batch

Add your comments directly to the page. Include links to any relevant research, data, or feedback.

**Status**

**not started**

**Impact**

**high** / **medium** / **low**

**Driver**

[Pradeep Ravindranath](https://atrihub.atlassian.net/wiki/display/~paravindranath) (https://atrihub.atlassian.net/wiki/display/~paravindranath)

**Approver**

**Contributors**

**Informed**

**Due date**

**Outcome**

### <!\[if !supportLists\]>6.10.1 <!\[endif\]>Background

### <!\[if !supportLists\]>6.10.2 <!\[endif\]>Relevant data

### <!\[if !supportLists\]>6.10.3 <!\[endif\]>Options considered

Option 1:

Option 2:

**Description**

**Pros and cons**

<!\[if !vml\]>![_scroll_external/icons/add-4f14d566cd4def8f170c1c0b689648e053a4bfb56dc2974f2dde0f1d3328fb60.png](AWS%20Pipeline-v5-20190411_170412.fld/image030.jpg)<!\[endif\]>

<!\[if !vml\]>![_scroll_external/icons/forbidden-91ed7a9569c7f6084f7bfe65768d1813d768cfcd981b61d137b79eabd1f0fe11.png](AWS%20Pipeline-v5-20190411_170412.fld/image032.jpg)<!\[endif\]>

<!\[if !vml\]>![_scroll_external/icons/add-4f14d566cd4def8f170c1c0b689648e053a4bfb56dc2974f2dde0f1d3328fb60.png](AWS%20Pipeline-v5-20190411_170412.fld/image030.jpg)<!\[endif\]>

<!\[if !vml\]>![_scroll_external/icons/forbidden-91ed7a9569c7f6084f7bfe65768d1813d768cfcd981b61d137b79eabd1f0fe11.png](AWS%20Pipeline-v5-20190411_170412.fld/image032.jpg)<!\[endif\]>

**Estimated cost**

**large**

**medium**

### <!\[if !supportLists\]>6.10.4 <!\[endif\]>Action items

<!\[if !supportLists\]> ![*](AWS%20Pipeline-v5-20190411_170412.fld/) <!\[endif\]>

### <!\[if !supportLists\]>6.10.5 <!\[endif\]>Outcome

## <!\[if !supportLists\]>6.11 <!\[endif\]>Image Pipeline - Parking Lot

Add your comments directly to the page. Include links to any relevant research, data, or feedback.

**Status**

**in progress**

**Impact**

**low**

**Driver**

[Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq) (https://atrihub.atlassian.net/wiki/display/~hongmeiq)

**Approver**

**Contributors**

**Informed**

**Due date**

**Outcome**

### <!\[if !supportLists\]>6.11.1 <!\[endif\]>Immediate Needs

<!\[if !supportLists\]> ![*](AWS%20Pipeline-v5-20190411_170412.fld/) <!\[endif\]>relocate scripts (processDCM, lambda) from workspace bucket to a central bucket

<!\[if !supportLists\]>o <!\[endif\]>name: atri-edc-plugins-github-deployment

<!\[if !supportLists\]>o <!\[endif\]>location:

<!\[if !supportLists\]>§ <!\[endif\]>processDCM: /edc-plugin-image-pipeline/batch/job\_def\_scripts/

<!\[if !supportLists\]>§ <!\[endif\]>docker: /edc-plugin-image-pipeline/docker/

<!\[if !supportLists\]>§ <!\[endif\]>lambda functions: /edc-plugin-image-pipeline/lambda/

<!\[if !supportLists\]> ![*](AWS%20Pipeline-v5-20190411_170412.fld/) <!\[endif\]>log errors in a central log bucket

<!\[if !supportLists\]>o <!\[endif\]>name: atri-edc-logs

<!\[if !supportLists\]>o <!\[endif\]>location: /\[study\]/edc-plugin-image-pipeline/

<!\[if !supportLists\]> ![*](AWS%20Pipeline-v5-20190411_170412.fld/) <!\[endif\]>add edc user for API call with privs to image-pipeline-aws-integration to EDC_Config

<!\[if !supportLists\]>o <!\[endif\]>name: image-pipeline-aws-integration-bot

<!\[if !supportLists\]> ![*](AWS%20Pipeline-v5-20190411_170412.fld/) <!\[endif\]>setup google mailing lists:

<!\[if !supportLists\]>o <!\[endif\]>trc-img-pipe-amypet-l@atrihub.io

<!\[if !supportLists\]>o <!\[endif\]>trc-img-pipe-admin-l@atrihub.io

<!\[if !supportLists\]> ![*](AWS%20Pipeline-v5-20190411_170412.fld/) <!\[endif\]>rename github repo edc-image-pipeline to **edc-plugin-image-pipeline**

<!\[if !supportLists\]> ![*](AWS%20Pipeline-v5-20190411_170412.fld/) <!\[endif\]>rename processDCM.py to process_dicom.py

<!\[if !supportLists\]> ![*](AWS%20Pipeline-v5-20190411_170412.fld/) <!\[endif\]>migrate image_pipeline folder from AWS-Deployment, edc-plugin-image-pipeline repo

<!\[if !supportLists\]> ![*](AWS%20Pipeline-v5-20190411_170412.fld/) <!\[endif\]>review CloudWatch logs make sure they are all traceable, e.g. include information such as study, pipeline, image type, file id, timestamp etc. (this will be a continuous project through phase I and phase II)

### <!\[if !supportLists\]>6.11.2 <!\[endif\]>Phase II

<!\[if !supportLists\]>· <!\[endif\]>data export API for image inventory:

<!\[if !supportLists\]>o <!\[endif\]>EDCPipeline

<!\[if !supportLists\]>o <!\[endif\]>EDCPipelineFile

<!\[if !supportLists\]>o <!\[endif\]>EDCPipelineDicom

<!\[if !supportLists\]>· <!\[endif\]>step function handle additional state 'status' = skip for query read replica lambda function (re-evaluate whether we need this state before implement)

<!\[if !supportLists\]>· <!\[endif\]>Digest email notification (weekly, daily summary)

<!\[if !supportLists\]>· <!\[endif\]>Revisit ProcessDCM logging error messages

<!\[if !supportLists\]>o <!\[endif\]>currently logged in CloudWatch logs through print

<!\[if !supportLists\]>o <!\[endif\]>determine whether we can utilize Emil's approach

<!\[if !supportLists\]>· <!\[endif\]>(evaluate) RDS Read Replica (R&D required)

<!\[if !supportLists\]>o <!\[endif\]>if we can restrict access through policies, we may not need this replica

<!\[if !supportLists\]>· <!\[endif\]>(evaluate) dispose workspace image files after execution is completed

<!\[if !supportLists\]>· <!\[endif\]>process ECAT

<!\[if !supportLists\]>· <!\[endif\]>update lambda query read replica to query API token info from EDC for user image-pipeline-aws-integration-bot

<!\[if !supportLists\]>· <!\[endif\]>fetch\_and\_run.sh (docker)

<!\[if !supportLists\]>· <!\[endif\]>replace arn:aws:lambda:us-east-1:898466741470:layer:psycopg2-py37:2 with our own layer in our account

### <!\[if !supportLists\]>6.11.3 <!\[endif\]>Future

<!\[if !supportLists\]>· <!\[endif\]>Codepipeline + Codebuild → deploy updated Lambda and processDCM code from Github

<!\[if !supportLists\]>· <!\[endif\]>revisit code versioning (currently using Github for version control)

<!\[if !supportLists\]>· <!\[endif\]>automate step to create RDS read replica (based on answers we found in Phase II, we may drop this)

<!\[if !supportLists\]>· <!\[endif\]>GUI register new pipeline in EDC? (TBD)

<!\[if !supportLists\]>· <!\[endif\]>Report error messages from s3 bucket

### <!\[if !supportLists\]>6.11.4 <!\[endif\]>Action items

<!\[if !supportLists\]> ![*](AWS%20Pipeline-v5-20190411_170412.fld/) <!\[endif\]>

### <!\[if !supportLists\]>6.11.5 <!\[endif\]>Outcome

# <!\[if !supportLists\]>7 <!\[endif\]>How-to articles

Add how-to article

  

Title

Creator

Modified

[Setup A new Image Pipeline](#scroll-bookmark-9)

[Hongmei Qiu](https://atrihub.atlassian.net/people/557058:0e04da62-9320-49f9-8df3-3a744f02137a?ref=confluence) (https://atrihub.atlassian.net/people/557058:0e04da62-9320-49f9-8df3-3a744f02137a?ref=confluence)

Mar 27, 2019

[How to manually trigger image pipeline in step function](#scroll-bookmark-10)

[Hongmei Qiu](https://atrihub.atlassian.net/people/557058:0e04da62-9320-49f9-8df3-3a744f02137a?ref=confluence) (https://atrihub.atlassian.net/people/557058:0e04da62-9320-49f9-8df3-3a744f02137a?ref=confluence)

Mar 22, 2019

## <!\[if !supportLists\]>7.1 <!\[endif\]>Setup A new Image Pipeline

### <!\[if !supportLists\]>7.1.1 <!\[endif\]>Runbook

[https://atrihub.app.box.com/file/399829398942](https://atrihub.app.box.com/file/399829398942) (https://atrihub.app.box.com/file/399829398942)

### <!\[if !supportLists\]>7.1.2 <!\[endif\]>Step 0

(notes to [Hongmei Qiu](https://atrihub.atlassian.net/wiki/display/~hongmeiq) (https://atrihub.atlassian.net/wiki/display/~hongmeiq): improve this!)

register a new pipeline with code and label info in the EDCPipeline table via Django Admin tool.

### <!\[if !supportLists\]>7.1.3 <!\[endif\]>CI/CD

github repo: [https://github.com/atrihub/AWS-Deployment](https://github.com/atrihub/AWS-Deployment) (https://github.com/atrihub/AWS-Deployment)

run script: sh image\_pipeline/cloudformation/scripts/create\_image_pipeline.sh \[configuration file\]

Script can be run multiple times on the same configuration, if a component is already setup, the script will skip that component

#### <!\[if !supportLists\]>7.1.3.1 <!\[endif\]>Ouptput

pending...

#### <!\[if !supportLists\]>7.1.3.2 <!\[endif\]>Configuration File

location: image_pipeline/cloudformation/config

file format: plain text

file name suggestion: \[study portal instance name\]-\[pipeline code\].config

##### <!\[if !supportLists\]>7.1.3.2.1 <!\[endif\]>Variables

pending...

##### <!\[if !supportLists\]>7.1.3.2.2 <!\[endif\]>Example

######### you may change the following variables based on the study portal, image type etc.

DEBUG=false

IS_PRODUCTION=false

AWS_PROFILE='sand-informatics'

AWS\_PROFILE\_DR='dr'

\# Pipeline code registered in EDC

EDC\_PIPELINE\_CODE='amypet'

\# Image Type: default to use EDC pipeline code if it is short enough

IMG\_TYPE=$EDC\_PIPELINE_CODE

\# EDC Elastic Beanstalk and RDS instances

EDC\_EB\_APP='IMAGE-PIPELINE'

EDC\_EB\_ENV='hq-trc-dev'

RDS\_READ\_REPLICA=$EDC\_EB\_ENV"-aurora"

EDC_HOST='hq-trc-dev.atrihub.mobi'

\# tags

TAG_STUDY='trc'

TAG_ENVIRONMENT='development'

TAG_PIPELINE='image'

TAG\_IMG\_TYPE=$IMG_TYPE

\# VPC

VPC_NAME='sandbox'

\# image process script

IMG_SCRIPT='file://image_pipeline/scripts/processDCM.py'

\# Email Notifications, comma separated

EMAIL_ERROR="hongmeiq@atrihub.io"

EMAIL_COMPLETION="hongmeiq@usc.edu"

######### provide a good reason when updating the following variables

\# Pipeline Name

PIPELINE\_NAME=$EDC\_EB_ENV"-img-pipe-"$IMG_TYPE

\# S3 buckets

SOURCE\_BUCKET\_PREFIX=$EDC\_EB\_ENV

DESTINATION\_BUCKET\_PREFIX=$SOURCE\_BUCKET\_PREFIX"-img-"$IMG_TYPE

WORKSPACE\_BUCKET\_PREFIX=$DESTINATION\_BUCKET\_PREFIX"-ws"

\# EC2 key pairs

EC2\_KEY\_DOCKER="atri-img-pipe-ec2-docker"

EC2\_KEY\_BATCH_DEBUG="atri-img-pipe-batch-debug"

\# Container image

\# ECR\_REPO\_NAME='atri-image-pipeline-docker-201803'

ECR\_REPO\_NAME="par-custom-fetch-and-run-new"

\# IAM roles

ROLE\_PREFIX=$PIPELINE\_NAME

LAMBDA\_ROLE\_SUFFIX="-lambda-role"

BATCH\_SERVICE\_ROLE="AWSBatchServiceRole"

BATCH\_INSTANCE\_PROFILE="AWSBatchInstanceProfile"

BATCH\_JOB\_ROLE=$ROLE_PREFIX"-batch-job-role"

LAMBDA\_BASIC\_ROLE='atri-lambda-basic-execution-role'

LAMBDA\_QUERY\_READ\_REPLICA\_ROLE=$ROLE_PREFIX"-query-read-replica"$LAMBDA\_ROLE\_SUFFIX

LAMBDA\_SUBMIT\_BATCH\_JOB\_ROLE=$ROLE_PREFIX"-submit-batch-job"$LAMBDA\_ROLE\_SUFFIX

LAMBDA\_GET\_BATCH\_JOB\_STATUS\_ROLE=$ROLE\_PREFIX"-get-batch-job-status"$LAMBDA\_ROLE\_SUFFIX

LAMBDA\_COPY\_TO\_DESTINATION\_ROLE=$ROLE_PREFIX"-copy-to-destination"$LAMBDA\_ROLE\_SUFFIX

LAMBDA\_NOTIFICATION\_ROLE=$ROLE_PREFIX"-notification"$LAMBDA\_ROLE\_SUFFIX

STEP\_FUNCTION\_ROLE=$ROLE_PREFIX"-step-function-role"

CLOUDWATCH\_ROLE=$EDC\_EB_ENV"-img-pipe-cloudwatch-role"

\# Lambda functions

LAMBDA\_QUERY\_READ\_REPLICA=$PIPELINE\_NAME"-query-read-replica"

LAMBDA\_CREATE\_PIPELINE\_JOB=$PIPELINE\_NAME"-create-pipeline-job"

LAMBDA\_SUBMIT\_BATCH\_JOB=$PIPELINE\_NAME"-submit-batch-job"

LAMBDA\_GET\_BATCH\_JOB\_STATUS=$PIPELINE_NAME"-get-batch-job-status"

LAMBDA\_COPY\_TO\_DESTINATION=$PIPELINE\_NAME"-copy-to-destination"

LAMBDA\_NOTIFICATION\_FOR\_ERROR=$PIPELINE\_NAME"-notification-for-error"

LAMBDA\_NOTIFICATION\_FOR\_COMPLETION=$PIPELINE\_NAME"-notification-for-completion"

\# CloudFormation stacks

IAM\_ROLE\_CF\_STACK=$EDC\_EB_ENV"-img-pipe-"$IMG_TYPE"-roles"

BATCH\_CF\_STACK=$EDC\_EB\_ENV"-img-pipe-"$IMG_TYPE"-batch"

LAMBDA\_CF\_STACK=$EDC\_EB\_ENV"-img-pipe-"$IMG_TYPE"-lambda"

STEP\_FN\_CF\_STACK=$EDC\_EB_ENV"-img-pipe-"$IMG_TYPE"-step-fn"

TRIGGER\_CF\_STACK=$EDC\_EB\_ENV"-img-pipe-trigger"

Code Block 2 pipeline config file example

### <!\[if !supportLists\]>7.1.4 <!\[endif\]>Brainstorming (archive this to a decision log)

#### <!\[if !supportLists\]>7.1.4.1 <!\[endif\]>Prerequisite

<!\[if !supportLists\]>· <!\[endif\]>Github repo:

<!\[if !supportLists\]>o <!\[endif\]>AWS-Deployment

<!\[if !supportLists\]>o <!\[endif\]>EDC

<!\[if !supportLists\]>o <!\[endif\]>EDC-Pipeline (future)

<!\[if !supportLists\]>· <!\[endif\]>EDC study portal

<!\[if !supportLists\]>o <!\[endif\]>readonly replica

<!\[if !supportLists\]>o <!\[endif\]>pipeline plug-in (future)

<!\[if !supportLists\]>· <!\[endif\]>S3 buckets:

<!\[if !supportLists\]>o <!\[endif\]>EDC study portal bucket (source)

<!\[if !supportLists\]>§ <!\[endif\]>naming convention: atri-edc-studyportal-aws\_account\_id

<!\[if !supportLists\]>o <!\[endif\]>Image pipeline destination bucket (target)

<!\[if !supportLists\]>§ <!\[endif\]>naming convention: atri-edc-studyportal-img-aws\_account\_id

<!\[if !supportLists\]>o <!\[endif\]>Image pipeline workspace bucket (workspace)

<!\[if !supportLists\]>§ <!\[endif\]>naming convention: atri-edc-studyportal-img-workspace-aws\_account\_id

<!\[if !supportLists\]>o <!\[endif\]>1 source vs 1 target vs 1 workspace

<!\[if !supportLists\]>§ <!\[endif\]>**area to improve**

<!\[if !supportLists\]>· <!\[endif\]>Docker

<!\[if !supportLists\]>o <!\[endif\]>IAM user with credential to push to EC2 and ECS instances

<!\[if !supportLists\]>§ <!\[endif\]>example on sandbox: user par-ec2-to-ecr with group par-aws-cli-access

<!\[if !supportLists\]>§ <!\[endif\]>**area to improve**

<!\[if !supportLists\]>o <!\[endif\]>EC2 key pair 1 - docker

<!\[if !supportLists\]>· <!\[endif\]>EC2 key pair 2 - debug batch computing environment

#### <!\[if !supportLists\]>7.1.4.2 <!\[endif\]>EDC Pipeline Plugin

pending...

Currently the pipeline code is in EDC github repo branch hq_pipeline

Create a CodePipeline (CodeBuild) that pushes EDC code to EDC study portal

#### <!\[if !supportLists\]>7.1.4.3 <!\[endif\]>Batch

##### <!\[if !supportLists\]>7.1.4.3.1 <!\[endif\]>Part 1: Docker

Download AWS-Deployment Github zip

Launch EC2 instance via AWS console

<!\[if !supportLists\]>· <!\[endif\]>create new instance

<!\[if !supportLists\]>o <!\[endif\]>make sure only use the free tier one

<!\[if !supportLists\]>· <!\[endif\]>use "Amazon Linux AMI 2018.03.0 (HVM), SSD Volume Type" (ami-0080e4c5bc078760e)

<!\[if !supportLists\]>· <!\[endif\]>no other overrides, use the default values

<!\[if !supportLists\]>· <!\[endif\]>**(area to improve the security: VPC)**

<!\[if !supportLists\]>· <!\[endif\]>choose a key pair 1 - to shell into the EC2 instance

<!\[if !supportLists\]>· <!\[endif\]>follow the popup instruction to shell into the instance

<!\[if !supportLists\]>o <!\[endif\]>scp -i ~/.ssh/your\_ssh\_key path\_to\_AWS-Deployment\_zip\_file EC2\_instance\_string:~/

<!\[if !supportLists\]>§ <!\[endif\]>EC2_instance string example: ec2-user@ec2-3-92-236-127.compute-1.amazonaws.com:~/.

<!\[if !supportLists\]>o <!\[endif\]>shell in to EC2 instance, unzip AWS-Deployment Github zip file

<!\[if !supportLists\]>o <!\[endif\]>setup IAM user credential to perform aws cli commands, so we can push to EC2 and ECS instances in the future

<!\[if !supportLists\]>§ <!\[endif\]>aws configure

<!\[if !supportLists\]>o <!\[endif\]>update the package:

<!\[if !supportLists\]>§ <!\[endif\]>sudo yum update -y

<!\[if !supportLists\]>o <!\[endif\]>Install Docker:

<!\[if !supportLists\]>§ <!\[endif\]>sudo yum install docker -y

<!\[if !supportLists\]>o <!\[endif\]>Start docker service

<!\[if !supportLists\]>§ <!\[endif\]>sudo service docker start

<!\[if !supportLists\]>o <!\[endif\]>Add the ec2-user to the docker group so you can execute Docker commands without using sudo.

<!\[if !supportLists\]>§ <!\[endif\]>sudo usermod -a -G docker ec2-user

<!\[if !supportLists\]>o <!\[endif\]>if error: no basic auth credentials

<!\[if !supportLists\]>§ <!\[endif\]>eval $(aws ecr get-login --no-include-email | sed 's|https://||')

<!\[if !supportLists\]>· <!\[endif\]>return: docker login ....

<!\[if !supportLists\]>§ <!\[endif\]>sudo docker login ...

<!\[if !supportLists\]>o <!\[endif\]>go to AWS-Deployment folder: /trc\_image\_pipeline/pre-packaged-source/docker

<!\[if !supportLists\]>o <!\[endif\]>create / update docker image in ECR within EC2 instance

<!\[if !supportLists\]>§ <!\[endif\]>sh _build\_and\_push.sh_ <ECR image name>

<!\[if !supportLists\]>§ <!\[endif\]>note: batch script to process the images (AWS-Deployment)

note: after dock image is created and stored to ECR, we can terminate the EC2 instance

##### <!\[if !supportLists\]>7.1.4.3.2 <!\[endif\]>Part 1.1: Creating an encrypted compute resource AMI

Launch EC2 instance via AWS console

<!\[if !supportLists\]>· <!\[endif\]>create new instance

<!\[if !supportLists\]>o <!\[endif\]>make sure only use the free tier one

<!\[if !supportLists\]>· <!\[endif\]>use "Amazon Linux AMI 2018.03.0 (HVM), SSD Volume Type" (ami-0080e4c5bc078760e)

<!\[if !supportLists\]>· <!\[endif\]>no other overrides, use the default values

<!\[if !supportLists\]>· <!\[endif\]>choose a key pair 1 - to shell into the EC2 instance

<!\[if !supportLists\]>· <!\[endif\]>shell into EC2 instance

<!\[if !supportLists\]>· <!\[endif\]>update the package:

<!\[if !supportLists\]>o <!\[endif\]>sudo yum update -y

<!\[if !supportLists\]>· <!\[endif\]>Install Docker:

<!\[if !supportLists\]>o <!\[endif\]>sudo yum install docker -y

<!\[if !supportLists\]>· <!\[endif\]>Start docker service

<!\[if !supportLists\]>o <!\[endif\]>sudo service docker start

<!\[if !supportLists\]>· <!\[endif\]>Add the ec2-user to the docker group so you can execute Docker commands without using sudo.

<!\[if !supportLists\]>o <!\[endif\]>sudo usermod -a -G docker ec2-user

<!\[if !supportLists\]>· <!\[endif\]>Install the ecs agent

<!\[if !supportLists\]>o <!\[endif\]>sudo yum install -y ecs-init

<!\[if !supportLists\]>o <!\[endif\]>(optional) sudo start ecs

<!\[if !supportLists\]>· <!\[endif\]>Create /etc/ecs/ecs.config

<!\[if !supportLists\]>o <!\[endif\]>insert the following lines:  
ECS\_ENABLE\_TASK\_IAM\_ROLE=true  
ECS\_ENABLE\_TASK\_IAM\_ROLE\_NETWORK\_HOST=true  
ECS_LOGFILE=/log/ecs-agent.log  
ECS\_AVAILABLE\_LOGGING_DRIVERS=\["json-file","awslogs"\]  
ECS_LOGLEVEL=info  
ECS_CLUSTER=_default  
<!\[if !supportLineBreakNewLine\]>  
<!\[endif\]>_

<!\[if !supportLists\]>· <!\[endif\]>(optional) sudo stop ecs

<!\[if !supportLists\]>· <!\[endif\]>sudo rm -rf /var/lib/ecs/data/ecs\_agent\_data.json

<!\[if !supportLists\]>· <!\[endif\]>Create and encrypt AMI:

<!\[if !supportLists\]>o <!\[endif\]>Select the instance

<!\[if !supportLists\]>o <!\[endif\]>choose Actions → Image → create image

<!\[if !supportLists\]>o <!\[endif\]>Go to IMAGES → AMIs from the side menu

<!\[if !supportLists\]>o <!\[endif\]>select the created AMI

<!\[if !supportLists\]>o <!\[endif\]>Copy the AMI with encrypt option selected.

<!\[if !supportLists\]>· <!\[endif\]>Provide the AMI id when creating the resource in AWS batch to use custom AMI after checking the “Enable user-specified Ami ID” option

<!\[if !supportLists\]>· <!\[endif\]>Stop or terminate the instance.References:https://medium.com/@abbyfuller/not-containers-101-bringing-your-own-ami-or-configuring-on-the-fly-8f66ca7d7eefhttps://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-agent-install.htmlhttps://docs.aws.amazon.com/batch/latest/userguide/compute\_resource\_AMIs.html#batch-ami-spec (https://medium.com/@abbyfuller/not-containers-101-bringing-your-own-ami-or-configuring-on-the-fly-8f66ca7d7eef)

##### <!\[if !supportLists\]>7.1.4.3.3 <!\[endif\]>Part 2: Batch

**convention: 1 environment, 1 job queue, 1 definition per pipeline**

###### <!\[if !supportLists\]>7.1.4.3.3.1 <!\[endif\]>create new compute environment

<!\[if !supportLists\]>· <!\[endif\]>managed

<!\[if !supportLists\]>· <!\[endif\]>service role: create new or use existing AWSBatchServiceRole

<!\[if !supportLists\]>· <!\[endif\]>Instance role: create new ecsInstanceRole

<!\[if !supportLists\]>· <!\[endif\]>key pair: key pair 2 for debugging purposes

<!\[if !supportLists\]>· <!\[endif\]>instance type: (default value) optimal/m5

<!\[if !supportLists\]>o <!\[endif\]>**area to improve: review this choice later**

<!\[if !supportLists\]>· <!\[endif\]>min vCPUs

<!\[if !supportLists\]>o <!\[endif\]>0: production

<!\[if !supportLists\]>o <!\[endif\]>1: testing

<!\[if !supportLists\]>· <!\[endif\]>desired vCPUs: 2 (based on the instance type we choose)

<!\[if !supportLists\]>o <!\[endif\]>**area to improve: review this value**

<!\[if !supportLists\]>· <!\[endif\]>Network:

<!\[if !supportLists\]>o <!\[endif\]>testing: sanbox

<!\[if !supportLists\]>o <!\[endif\]>production: edc-xxx

<!\[if !supportLists\]>o <!\[endif\]>**note: keep public for now, need to improve security by using private with NAT**

<!\[if !supportLists\]>· <!\[endif\]>Tags

<!\[if !supportLists\]>o <!\[endif\]>name

<!\[if !supportLists\]>o <!\[endif\]>study

<!\[if !supportLists\]>o <!\[endif\]>environment

##### <!\[if !supportLists\]>7.1.4.3.4 <!\[endif\]>create a job queue

<!\[if !supportLists\]>· <!\[endif\]>priority: 1

<!\[if !supportLists\]>· <!\[endif\]>Enable job queue: check

<!\[if !supportLists\]>· <!\[endif\]>compute environment: created in previous step

###### <!\[if !supportLists\]>7.1.4.3.4.1 <!\[endif\]>job definitions

<!\[if !supportLists\]>· <!\[endif\]>name

<!\[if !supportLists\]>· <!\[endif\]>job attempts: use default 1

<!\[if !supportLists\]>· <!\[endif\]>execution timeout (seconds): 300

<!\[if !supportLists\]>· <!\[endif\]>compute environment: created in previous step

<!\[if !supportLists\]>· <!\[endif\]>job role: allows docker image to communicate to s3 bucket, or other AWS services in the future

<!\[if !supportLists\]>o <!\[endif\]>e.g. par-imgpipe-ecstask-s3

<!\[if !supportLists\]>o <!\[endif\]>**area to improve**

<!\[if !supportLists\]>· <!\[endif\]>container image: ECR -> image URI

<!\[if !supportLists\]>· <!\[endif\]>environment variables

<!\[if !supportLists\]>o <!\[endif\]>SCRIPT\_S3\_IN: s3 bucket image workspace

<!\[if !supportLists\]>o <!\[endif\]>OUTPUT\_S3\_OUT: img-pipe-submit-batch-job defines this value  
<!\[if !supportLineBreakNewLine\]>  
<!\[endif\]>

<!\[if !supportLists\]>o <!\[endif\]>INPUT\_S3\_IN: img-pipe-submit-batch-job defines this value  
<!\[if !supportLineBreakNewLine\]>  
<!\[endif\]>

<!\[if !supportLists\]>o <!\[endif\]>OUT_NAME: img-pipe-submit-batch-job defines this value

<!\[if !supportLists\]>· <!\[endif\]>parameters: will be defined by img-pipe-submit-batch-job

<!\[if !supportLists\]>o <!\[endif\]>pipeline_code  
<!\[if !supportLineBreakNewLine\]>  
<!\[endif\]>

<!\[if !supportLists\]>o <!\[endif\]>subjecteventcrffile_id  
<!\[if !supportLineBreakNewLine\]>  
<!\[endif\]>

<!\[if !supportLists\]>o <!\[endif\]>edc\_pipeline\_file_id  
<!\[if !supportLineBreakNewLine\]>  
<!\[endif\]>

<!\[if !supportLists\]>o <!\[endif\]>api_token  
<!\[if !supportLineBreakNewLine\]>  
<!\[endif\]>

<!\[if !supportLists\]>o <!\[endif\]>api\_url\_dicom  
<!\[if !supportLineBreakNewLine\]>  
<!\[endif\]>

<!\[if !supportLists\]>o <!\[endif\]>api\_url\_log_error

  
<!\[if !supportLineBreakNewLine\]>  
<!\[endif\]>

<!\[if !supportLists\]>· <!\[endif\]>command: value will be overwritten by the Lambda Submit Job

<!\[if !supportLists\]>o <!\[endif\]>default sample command for pipeline: _python3 processDCM.py --pipelinecode Ref::pipeline\_code --subjecteventcrffileid Ref::subjecteventcrffile\_id --edcpipelinefileid Ref::edc\_pipeline\_file\_id --apitoken Ref::api\_token --apiurldicom Ref::api\_url\_dicom --apiurllogerror Ref::api\_url\_log_error_

<!\[if !supportLists\]>§ <!\[endif\]>Ref::xxxx = Ref::parameter

<!\[if !supportLists\]>· <!\[endif\]>vCPUs: 1

<!\[if !supportLists\]>· <!\[endif\]>Memory(MB): 1024

<!\[if !supportLists\]>o <!\[endif\]>**area to improve: define this value in the lambda function Submit Job as environment variable**

<!\[if !supportLists\]>· <!\[endif\]>Security:

<!\[if !supportLists\]>o <!\[endif\]>privileged: check

<!\[if !supportLists\]>o <!\[endif\]>user: nobody

<!\[if !supportLists\]>§ <!\[endif\]>**area to improve: review this value**

<!\[if !supportLists\]>o <!\[endif\]>area to improve: security, ask Emil

###### <!\[if !supportLists\]>7.1.4.3.4.2 <!\[endif\]>Job

<!\[if !supportLists\]>· <!\[endif\]>submit a job (j_ust for testing for initial setup_)

<!\[if !supportLists\]>o <!\[endif\]>name

<!\[if !supportLists\]>o <!\[endif\]>job definition: created in previous step

<!\[if !supportLists\]>o <!\[endif\]>job queue: created in previous step

<!\[if !supportLists\]>o <!\[endif\]>job type: Single

<!\[if !supportLists\]>o <!\[endif\]>container properties:

<!\[if !supportLists\]>§ <!\[endif\]>echo job name (just for testing)

<!\[if !supportLists\]>§ <!\[endif\]>leave blank for production

#### <!\[if !supportLists\]>7.1.4.4 <!\[endif\]>Step function

step function name: same as the pipeline code

step function role: grant step function permission to invoke lambda functions  
<!\[if !supportLineBreakNewLine\]>  
<!\[endif\]>

<!\[if !supportLists\]>· <!\[endif\]>par-imgpipe-sfn

##### <!\[if !supportLists\]>7.1.4.4.1 <!\[endif\]>Lambda

<!\[if !supportLists\]>· <!\[endif\]>create the following lambda functions:

<!\[if !supportLists\]>o <!\[endif\]>list:

<!\[if !supportLists\]>§ <!\[endif\]>img-pipe-query-read-replica

<!\[if !supportLists\]>§ <!\[endif\]>img-pipe-create-pipeline-job

<!\[if !supportLists\]>§ <!\[endif\]>img-pipe-submit-batch-job

<!\[if !supportLists\]>§ <!\[endif\]>img-pipe-get-batch-job-status

<!\[if !supportLists\]>§ <!\[endif\]>img-pipe-copy-to-destination

<!\[if !supportLists\]>§ <!\[endif\]>img-pipe-notification-for-error

<!\[if !supportLists\]>§ <!\[endif\]>img-pipe-notification-for-completion

<!\[if !supportLists\]>§ <!\[endif\]>**area to improve: refactor the script and environment variables to be able to use for another image pipeline**

<!\[if !supportLists\]>o <!\[endif\]>service role: for step function used lambda function

<!\[if !supportLists\]>§ <!\[endif\]>e.g. par-imgpipe

<!\[if !supportLists\]>§ <!\[endif\]>**area to improve**

<!\[if !supportLists\]>o <!\[endif\]>VPC:

<!\[if !supportLists\]>§ <!\[endif\]>area to improve: make sure the VPC is tight

<!\[if !supportLists\]>o <!\[endif\]>environment variables:

<!\[if !supportLists\]>§ <!\[endif\]>img-pipe-query-read-replica

<!\[if !supportLists\]>· <!\[endif\]>edc\_pipeline\_api_token

<!\[if !supportLists\]>· <!\[endif\]>edc\_pipeline\_api\_url\_dicom

<!\[if !supportLists\]>· <!\[endif\]>edc\_pipeline\_api\_url\_log_error

<!\[if !supportLists\]>· <!\[endif\]>edc\_pipeline\_code

<!\[if !supportLists\]>· <!\[endif\]>rds\_db\_name

<!\[if !supportLists\]>· <!\[endif\]>rds\_db\_password

<!\[if !supportLists\]>· <!\[endif\]>rds\_db\_username

<!\[if !supportLists\]>· <!\[endif\]>rds_host

<!\[if !supportLists\]>· <!\[endif\]>workspace\_bucket\_name

<!\[if !supportLists\]>· <!\[endif\]>workspace\_file\_path

<!\[if !supportLists\]>· <!\[endif\]>note: add layer for psycopg2 library, python version used: 3.7

<!\[if !supportLists\]>§ <!\[endif\]>img-pipe-create-pipeline-job

<!\[if !supportLists\]>§ <!\[endif\]>img-pipe-submit-batch-job

<!\[if !supportLists\]>§ <!\[endif\]>img-pipe-get-batch-job-status

<!\[if !supportLists\]>§ <!\[endif\]>img-pipe-copy-to-destination

<!\[if !supportLists\]>· <!\[endif\]>target\_bucket\_name

<!\[if !supportLists\]>· <!\[endif\]>target\_file\_path

<!\[if !supportLists\]>§ <!\[endif\]>img-pipe-notification-for-error

<!\[if !supportLists\]>§ <!\[endif\]>img-pipe-notification-for-completion

<!\[if !supportLists\]>o <!\[endif\]>**area to improve:**

<!\[if !supportLists\]>§ <!\[endif\]>code refactor

<!\[if !supportLists\]>§ <!\[endif\]>environment variables

##### <!\[if !supportLists\]>7.1.4.4.2 <!\[endif\]>State Machine Definition

{

"StartAt":"Queryreadreplica",

"States":{

"Queryreadreplica":{

"Type":"Task",

"Resource":"arn:aws:lambda:us-east-1:xxx:function:img-pipe-query-read-replica",

"Next":"Create-pipeline-job",

"Retry":\[

{

"ErrorEquals":\[

"Error"

\],

"IntervalSeconds":1,

"BackoffRate":2.0,

"MaxAttempts":3

}

\],

"Catch":\[

{

"ErrorEquals":\[

"States.ALL"

\],

"Next":"ErrorSNS"

}

\]

},

"Create-pipeline-job":{

"Type":"Task",

"Resource":"arn:aws:lambda:us-east-1:xxx:function:hq-create-pipeline-job",

"Next":"SubmitJob",

"Catch":\[

{

"ErrorEquals":\[

"States.ALL"

\],

"Next":"ErrorSNS"

}

\]

},

"SubmitJob":{

"Type":"Task",

"Resource":"arn:aws:lambda:us-east-1:xxx:function:par-imgpipe-batchSubmitJob",

"Next":"GetJobStatus",

"Catch":\[

{

"ErrorEquals":\[

"States.ALL"

\],

"Next":"ErrorSNS"

}

\]

},

"GetJobStatus":{

"Type":"Task",

"Resource":"arn:aws:lambda:us-east-1:xxx:function:par-imgpipe-batchGetJobStatus",

"Next":"CheckJobStatus",

"InputPath":"$",

"ResultPath":"$.status"

},

"CheckJobStatus":{

"Type":"Choice",

"Choices":\[

{

"Variable":"$.status",

"StringEquals":"FAILED",

"Next":"ErrorSNS"

},

{

"Variable":"$.status",

"StringEquals":"SUCCEEDED",

"Next":"par-imgpipe-copy2dest"

}

\],

"Default":"Wait30Seconds"

},

"Wait30Seconds":{

"Type":"Wait",

"Seconds":15,

"Next":"GetJobStatus"

},

"par-imgpipe-copy2dest":{

"Type":"Task",

"Resource":"arn:aws:lambda:us-east-1:xxx:function:par-imgpipe-copy2dest",

"Next":"par-imgpipe-updateStatus",

"Catch":\[

{

"ErrorEquals":\[

"States.ALL"

\],

"Next":"ErrorSNS"

}

\]

},

"par-imgpipe-updateStatus":{

"Type":"Task",

"Resource":"arn:aws:lambda:us-east-1:xxx:function:par-imgpipe-updateStatus",

"Next":"processCompletionSNS",

"Catch":\[

{

"ErrorEquals":\[

"States.ALL"

\],

"Next":"ErrorSNS"

}

\]

},

"ErrorSNS":{

"Type":"Task",

"Resource":"arn:aws:lambda:us-east-1:xxx:function:par-imgpipe-errorSNS",

"Next":"processCompletionSNS"

},

"processCompletionSNS":{

"Type":"Task",

"Resource":"arn:aws:lambda:us-east-1:xxx:function:par-imgpipe-processCompletionSNS",

"End":true

}

}

}

Trigger

<!\[if !supportLists\]>· <!\[endif\]>we have the state machine (step function)

<!\[if !supportLists\]>· <!\[endif\]>we have source s3 bucket

<!\[if !supportLists\]>· <!\[endif\]>create trail in CloudTrail

<!\[if !supportLists\]>o <!\[endif\]>trail name: same as step function for batch

<!\[if !supportLists\]>o <!\[endif\]>s3 bucket: workspace bucket

<!\[if !supportLists\]>§ <!\[endif\]>prefix: subjecteventcrffile

<!\[if !supportLists\]>§ <!\[endif\]>write only

<!\[if !supportLists\]>o <!\[endif\]>storage location (for logs)

<!\[if !supportLists\]>§ <!\[endif\]>s3 bucket: workspace

<!\[if !supportLists\]>§ <!\[endif\]>prefix: logs/pipeline_code/trigger

### <!\[if !supportLists\]>7.1.5 <!\[endif\]>Relevant Documents

[AWS Batch](https://atrihub.atlassian.net/wiki/spaces/RD/blog/2018/12/10/912261126/AWS+Batch) (https://atrihub.atlassian.net/wiki/spaces/RD/blog/2018/12/10/912261126/AWS+Batch)

[https://docs.aws.amazon.com/step-functions/latest/dg/tutorial-cloudwatch-events-s3.html](https://docs.aws.amazon.com/step-functions/latest/dg/tutorial-cloudwatch-events-s3.html) (https://docs.aws.amazon.com/step-functions/latest/dg/tutorial-cloudwatch-events-s3.html)

## <!\[if !supportLists\]>7.2 <!\[endif\]>How to manually trigger image pipeline in step function

{

 "detail":{

 "requestParameters":{

 "bucketName": source s3 bucket name,

 "key":s3 object key  


}  


}  


}
<!--stackedit_data:
eyJoaXN0b3J5IjpbMTMzNTIwMzQyN119
-->